{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjKbICfT7OOM"
      },
      "source": [
        "#**Data Normalization (part 1)**\n",
        "\n",
        "#**Normalizing & Scaling data**\n",
        "\n",
        "This lesson is about preparing your data so that machine learning algorithms can be more accurate and efficient. We will discuss various techniques that all fall under the categories of data standardization, cleaning, scaling, etc. We'll use the umbrella term normalization. Although even that term means something different when talking about vector normalization.\n",
        "\n",
        "The overall goal of data normalization is about reducing redundancy and improving accuracy and integrity of the data and for any techniques that will use the data. The process of normalizing has its roots in relational databases where the goal is to restructure the tables and relationships to get them into 'normal' form to reduce data redundancy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwWJ7-OK7oAA"
      },
      "source": [
        "#**Different Data Types, different techniques**\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1UvAkd0P4H_lLomxN3qQwsHOpE5VzcWRV)\n",
        "\n",
        "You learned about the different ways to classify data in the previous class; this lesson is looking at data at more granular level. Although all data is essentially grouped binary values (bits on or off), we will look at how to manage some of the most common categories in data- science including text, numeric, and categorical (a mix of text and numbers).\n",
        "\n",
        "Data normalization can be done just about any kind of data including audio, image, text, numeric, and categorical data. We will go over some of the basic strategies for handling several of these data types.\n",
        "\n",
        "We will have an additional lesson that focuses on processing text data. What follows are some common techniques we can use to apply rules to help bring some consistency to handling both numeric and categorical attributes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxcUG0e3-nmE"
      },
      "source": [
        "**Cleaning the Missing**\n",
        "\n",
        "Many of the techniques to 'normalize' the data will fail if the transformation is done on a missing value. Missing values can truly be absent (e.g. the dreaded double comma in csv files) or marked with a special character like None, NAN, NaN, nan,null, NULL, void, 'n/a', or the empty string (i.e ''). Pandas, NumPy, and Sklearn all provide ways to help with cleaning and normalizing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsb0QfLKCLoW"
      },
      "source": [
        "#**A titanic example**\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1T62pGhC6VkO8Ya1jJe0hvZUvooEOjtDL)\n",
        "\n",
        "The Titanic sank on April 15th, 1912 after hitting an iceberg. It had roughly 2208 passengers and crew aboard (the exact number seems to be [unknown](http://www.icyousee.org/titanic.html).) A few good [references](https://www.historyonthenet.com/the-titanic) for some [details](https://titanicfacts.net/titanic-passengers/) show the discrepancies in the exact numbers.\n",
        "\n",
        "The titanic dataset provides a good opportunity to work on a classic dataset that is in need of some cleaning and normalization. This lesson includes\n",
        "one of the more complete datasets. There are many available.\n",
        "\n",
        "We can load up the dataset and print out the first row so you can get a feel for the data. You can [read](http://campus.lakeforest.edu/frank/FILES/MLFfiles/Bio150/Titanic/TitanicMETA.pdf) about the meaning of each data field as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OpV0uMNrC4XV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total rows 2207\n",
            "   id                 name gender   age class embarked        country  ticketno  fare  sibsp  parch survived   sid\n",
            "0   1  Abbing, Mr. Anthony   male  42.0   3rd        S  United States    5547.0  7.11    0.0    0.0       no  1870\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 200)\n",
        "\n",
        "def build_titanic():\n",
        "  df = pd.read_csv('titanic.csv')\n",
        "  print('total rows', len(df))\n",
        "\n",
        "  # add an extra passenger\n",
        "  extra = {'name': 'Jack Dawson', 'age': 28, 'id': len(df)+1, 'gender': 'male'}\n",
        "  df = df.append(extra, ignore_index=True)\n",
        "\n",
        "  # add an extra field for using a custom transformer\n",
        "  df['sid'] = df['age'].apply(lambda x: 'NA' if np.isnan(x) else \"{:.0f}\".format(1912-x)).astype('string')\n",
        "  df['sid'].replace('NA', np.nan, inplace=True)\n",
        "  \n",
        "  return df.copy()\n",
        "\n",
        "df = build_titanic()\n",
        "print(df.head(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlti5VSAC7kH"
      },
      "source": [
        "**Getting the missing counts**\n",
        "\n",
        "One of the first things you should do is get a count of which attributes have missing values. You can easily do this with pandas. In the example below, we ask for all null (NaN) values and then sum them up. When you look at the result, any column with a non-zero value has missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SKUEDfihDEKy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id            0\n",
            "name          0\n",
            "gender        0\n",
            "age           2\n",
            "class         1\n",
            "embarked      1\n",
            "country      82\n",
            "ticketno    892\n",
            "fare        917\n",
            "sibsp       901\n",
            "parch       901\n",
            "survived      1\n",
            "sid           2\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def show_missing(df):\n",
        "  print(df.isna().sum())\n",
        "  \n",
        "show_missing(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvsRJK4-DFC6"
      },
      "source": [
        "You can see that 'age' has only 2 missing values. That is, 2 rows/instances don't have a value for the 'age' column. If a majority of your rows have missing values for a certain attribute, the best strategy is to simply not use that attribute in any of the analysis (e.g. country, ticketno, fare, sibsp, parch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2SLbfTfDMtl"
      },
      "source": [
        "### **Imputing the missing**\n",
        "\n",
        "One of the most common ways to deal with missing values is to interpolate (e.g. estimate or impute) the value from the values that are present.\n",
        "\n",
        "**Pandas**\n",
        "\n",
        "In the example below, we fill empty/missing values for the 'age' attribute with the mean for that column. You can also use the calculated median, mode or a constant as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ElM-UWZiDZ2v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      id                    name  age  age_clean\n",
            "439  440  Gheorgheff, Mr. Stanio  NaN   30.43563\n",
            "677  678     Kraeff, Mr. Theodor  NaN   30.43563\n"
          ]
        }
      ],
      "source": [
        "def process_missing_age(df, debug=True):\n",
        "\n",
        "  # mask to select the rows where age is empty\n",
        "  mask = df.age.isna()\n",
        "\n",
        "  # calculate the mean (the replacement value)\n",
        "  replace_value = df.age.mean()\n",
        "  \n",
        "  # fill those values with the value calculated\n",
        "  df['age_clean']= df[mask].age.fillna(replace_value)\n",
        "  if debug:\n",
        "    # print out the updates\n",
        "    cols = ['id', 'name', 'age', 'age_clean']\n",
        "    print(df[mask][cols].head())\n",
        "    \n",
        "# pass in a copy, so we keep the original\n",
        "process_missing_age(df.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cADYG_kpDeG9"
      },
      "source": [
        "**Sklearn**\n",
        "\n",
        "Another way to impute the missing is to use sklearn. The same 'age' column is updated to the mean for any missing value. Note how we create a new attribute to hold the 'age' column that is free of any missing values. \n",
        "\n",
        "Also, read the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) for different strategies you can use. Note sklearn's repeated fit and transform process is applied here (even though there is no training and fitting of models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [2],\n",
              "       [3]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([1, 2, 3]).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DQJrCi1yDdPx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[42. 13. 16. ... 20. 26. 28.]\n",
            "      id                    name  age    im_age\n",
            "439  440  Gheorgheff, Mr. Stanio  NaN  30.43563\n",
            "677  678     Kraeff, Mr. Theodor  NaN  30.43563\n",
            "Missing\n",
            "id        0\n",
            "name      0\n",
            "age       2\n",
            "im_age    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def process_missing_age_skl(df, debug=True):\n",
        "  from sklearn.impute import SimpleImputer\n",
        "  import numpy as np\n",
        "\n",
        "  # np.nan is the how pandas marks missing values\n",
        "  # replace with the mean\n",
        "  imr = SimpleImputer(strategy=\"mean\", missing_values=np.nan)\n",
        "\n",
        "  # Impute values\n",
        "  values = df.age.values.reshape(-1,1)\n",
        "  print(df.age.values)\n",
        "  out = imr.fit_transform(values)\n",
        "\n",
        "  # now we assign those values to a new column\n",
        "  df['im_age'] = out\n",
        "\n",
        "  if debug:\n",
        "    cols = ['id', 'name', 'age', 'im_age']\n",
        "    mask = df.age.isna()\n",
        "    print(df[mask][cols].head())\n",
        "    print('Missing')\n",
        "    print(df.isna()[cols].sum())\n",
        "    \n",
        "process_missing_age_skl(df.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[42.],\n",
              "       [13.],\n",
              "       [16.],\n",
              "       ...,\n",
              "       [20.],\n",
              "       [26.],\n",
              "       [28.]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.age.values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvflS3VbDrvH"
      },
      "source": [
        "A few lines of code to note. See if you understand the following from the above code block:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Impute values\n",
        "values = df.age.values.reshape(-1,1)\n",
        "out = imr.fit_transform(values)\n",
        "```\n",
        "\n",
        "* sklearn needs its data in numpy/array form\n",
        "* .values is the underlying numpy array\n",
        "* .reshape(-1,1) reshapes the data to a single feature/column\n",
        "* -1,1 means all rows, 1 column\n",
        "\n",
        "It's also possible to use a more 'user-friendly' version as well:\n",
        "\n",
        "```\n",
        "# Impute values\n",
        "features = ['age']\n",
        "values = df[features]\n",
        "out = imr.fit_transform(values)\n",
        "```\n",
        "\n",
        "In this case, we can actually fit and transform multiple columns. If you do that it's important to take caution on how you assign the result back to the pandas dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_7rqMW0FUw9"
      },
      "source": [
        "**Deleting the missing instances (rows)**\n",
        "\n",
        "Another, perhaps drastic, technique is to simply remove any row that has a missing value for any of the attributes you need. This strategy is fine if you have plenty of data. You can also decide to delete only if an instance has multiple missing attributes.\n",
        "\n",
        "**Predicting the missing;**\n",
        "\n",
        "Another viable option is to use a machine learning algorithm to figure out which value should be used to replace the missing. Although we haven't discussed the K-Nearest Neighbors (KNN) algorithm (a supervised ML algorithm for both classification and regression), it's a viable solution if you want a more robust strategy than simple statistical (e.g. mean, median, mode) replacement. If there's enough time, we will have a lesson on KNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFM-Dv75FdFR"
      },
      "source": [
        "#**Categorical Data**\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1_8d2JROR2Oa4_XMi2UIQEkdqi4YhQJnV)\n",
        "\n",
        "For handling categorical data or data whose attribute values are labels/text, the main focus is being consistent for handling the different categories. The goal is to map each label/category to a unique number.\n",
        "\n",
        "Many of the same rules apply for text cleaning; however, if the label is coming from a computer, process, sensor, or standardized input, much of the cleaning is already done for you. That is, you don't have to worry about different labels having the same semantic meaning. For example, if your categories are coming from a web form, you would have to deal with misspellings, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qDsOxroF1nK"
      },
      "source": [
        "###**Mapping labels to numbers**\n",
        "\n",
        "All machine learning algorithms need a numeric representation of any text value. If you have categorical attributes whose values are strings, you will need to map these values to a number.\n",
        "\n",
        "**Nominal Attributes**\n",
        "For simple categorical data where there is no ranking order of the values, we can simply map the labels to numbers. In Pandas, it's very straight forward. You can use the .astype(\"category\").cat.codes on any categorical data type:\n",
        "\n",
        "```\n",
        "df['g_code'] = df['gender'].astype(\"category\").cat.codes\n",
        "```\n",
        "Because the process is so straight forward, we can create a utility function to help us map any column:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ddzAN72OFSLh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 unique values for gender: ['male' 'female']\n",
            "   gender  g_code\n",
            "0  female     489\n",
            "1    male    1719\n",
            "2208\n",
            "   gender  g_code\n",
            "0    male       1\n",
            "1    male       1\n",
            "2    male       1\n",
            "3  female       0\n",
            "4  female       0\n",
            "5    male       1\n",
            "6    male       1\n",
            "7  female       0\n",
            "8    male       1\n",
            "9    male       1\n"
          ]
        }
      ],
      "source": [
        "def category_to_number(df, col_name, new_name, debug=True):\n",
        "\n",
        "  # map the categories to unique integers (starting at 0)\n",
        "  df[new_name] = df[col_name].astype(\"category\").cat.codes\n",
        "\n",
        "  if debug:\n",
        "    values = df[col_name].unique()\n",
        "    print('{:d} unique values for {:s}:'.format(len(values), col_name), values)\n",
        "    # show how many rows are in each group\n",
        "    print(df.groupby([col_name]).count()[new_name].reset_index())\n",
        "    print(df.groupby([col_name]).count()[new_name].sum())\n",
        "  \n",
        "  return df\n",
        "\n",
        "# map gender to a 0/1 code\n",
        "cols = ['gender', 'g_code']\n",
        "df2 = category_to_number(df.copy(), *cols)  # putting * to good use\n",
        "print(df2[cols][0:10]) # first 10 rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbCJiwDYGSBO"
      },
      "source": [
        "**Handling missing values**\n",
        "\n",
        "For the 'gender' column, there are no missing values. However if there are any missing values, those values get marked with a -1 by default. If you want to keep the np.nan values for missing you can simply do a replace:\n",
        "\n",
        "```\n",
        "df2['g_code'] = df2['g_code'].replace(-1, np.nan)\n",
        "```\n",
        "\n",
        "**port of embarkation**\n",
        "We can use the same function to map port of embarkation, which does have some missing values. Let's take a look at how pandas handles those missing values. Be sure to understand how pandas treats the missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7h0cyTfuGmQd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 unique values for embarked: ['S' 'C' 'B' 'Q' nan]\n",
            "  embarked  e_code\n",
            "0        B     197\n",
            "1        C     271\n",
            "2        Q     123\n",
            "3        S    1616\n",
            "2207\n",
            "  embarked  e_code\n",
            "0        S       3\n",
            "1        S       3\n",
            "2        S       3\n",
            "3        S       3\n",
            "4        S       3\n",
            "5        S       3\n",
            "6        C       1\n",
            "7        C       1\n",
            "8        C       1\n",
            "9        S       3\n",
            "        id         name gender   age class embarked country  ticketno  fare  sibsp  parch survived   sid  e_code\n",
            "2207  2208  Jack Dawson   male  28.0   NaN      NaN     NaN       NaN   NaN    NaN    NaN      NaN  1884      -1\n"
          ]
        }
      ],
      "source": [
        "# map port of embarkation (C, Q, S)\n",
        "# C = Cherbourg, Q = Queenstown, S = Southampton,  B = ??\n",
        "cols = ['embarked', 'e_code']\n",
        "df = category_to_number(df.copy(), *cols)\n",
        "print(df[cols][0:10]) # first 10 rows\n",
        "mask = df.embarked.isna()\n",
        "print(df[mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X-gSSipGprX"
      },
      "source": [
        "**Codebook WARNING**\n",
        "\n",
        "As you may have noticed, there's not much control over which numbers will be assigned to which categories. If you needed 'Cherbourg' to be a specific numeric value (because of an outside requirement or codebook -- a document that specifies how the mappings are done), you would have to adjust the algorithm. The next section discusses, one possible solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_sdFW9MGzms"
      },
      "source": [
        "**Ordinal Mapping**\n",
        "When your categorical attributes have an inherent ranking (e.g. review of stars, likert scales, etc), you can define your own value map that maintains the order as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jik_xaUPHFoc"
      },
      "source": [
        "**“ Likert's Log**: As a word of caution, just because there's an order of 'rank' to your values, these values are still not 'numeric'.\n",
        "\n",
        "For example, if you had a survey that ranked items using a [Strongly Agree, Agree, Neither, Disagree, Strongly Disagree] scale or you asked someone to rank an issue from 1 to 5, don't assume you can work with averages. Also, the interval between different values isn't mathematically stable. For example, the difference between 'Strongly Agree' and 'Agree' cannot be assumed to be the same as the difference between 'Disagree' and 'Strongly Disagree'. Using counts, medians, and modes is usually the best you can do.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDBGhVX1HTGF"
      },
      "source": [
        "With Pandas, you can use the map function to create custom rank values:\n",
        "\n",
        "```\n",
        "df[new_name] = df[column_name].map(kv_map)\n",
        "```\n",
        "\n",
        "Let's use that pattern to map the class attribute that categorizes both the passengers and crew. Note that all the crew gets the value 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9M0GqHzSGpMH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['3rd', '2nd', '1st', 'engineering crew', 'victualling crew', 'restaurant staff', 'deck crew', 'unknown']\n",
            "              class  o_class\n",
            "0               1st      324\n",
            "1               2nd      284\n",
            "2               3rd      709\n",
            "3         deck crew       66\n",
            "4  engineering crew      324\n",
            "5  restaurant staff       69\n",
            "6           unknown        1\n",
            "7  victualling crew      431\n",
            "   id                            name  gender   age class embarked        country  ticketno   fare  sibsp  parch survived   sid  e_code  o_class\n",
            "0   1             Abbing, Mr. Anthony    male  42.0   3rd        S  United States    5547.0   7.11    0.0    0.0       no  1870       3        3\n",
            "1   2       Abbott, Mr. Eugene Joseph    male  13.0   3rd        S  United States    2673.0  20.05    0.0    2.0       no  1899       3        3\n",
            "2   3     Abbott, Mr. Rossmore Edward    male  16.0   3rd        S  United States    2673.0  20.05    1.0    1.0       no  1896       3        3\n",
            "3   4  Abbott, Mrs. Rhoda Mary 'Rosa'  female  39.0   3rd        S        England    2673.0  20.05    1.0    1.0      yes  1873       3        3\n",
            "4   5     Abelseth, Miss. Karen Marie  female  16.0   3rd        S         Norway  348125.0   7.13    0.0    0.0      yes  1896       3        3\n"
          ]
        }
      ],
      "source": [
        "def map_class_attribute(df, debug=True):\n",
        "\n",
        "  # map 1st/2nd/3rd class as ordinal 1st < 2nd < 3rd + missing\n",
        "  # replace nan with the value 'unknown'\n",
        "  df['class'].fillna('unknown', inplace=True)\n",
        "  # assign the labels values\n",
        "  ord_map = {'3rd':3, '2nd':2, '1st':1,\n",
        "             'engineering crew':4,\n",
        "             'victualling crew':4,\n",
        "             'restaurant staff':4,\n",
        "             'deck crew':4, 'unknown':0}\n",
        "\n",
        "  # apply the map to the 'class' attribute\n",
        "  df['o_class'] = df['class'].map(ord_map)\n",
        "\n",
        "  if debug:\n",
        "    print(df['class'].unique().tolist())\n",
        "    # show how many rows are in each group\n",
        "    print(df.groupby(['class']).count()['o_class'].reset_index())\n",
        "\n",
        "  return df\n",
        "  \n",
        "df_class = map_class_attribute(df.copy())\n",
        "print(df_class.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHSF1tGDIAZz"
      },
      "source": [
        "Once we have those numeric values, it's pretty easy to separate everyone into crew and passengers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1oYMMgGIDN_",
        "outputId": "88373394-d005-4dcb-92d1-76751bd44d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "crew 890\n",
            "pass 1318\n"
          ]
        }
      ],
      "source": [
        "def print_passenger_class_stats(df):\n",
        "  is_crew = df['o_class'].isin([4])\n",
        "\n",
        "  # any of these will work\n",
        "  is_pass = df['o_class'].isin([1,2,3])\n",
        "  is_pass = (df['o_class'] < 4 ) & (df['o_class'] > 0)\n",
        "  is_pass = ~is_crew  # will include the unknowns\n",
        "\n",
        "  print('crew', len(df[is_crew]))\n",
        "  print('pass', len(df[is_pass]))\n",
        "  \n",
        "# this assumes map_class_attribute is done\n",
        "print_passenger_class_stats(df_class.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OKqp-PEIGYA"
      },
      "source": [
        "**Binary Fields**\n",
        "\n",
        "Sometimes you may want an attribute to simply indicate a simple Yes/No, On/Off, Have/not- Have value.\n",
        "\n",
        "For example, we can add a is_passenger attribute to the data. This field will either be 0 (False) or 1 (True) indicating if the person was a passenger on the ship (as opposed to being part of the crew.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "peUkytXPIPxk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n",
            "   id                            name  gender   age class embarked        country  ticketno   fare  sibsp  parch survived   sid  e_code  o_class  is_passenger\n",
            "0   1             Abbing, Mr. Anthony    male  42.0   3rd        S  United States    5547.0   7.11    0.0    0.0       no  1870       3        3             1\n",
            "1   2       Abbott, Mr. Eugene Joseph    male  13.0   3rd        S  United States    2673.0  20.05    0.0    2.0       no  1899       3        3             1\n",
            "2   3     Abbott, Mr. Rossmore Edward    male  16.0   3rd        S  United States    2673.0  20.05    1.0    1.0       no  1896       3        3             1\n",
            "3   4  Abbott, Mrs. Rhoda Mary 'Rosa'  female  39.0   3rd        S        England    2673.0  20.05    1.0    1.0      yes  1873       3        3             1\n",
            "4   5     Abelseth, Miss. Karen Marie  female  16.0   3rd        S         Norway  348125.0   7.13    0.0    0.0      yes  1896       3        3             1\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "def create_binary_field(df, debug=True):\n",
        "  # Binary Fields\n",
        "  from sklearn.preprocessing import Binarizer\n",
        "  binarizer = Binarizer(threshold=3, copy=True)  # <= 3 asssing\n",
        "  column_values = binarizer.fit_transform(df.o_class.values.reshape(-1, 1))\n",
        "  \n",
        "  # flip the values (1 -> 0; 0 -> 1)\n",
        "  df['is_passenger'] = 1 - column_values\n",
        "  if debug:\n",
        "    print(column_values)\n",
        "    print(df.head(5))\n",
        "\n",
        "print(create_binary_field(df_class.copy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRJbYCpfITOk"
      },
      "source": [
        "**One Hot Encoding**\n",
        "\n",
        "As mentioned in a previous lesson, one hot encoding simply assigns either a 1 or a 0 to an attribute if that attribute is present or not. It's an extension of using the Binarizer. The issue is that for categorical (nominal or ordinal), it's not accurate that some values will be 'higher' than other only because their mapping value was larger. As we just saw, if you map category labels, for example, to the numbers 0 through 100 (or 0.0 to 1.0), the ML algorithm may think the higher values contributes more to some correlation or calculation than the lower values. It's also useful just to mark some attributes as being present or not. This is where one hot encoding becomes useful.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "In the previous section we built a simple one-hot attribute (is_passenger), this example takes an entire column of categorical values and builds separate one-hot columns for each unique value. It's simply a convenient way to create one-hot attributes. The image below shows an example of the result of one hot encoding of the embankment attribute:\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1tBf_U9C70qAmBFZgcqPltDDbv5ueC1DZ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EIrajGiuIeVY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      B  C  Q  S UKN\n",
            "2188  0  0  0  1   0\n",
            "2189  0  0  0  1   0\n",
            "2190  0  0  0  1   0\n",
            "2191  0  0  0  1   0\n",
            "2192  0  0  0  1   0\n",
            "2193  0  0  0  1   0\n",
            "2194  0  0  0  1   0\n",
            "2195  0  0  0  1   0\n",
            "2196  0  0  0  1   0\n",
            "2197  0  0  0  1   0\n",
            "2198  1  0  0  0   0\n",
            "2199  0  0  0  1   0\n",
            "2200  0  0  0  1   0\n",
            "2201  0  0  0  1   0\n",
            "2202  1  0  0  0   0\n",
            "2203  0  0  0  1   0\n",
            "2204  0  0  0  1   0\n",
            "2205  0  0  0  1   0\n",
            "2206  0  0  0  1   0\n",
            "2207  0  0  0  0   1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zq/gn09x0d53r74hd7z0lp249cr0000gp/T/ipykernel_33131/1856968406.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  onehot = OneHotEncoder(dtype=np.int, sparse=True)\n"
          ]
        }
      ],
      "source": [
        "def one_hot_encoding(df):\n",
        "  import numpy as np\n",
        "  from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "  onehot = OneHotEncoder(dtype=np.int, sparse=True)\n",
        "  \n",
        "  # fill in any missing values with 'UNK'\n",
        "  df['embarked'].fillna('UKN', inplace=True)\n",
        "  values = df['embarked'].values.reshape(-1, 1)\n",
        "  values = onehot.fit_transform(values).toarray() # it is sparse\n",
        "  labels = onehot.categories_\n",
        "  \n",
        "  return pd.DataFrame(values, columns=labels)\n",
        "\n",
        "df_hot = one_hot_encoding(df.copy())\n",
        "print(df_hot.tail(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9CetVdXIgxR"
      },
      "source": [
        "The panda's get_dummies method provides another way to do one-hot encoding:\n",
        "\n",
        "```\n",
        "print(pd.get_dummies(df['embarked'], dummy_na=True))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNy2W4tiIlnk"
      },
      "source": [
        "#**Binning/Discretizating Features**\n",
        "Although not strictly for categorical data, another option is to put data into bins. Pandas provides the cut method to create custom bins:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fNQRcpw1IsjR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id   age      age_cat\n",
            "0   1  42.0       middle\n",
            "1   2  13.0        youth\n",
            "2   3  16.0  young adult\n",
            "3   4  39.0       middle\n",
            "4   5  16.0  young adult\n",
            "5   6  25.0        adult\n",
            "6   7  30.0        adult\n",
            "7   8  28.0        adult\n",
            "8   9  27.0        adult\n",
            "9  10  20.0  young adult\n"
          ]
        }
      ],
      "source": [
        "# binning data\n",
        "def bin_demo1(df):\n",
        "# set up custom bins\n",
        "  bins = [0, 3, 8, 16, 21, 35, 55, 200] \n",
        "  labels = ['infant','child','youth','young adult','adult','middle','senior'] \n",
        "  age_bins = pd.cut(df['age'], bins=bins, labels=labels, right=False) \n",
        "  df['age_cat'] = age_bins\n",
        "  print(df['id age age_cat'.split()].head(10))\n",
        "  return df\n",
        "  \n",
        "df_bin = bin_demo1(df.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyUqdihHIv5x"
      },
      "source": [
        "Sklearn provides a similar preprocessing utility class for binning, named KBinsDiscretizer. It has the familiar fit and transform API. It also requires that the attribute has no missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8ZNhNBUQIykU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id   age      age_cat  age_cat2\n",
            "0   1  42.0       middle       4.0\n",
            "1   2  13.0        youth       1.0\n",
            "2   3  16.0  young adult       1.0\n",
            "3   4  39.0       middle       4.0\n",
            "4   5  16.0  young adult       1.0\n",
            "5   6  25.0        adult       2.0\n",
            "6   7  30.0        adult       3.0\n",
            "7   8  28.0        adult       3.0\n",
            "8   9  27.0        adult       2.0\n",
            "9  10  20.0  young adult       2.0\n"
          ]
        }
      ],
      "source": [
        "def bin_demo2(df):\n",
        "  # uniform bins\n",
        "  from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "  # this must be done first\n",
        "  df['age'].fillna(df['age'].mean(), inplace=True)\n",
        "  \n",
        "  binner = KBinsDiscretizer(n_bins=8, encode='ordinal', strategy='uniform')\n",
        "  values = binner.fit_transform(df['age'].values.reshape(-1, 1))\n",
        "  df['age_cat2'] = values\n",
        "  print(df['id age age_cat age_cat2'.split()].head(10))\n",
        "\n",
        "bin_demo2(df_bin.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4ftDznMI0hj"
      },
      "source": [
        "We can even use the same class to create one-hot encoded bins. By changing it's strategy. Be sure to [read](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) its documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qF8ie7FoI24I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   bin 1  bin 2  bin 3  bin 4   age\n",
            "0    0.0    0.0    1.0    0.0  42.0\n",
            "1    1.0    0.0    0.0    0.0  13.0\n",
            "2    1.0    0.0    0.0    0.0  16.0\n",
            "3    0.0    0.0    1.0    0.0  39.0\n",
            "4    1.0    0.0    0.0    0.0  16.0\n",
            "5    0.0    1.0    0.0    0.0  25.0\n",
            "6    0.0    1.0    0.0    0.0  30.0\n",
            "7    0.0    1.0    0.0    0.0  28.0\n",
            "8    0.0    1.0    0.0    0.0  27.0\n",
            "9    0.0    1.0    0.0    0.0  20.0\n"
          ]
        }
      ],
      "source": [
        "def bin_demo3(df):\n",
        "  # one hot binning\n",
        "  from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "  bin_count = 4\n",
        "  df['age'].fillna(df['age'].mean(), inplace=True)\n",
        "  binner = KBinsDiscretizer(n_bins=bin_count, encode='onehot-dense', strategy='uniform')\n",
        "  values = binner.fit_transform(df['age'].values.reshape(-1, 1))\n",
        "  labels = ['bin {:d}'.format(i) for i in range(1, bin_count+1)]\n",
        "  \n",
        "  df2 = pd.DataFrame(values, columns=labels)\n",
        "  df2['age'] = df['age']\n",
        "  print(df2.head(10))\n",
        "\n",
        "bin_demo3(df.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH5CsyNZI5iH"
      },
      "source": [
        "#**Numeric Data**\n",
        "\n",
        "The goal for normalizing numeric data is essentially same: you want your values to accurately represent the underlying measurement. However, there's an additional consideration called scaling (or feature scaling). The idea is that you don't want the units of one feature (i.e. column/attribute) to overshadow the units of another.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1eFOO24Rb9gU98yH43smcy3WxxOvd41Oi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ0BwxEZJCD0"
      },
      "source": [
        "#**Feature Scaling Data**\n",
        "One of the most important transformation to make is to ensure each of your numeric attributes are scaled so that one attribute's units are in the same 'scale' as others. Feature scaling standardizes the value range of features of the data.\n",
        "\n",
        "Let's go over some vocabulary relevant for feature 'scaling':\n",
        "* **Rescaling** a feature vector (think columns of data) means to add or subtract a constant and then multiply or divide by a constant, as you would do to change the units of measurement of the data, for example, to convert a temperature from Celsius to Fahrenheit.\n",
        "\n",
        "* **Normalizing** a feature vector usually means dividing each element by the norm (L1 or L2) of the vector (||x||). However, for this lesson it will refer to a type of rescaling.\n",
        "\n",
        "* **Standardizing** a vector means subtracting a measure of location (mean or median) and dividing by a measure of scale (e.g. standard deviation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U62td42YJVui"
      },
      "source": [
        "**Min-Max Scaling**\n",
        "\n",
        "**(a.k.a Min-Max Normalization)**\n",
        "\n",
        "In min-max scaling, you transform the data such that the features are within a specific range usually [0, 1].\n",
        "\n",
        "Scaling is important for algorithms where distance between data points is important. You want to avoid attributes working together but are on different scales. For example, having one attribute measured in feet while the other is in pounds while another is in miles, will wreak havoc on the ML algorithm's calculations.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1yjhjzsYIzUuQiL_5tI3g1Rv4E8NUIkzX)\n",
        "\n",
        "\n",
        "You can see how the min-max formula scales by the data range (also called peak-to-peak). Run the code below to view some of the values that are used to scale each data item:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AWE6BKExJh39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total rows 2207\n",
            "3.0305\n",
            "3.0305 512.0607\n",
            "509.0302\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def fare_stats(df):\n",
        "  df['fare'].fillna(df['fare'].mean(), inplace=True)\n",
        "\n",
        "  print(df['fare'].min())\n",
        "  min_fair = np.min(df['fare'])\n",
        "  max_fair = np.max(df['fare'])\n",
        "  print(min_fair, max_fair)\n",
        "  print(np.ptp(df['fare']))\n",
        "  \n",
        "df = build_titanic()\n",
        "fare_stats(df.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUC9GJyrJkfJ"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Create a function named fare_min_max_scaled_np that uses NumPy to scale the attributes using the min-max formula given above.\n",
        "\n",
        "* You can only use NumPy to do the calculations.\n",
        "* Add the new values to an attribute named fare_mms \n",
        "* You must return the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "By-jRaozVfyC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total rows 2207\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "      <th>embarked</th>\n",
              "      <th>country</th>\n",
              "      <th>ticketno</th>\n",
              "      <th>fare</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>survived</th>\n",
              "      <th>sid</th>\n",
              "      <th>fare_mms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Abbing, Mr. Anthony</td>\n",
              "      <td>male</td>\n",
              "      <td>42.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>5547.0</td>\n",
              "      <td>7.11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1870</td>\n",
              "      <td>0.008014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Abbott, Mr. Eugene Joseph</td>\n",
              "      <td>male</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>2673.0</td>\n",
              "      <td>20.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1899</td>\n",
              "      <td>0.033435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Abbott, Mr. Rossmore Edward</td>\n",
              "      <td>male</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>2673.0</td>\n",
              "      <td>20.05</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1896</td>\n",
              "      <td>0.033435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Abbott, Mrs. Rhoda Mary 'Rosa'</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>2673.0</td>\n",
              "      <td>20.05</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1873</td>\n",
              "      <td>0.033435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Abelseth, Miss. Karen Marie</td>\n",
              "      <td>female</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>Norway</td>\n",
              "      <td>348125.0</td>\n",
              "      <td>7.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1896</td>\n",
              "      <td>0.008054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2203</th>\n",
              "      <td>2204</td>\n",
              "      <td>Yearsley, Mr. Harry</td>\n",
              "      <td>male</td>\n",
              "      <td>40.0</td>\n",
              "      <td>victualling crew</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yes</td>\n",
              "      <td>1872</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2204</th>\n",
              "      <td>2205</td>\n",
              "      <td>Young, Mr. Francis James</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>engineering crew</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>1880</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2205</th>\n",
              "      <td>2206</td>\n",
              "      <td>Zanetti, Sig. Minio</td>\n",
              "      <td>male</td>\n",
              "      <td>20.0</td>\n",
              "      <td>restaurant staff</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>1892</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2206</th>\n",
              "      <td>2207</td>\n",
              "      <td>Zarracchi, Sig. L.</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>restaurant staff</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>1886</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2207</th>\n",
              "      <td>2208</td>\n",
              "      <td>Jack Dawson</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1884</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2208 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                            name  gender   age             class embarked        country  ticketno   fare  sibsp  parch survived   sid  fare_mms\n",
              "0        1             Abbing, Mr. Anthony    male  42.0               3rd        S  United States    5547.0   7.11    0.0    0.0       no  1870  0.008014\n",
              "1        2       Abbott, Mr. Eugene Joseph    male  13.0               3rd        S  United States    2673.0  20.05    0.0    2.0       no  1899  0.033435\n",
              "2        3     Abbott, Mr. Rossmore Edward    male  16.0               3rd        S  United States    2673.0  20.05    1.0    1.0       no  1896  0.033435\n",
              "3        4  Abbott, Mrs. Rhoda Mary 'Rosa'  female  39.0               3rd        S        England    2673.0  20.05    1.0    1.0      yes  1873  0.033435\n",
              "4        5     Abelseth, Miss. Karen Marie  female  16.0               3rd        S         Norway  348125.0   7.13    0.0    0.0      yes  1896  0.008054\n",
              "...    ...                             ...     ...   ...               ...      ...            ...       ...    ...    ...    ...      ...   ...       ...\n",
              "2203  2204             Yearsley, Mr. Harry    male  40.0  victualling crew        S        England       NaN    NaN    NaN    NaN      yes  1872       NaN\n",
              "2204  2205        Young, Mr. Francis James    male  32.0  engineering crew        S        England       NaN    NaN    NaN    NaN       no  1880       NaN\n",
              "2205  2206             Zanetti, Sig. Minio    male  20.0  restaurant staff        S        England       NaN    NaN    NaN    NaN       no  1892       NaN\n",
              "2206  2207              Zarracchi, Sig. L.    male  26.0  restaurant staff        S        England       NaN    NaN    NaN    NaN       no  1886       NaN\n",
              "2207  2208                     Jack Dawson    male  28.0               NaN      NaN            NaN       NaN    NaN    NaN    NaN      NaN  1884       NaN\n",
              "\n",
              "[2208 rows x 14 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def fare_min_max_scaled_np(df):\n",
        "  min_fair = np.min(df['fare'])\n",
        "  max_fair = np.max(df['fare'])\n",
        "  df['fare_mms'] = df.fare.apply(lambda f: (f - min_fair) / (max_fair - min_fair))\n",
        "  return df\n",
        "\n",
        "df = build_titanic()\n",
        "fare_min_max_scaled_np(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49lP206MJzDU"
      },
      "source": [
        "\n",
        "Be sure to write your own test for fare_min_max_scaled_np function. How will you confirm that the operation succeeded?\n",
        "\n",
        "```\n",
        "def test_fare_mms(df):\n",
        "  pass\n",
        "\n",
        "test_fare_mms(df.copy())\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zq/gn09x0d53r74hd7z0lp249cr0000gp/T/ipykernel_33131/4008974831.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  return df.dropna()[~(df['recalculated_fare'].dropna() == df['fare'].dropna())]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "      <th>embarked</th>\n",
              "      <th>country</th>\n",
              "      <th>ticketno</th>\n",
              "      <th>fare</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>survived</th>\n",
              "      <th>sid</th>\n",
              "      <th>fare_mms</th>\n",
              "      <th>recalculated_fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>127</td>\n",
              "      <td>Blackwell, Mr. Stephen Weart</td>\n",
              "      <td>male</td>\n",
              "      <td>45.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>113784.0</td>\n",
              "      <td>35.1000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1867</td>\n",
              "      <td>0.063001</td>\n",
              "      <td>35.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>Brewe, Dr. Arthur Jackson</td>\n",
              "      <td>male</td>\n",
              "      <td>46.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>C</td>\n",
              "      <td>United States</td>\n",
              "      <td>112379.0</td>\n",
              "      <td>39.1200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1866</td>\n",
              "      <td>0.070899</td>\n",
              "      <td>39.1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>203</td>\n",
              "      <td>Carraú-Esteves, Mr. José Pedro</td>\n",
              "      <td>male</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>Uruguay</td>\n",
              "      <td>113059.0</td>\n",
              "      <td>47.0200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1895</td>\n",
              "      <td>0.086418</td>\n",
              "      <td>47.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>204</td>\n",
              "      <td>Carrau, Mr. Francisco Mauro Severiano</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>Uruguay</td>\n",
              "      <td>113059.0</td>\n",
              "      <td>47.0200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1885</td>\n",
              "      <td>0.086418</td>\n",
              "      <td>47.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>218</td>\n",
              "      <td>Chaffee, Mr. Herbert Fuller</td>\n",
              "      <td>male</td>\n",
              "      <td>46.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>5734.0</td>\n",
              "      <td>61.0306</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1866</td>\n",
              "      <td>0.113942</td>\n",
              "      <td>61.0306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>219</td>\n",
              "      <td>Chaffee, Mrs. Carrie Constance</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>5734.0</td>\n",
              "      <td>61.0306</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1865</td>\n",
              "      <td>0.113942</td>\n",
              "      <td>61.0306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>220</td>\n",
              "      <td>Chambers, Mr. Norman Campbell</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>113806.0</td>\n",
              "      <td>53.0200</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1885</td>\n",
              "      <td>0.098205</td>\n",
              "      <td>53.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>221</td>\n",
              "      <td>Chambers, Mrs. Bertha</td>\n",
              "      <td>female</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>113806.0</td>\n",
              "      <td>53.0200</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1880</td>\n",
              "      <td>0.098205</td>\n",
              "      <td>53.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>305</td>\n",
              "      <td>Davies, Master. John Morgan jr</td>\n",
              "      <td>male</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2nd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>33112.0</td>\n",
              "      <td>36.1500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1904</td>\n",
              "      <td>0.065064</td>\n",
              "      <td>36.1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>311</td>\n",
              "      <td>Davies, Mrs. Agnes</td>\n",
              "      <td>female</td>\n",
              "      <td>48.0</td>\n",
              "      <td>2nd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>33112.0</td>\n",
              "      <td>36.1500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1864</td>\n",
              "      <td>0.065064</td>\n",
              "      <td>36.1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>360</td>\n",
              "      <td>Duff Gordon, Sir. Cosmo Edmund</td>\n",
              "      <td>male</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>C</td>\n",
              "      <td>England</td>\n",
              "      <td>11755.0</td>\n",
              "      <td>39.1200</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1863</td>\n",
              "      <td>0.070899</td>\n",
              "      <td>39.1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>421</td>\n",
              "      <td>Frölicher, Miss. Hedwig Margaritha</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>C</td>\n",
              "      <td>Switzerland</td>\n",
              "      <td>13568.0</td>\n",
              "      <td>49.1000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1890</td>\n",
              "      <td>0.090504</td>\n",
              "      <td>49.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>427</td>\n",
              "      <td>Futrelle, Mr. Jacques Heath</td>\n",
              "      <td>male</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>113803.0</td>\n",
              "      <td>53.0200</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1875</td>\n",
              "      <td>0.098205</td>\n",
              "      <td>53.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>428</td>\n",
              "      <td>Futrelle, Mrs. Lily May</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>113803.0</td>\n",
              "      <td>53.0200</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1877</td>\n",
              "      <td>0.098205</td>\n",
              "      <td>53.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>437</td>\n",
              "      <td>Gee, Mr. Arthur H.</td>\n",
              "      <td>male</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>111320.0</td>\n",
              "      <td>38.1000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1865</td>\n",
              "      <td>0.068895</td>\n",
              "      <td>38.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>462</td>\n",
              "      <td>Goodwin, Master. Harold Victor</td>\n",
              "      <td>male</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>2144.0</td>\n",
              "      <td>46.1800</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1903</td>\n",
              "      <td>0.084768</td>\n",
              "      <td>46.1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>463</td>\n",
              "      <td>Goodwin, Master. Sidney Leslie</td>\n",
              "      <td>male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>2144.0</td>\n",
              "      <td>46.1800</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1911</td>\n",
              "      <td>0.084768</td>\n",
              "      <td>46.1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>464</td>\n",
              "      <td>Goodwin, Master. William Frederick</td>\n",
              "      <td>male</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>2144.0</td>\n",
              "      <td>46.1800</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1901</td>\n",
              "      <td>0.084768</td>\n",
              "      <td>46.1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>465</td>\n",
              "      <td>Goodwin, Miss. Jessie Allis</td>\n",
              "      <td>female</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>2144.0</td>\n",
              "      <td>46.1800</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1902</td>\n",
              "      <td>0.084768</td>\n",
              "      <td>46.1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>466</td>\n",
              "      <td>Goodwin, Miss. Lillian Amy</td>\n",
              "      <td>female</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>2144.0</td>\n",
              "      <td>46.1800</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1896</td>\n",
              "      <td>0.084768</td>\n",
              "      <td>46.1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>467</td>\n",
              "      <td>Goodwin, Mr. Charles Edward</td>\n",
              "      <td>male</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>2144.0</td>\n",
              "      <td>46.1800</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1898</td>\n",
              "      <td>0.084768</td>\n",
              "      <td>46.1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>468</td>\n",
              "      <td>Goodwin, Mr. Frederick Joseph</td>\n",
              "      <td>male</td>\n",
              "      <td>42.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>2144.0</td>\n",
              "      <td>46.1800</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1870</td>\n",
              "      <td>0.084768</td>\n",
              "      <td>46.1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>469</td>\n",
              "      <td>Goodwin, Mrs. Augusta</td>\n",
              "      <td>female</td>\n",
              "      <td>43.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>2144.0</td>\n",
              "      <td>46.1800</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1869</td>\n",
              "      <td>0.084768</td>\n",
              "      <td>46.1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>527</td>\n",
              "      <td>Head, Mr. Christopher</td>\n",
              "      <td>male</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>113038.0</td>\n",
              "      <td>42.1000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1870</td>\n",
              "      <td>0.076753</td>\n",
              "      <td>42.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>549</td>\n",
              "      <td>Hippach, Miss. Jean Gertrude</td>\n",
              "      <td>female</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>C</td>\n",
              "      <td>United States</td>\n",
              "      <td>111361.0</td>\n",
              "      <td>57.1907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1895</td>\n",
              "      <td>0.106399</td>\n",
              "      <td>57.1907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>550</td>\n",
              "      <td>Hippach, Mrs. Ida Sophia</td>\n",
              "      <td>female</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>C</td>\n",
              "      <td>United States</td>\n",
              "      <td>111361.0</td>\n",
              "      <td>57.1907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1868</td>\n",
              "      <td>0.106399</td>\n",
              "      <td>57.1907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>603</td>\n",
              "      <td>Jensen, Mr. Niels Rasmus</td>\n",
              "      <td>male</td>\n",
              "      <td>48.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>Denmark</td>\n",
              "      <td>350048.0</td>\n",
              "      <td>7.0101</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1864</td>\n",
              "      <td>0.007818</td>\n",
              "      <td>7.0101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>694</td>\n",
              "      <td>Laroche, Miss. Louise</td>\n",
              "      <td>female</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2nd</td>\n",
              "      <td>C</td>\n",
              "      <td>France</td>\n",
              "      <td>2123.0</td>\n",
              "      <td>41.1107</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1911</td>\n",
              "      <td>0.074809</td>\n",
              "      <td>41.1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>695</td>\n",
              "      <td>Laroche, Miss. Simonne Marie Anne Andrée</td>\n",
              "      <td>female</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2nd</td>\n",
              "      <td>C</td>\n",
              "      <td>France</td>\n",
              "      <td>2123.0</td>\n",
              "      <td>41.1107</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1909</td>\n",
              "      <td>0.074809</td>\n",
              "      <td>41.1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>696</td>\n",
              "      <td>Laroche, Mr. Joseph Philippe Lemercier</td>\n",
              "      <td>male</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2nd</td>\n",
              "      <td>C</td>\n",
              "      <td>France</td>\n",
              "      <td>2123.0</td>\n",
              "      <td>41.1107</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1887</td>\n",
              "      <td>0.074809</td>\n",
              "      <td>41.1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>697</td>\n",
              "      <td>Laroche, Mrs. Juliette Marie Louise</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2nd</td>\n",
              "      <td>C</td>\n",
              "      <td>France</td>\n",
              "      <td>2123.0</td>\n",
              "      <td>41.1107</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1890</td>\n",
              "      <td>0.074809</td>\n",
              "      <td>41.1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738</th>\n",
              "      <td>739</td>\n",
              "      <td>Loring, Mr. Joseph Holland</td>\n",
              "      <td>male</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>113801.0</td>\n",
              "      <td>45.1000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1882</td>\n",
              "      <td>0.082646</td>\n",
              "      <td>45.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>744</td>\n",
              "      <td>Lundahl, Mr. Johan Svensson</td>\n",
              "      <td>male</td>\n",
              "      <td>50.0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>S</td>\n",
              "      <td>Sweden</td>\n",
              "      <td>347743.0</td>\n",
              "      <td>7.0101</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1862</td>\n",
              "      <td>0.007818</td>\n",
              "      <td>7.0101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>773</th>\n",
              "      <td>774</td>\n",
              "      <td>Marvin, Mr. Daniel Warner</td>\n",
              "      <td>male</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>113773.0</td>\n",
              "      <td>53.0200</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1894</td>\n",
              "      <td>0.098205</td>\n",
              "      <td>53.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>774</th>\n",
              "      <td>775</td>\n",
              "      <td>Marvin, Mrs. Mary Graham Carmichael</td>\n",
              "      <td>female</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>Scotland</td>\n",
              "      <td>113773.0</td>\n",
              "      <td>53.0200</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1894</td>\n",
              "      <td>0.098205</td>\n",
              "      <td>53.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>824</td>\n",
              "      <td>Mock, Mr. Philipp Edmund</td>\n",
              "      <td>male</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>C</td>\n",
              "      <td>United States</td>\n",
              "      <td>13236.0</td>\n",
              "      <td>57.1500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1882</td>\n",
              "      <td>0.106319</td>\n",
              "      <td>57.1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876</th>\n",
              "      <td>877</td>\n",
              "      <td>Nicholls, Mr. Joseph Charles</td>\n",
              "      <td>male</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2nd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>33112.0</td>\n",
              "      <td>36.1500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1893</td>\n",
              "      <td>0.065064</td>\n",
              "      <td>36.1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>920</td>\n",
              "      <td>Østby, Miss. Helen Ragnhild</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>113509.0</td>\n",
              "      <td>61.1907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1890</td>\n",
              "      <td>0.114257</td>\n",
              "      <td>61.1907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>920</th>\n",
              "      <td>921</td>\n",
              "      <td>Ostby, Mr. Engelhart Cornelius</td>\n",
              "      <td>male</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>113509.0</td>\n",
              "      <td>61.1907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1848</td>\n",
              "      <td>0.114257</td>\n",
              "      <td>61.1907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>1006</td>\n",
              "      <td>Rheims, Mr. George Alexander Lucien</td>\n",
              "      <td>male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>C</td>\n",
              "      <td>United States</td>\n",
              "      <td>17607.0</td>\n",
              "      <td>39.1200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1879</td>\n",
              "      <td>0.070899</td>\n",
              "      <td>39.1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1086</th>\n",
              "      <td>1087</td>\n",
              "      <td>Schabert, Mrs. Emma</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>C</td>\n",
              "      <td>Germany</td>\n",
              "      <td>13236.0</td>\n",
              "      <td>57.1500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1877</td>\n",
              "      <td>0.106319</td>\n",
              "      <td>57.1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1106</th>\n",
              "      <td>1107</td>\n",
              "      <td>Silvey, Mrs. Alice Gray</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>C</td>\n",
              "      <td>United States</td>\n",
              "      <td>13507.0</td>\n",
              "      <td>55.1800</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1873</td>\n",
              "      <td>0.102449</td>\n",
              "      <td>55.1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1107</th>\n",
              "      <td>1108</td>\n",
              "      <td>Silvey, Mr. William Baird</td>\n",
              "      <td>male</td>\n",
              "      <td>51.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>C</td>\n",
              "      <td>United States</td>\n",
              "      <td>13507.0</td>\n",
              "      <td>55.1800</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>no</td>\n",
              "      <td>1861</td>\n",
              "      <td>0.102449</td>\n",
              "      <td>55.1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1109</th>\n",
              "      <td>1110</td>\n",
              "      <td>Simonius-Blumer, Mr. Colonel (Oberst) Alfons</td>\n",
              "      <td>male</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>Switzerland</td>\n",
              "      <td>13213.0</td>\n",
              "      <td>35.1000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1856</td>\n",
              "      <td>0.063001</td>\n",
              "      <td>35.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1110</th>\n",
              "      <td>1111</td>\n",
              "      <td>Sincock, Miss. Maude</td>\n",
              "      <td>female</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2nd</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>33112.0</td>\n",
              "      <td>36.1500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1892</td>\n",
              "      <td>0.065064</td>\n",
              "      <td>36.1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128</th>\n",
              "      <td>1129</td>\n",
              "      <td>Sloper, Mr. William Thompson</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>United States</td>\n",
              "      <td>113788.0</td>\n",
              "      <td>35.1000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1884</td>\n",
              "      <td>0.063001</td>\n",
              "      <td>35.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1305</th>\n",
              "      <td>1306</td>\n",
              "      <td>Woolner, Mr. Hugh</td>\n",
              "      <td>male</td>\n",
              "      <td>46.0</td>\n",
              "      <td>1st</td>\n",
              "      <td>S</td>\n",
              "      <td>England</td>\n",
              "      <td>19947.0</td>\n",
              "      <td>35.1000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1866</td>\n",
              "      <td>0.063001</td>\n",
              "      <td>35.1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                          name  gender   age class embarked        country  ticketno     fare  sibsp  parch survived   sid  fare_mms  recalculated_fare\n",
              "126    127                  Blackwell, Mr. Stephen Weart    male  45.0   1st        S  United States  113784.0  35.1000    0.0    0.0       no  1867  0.063001            35.1000\n",
              "149    150                     Brewe, Dr. Arthur Jackson    male  46.0   1st        C  United States  112379.0  39.1200    0.0    0.0       no  1866  0.070899            39.1200\n",
              "202    203                Carraú-Esteves, Mr. José Pedro    male  17.0   1st        S        Uruguay  113059.0  47.0200    0.0    0.0       no  1895  0.086418            47.0200\n",
              "203    204         Carrau, Mr. Francisco Mauro Severiano    male  27.0   1st        S        Uruguay  113059.0  47.0200    0.0    0.0       no  1885  0.086418            47.0200\n",
              "217    218                   Chaffee, Mr. Herbert Fuller    male  46.0   1st        S  United States    5734.0  61.0306    1.0    0.0       no  1866  0.113942            61.0306\n",
              "218    219                Chaffee, Mrs. Carrie Constance  female  47.0   1st        S  United States    5734.0  61.0306    1.0    0.0      yes  1865  0.113942            61.0306\n",
              "219    220                 Chambers, Mr. Norman Campbell    male  27.0   1st        S  United States  113806.0  53.0200    1.0    0.0      yes  1885  0.098205            53.0200\n",
              "220    221                         Chambers, Mrs. Bertha  female  32.0   1st        S  United States  113806.0  53.0200    1.0    0.0      yes  1880  0.098205            53.0200\n",
              "304    305                Davies, Master. John Morgan jr    male   8.0   2nd        S        England   33112.0  36.1500    1.0    1.0      yes  1904  0.065064            36.1500\n",
              "310    311                            Davies, Mrs. Agnes  female  48.0   2nd        S        England   33112.0  36.1500    0.0    2.0      yes  1864  0.065064            36.1500\n",
              "359    360                Duff Gordon, Sir. Cosmo Edmund    male  49.0   1st        C        England   11755.0  39.1200    1.0    0.0      yes  1863  0.070899            39.1200\n",
              "420    421            Frölicher, Miss. Hedwig Margaritha  female  22.0   1st        C    Switzerland   13568.0  49.1000    0.0    2.0      yes  1890  0.090504            49.1000\n",
              "426    427                   Futrelle, Mr. Jacques Heath    male  37.0   1st        S        England  113803.0  53.0200    1.0    0.0       no  1875  0.098205            53.0200\n",
              "427    428                       Futrelle, Mrs. Lily May  female  35.0   1st        S        England  113803.0  53.0200    1.0    0.0      yes  1877  0.098205            53.0200\n",
              "436    437                            Gee, Mr. Arthur H.    male  47.0   1st        S        England  111320.0  38.1000    0.0    0.0       no  1865  0.068895            38.1000\n",
              "461    462                Goodwin, Master. Harold Victor    male   9.0   3rd        S        England    2144.0  46.1800    5.0    2.0       no  1903  0.084768            46.1800\n",
              "462    463                Goodwin, Master. Sidney Leslie    male   1.0   3rd        S        England    2144.0  46.1800    5.0    2.0       no  1911  0.084768            46.1800\n",
              "463    464            Goodwin, Master. William Frederick    male  11.0   3rd        S        England    2144.0  46.1800    5.0    2.0       no  1901  0.084768            46.1800\n",
              "464    465                   Goodwin, Miss. Jessie Allis  female  10.0   3rd        S        England    2144.0  46.1800    5.0    2.0       no  1902  0.084768            46.1800\n",
              "465    466                    Goodwin, Miss. Lillian Amy  female  16.0   3rd        S        England    2144.0  46.1800    5.0    2.0       no  1896  0.084768            46.1800\n",
              "466    467                   Goodwin, Mr. Charles Edward    male  14.0   3rd        S        England    2144.0  46.1800    5.0    2.0       no  1898  0.084768            46.1800\n",
              "467    468                 Goodwin, Mr. Frederick Joseph    male  42.0   3rd        S        England    2144.0  46.1800    1.0    6.0       no  1870  0.084768            46.1800\n",
              "468    469                         Goodwin, Mrs. Augusta  female  43.0   3rd        S        England    2144.0  46.1800    1.0    6.0       no  1869  0.084768            46.1800\n",
              "526    527                         Head, Mr. Christopher    male  42.0   1st        S        England  113038.0  42.1000    0.0    0.0       no  1870  0.076753            42.1000\n",
              "548    549                  Hippach, Miss. Jean Gertrude  female  17.0   1st        C  United States  111361.0  57.1907    0.0    1.0      yes  1895  0.106399            57.1907\n",
              "549    550                      Hippach, Mrs. Ida Sophia  female  44.0   1st        C  United States  111361.0  57.1907    0.0    1.0      yes  1868  0.106399            57.1907\n",
              "602    603                      Jensen, Mr. Niels Rasmus    male  48.0   3rd        S        Denmark  350048.0   7.0101    0.0    0.0       no  1864  0.007818             7.0101\n",
              "693    694                         Laroche, Miss. Louise  female   1.0   2nd        C         France    2123.0  41.1107    1.0    2.0      yes  1911  0.074809            41.1107\n",
              "694    695      Laroche, Miss. Simonne Marie Anne Andrée  female   3.0   2nd        C         France    2123.0  41.1107    1.0    2.0      yes  1909  0.074809            41.1107\n",
              "695    696        Laroche, Mr. Joseph Philippe Lemercier    male  25.0   2nd        C         France    2123.0  41.1107    1.0    2.0       no  1887  0.074809            41.1107\n",
              "696    697           Laroche, Mrs. Juliette Marie Louise  female  22.0   2nd        C         France    2123.0  41.1107    1.0    2.0      yes  1890  0.074809            41.1107\n",
              "738    739                    Loring, Mr. Joseph Holland    male  30.0   1st        S  United States  113801.0  45.1000    0.0    0.0       no  1882  0.082646            45.1000\n",
              "743    744                   Lundahl, Mr. Johan Svensson    male  50.0   3rd        S         Sweden  347743.0   7.0101    0.0    0.0       no  1862  0.007818             7.0101\n",
              "773    774                     Marvin, Mr. Daniel Warner    male  18.0   1st        S  United States  113773.0  53.0200    1.0    0.0       no  1894  0.098205            53.0200\n",
              "774    775           Marvin, Mrs. Mary Graham Carmichael  female  18.0   1st        S       Scotland  113773.0  53.0200    1.0    0.0      yes  1894  0.098205            53.0200\n",
              "823    824                      Mock, Mr. Philipp Edmund    male  30.0   1st        C  United States   13236.0  57.1500    1.0    0.0      yes  1882  0.106319            57.1500\n",
              "876    877                  Nicholls, Mr. Joseph Charles    male  19.0   2nd        S        England   33112.0  36.1500    1.0    1.0       no  1893  0.065064            36.1500\n",
              "919    920                   Østby, Miss. Helen Ragnhild  female  22.0   1st        S  United States  113509.0  61.1907    0.0    1.0      yes  1890  0.114257            61.1907\n",
              "920    921                Ostby, Mr. Engelhart Cornelius    male  64.0   1st        S  United States  113509.0  61.1907    0.0    1.0       no  1848  0.114257            61.1907\n",
              "1005  1006           Rheims, Mr. George Alexander Lucien    male  33.0   1st        C  United States   17607.0  39.1200    0.0    0.0      yes  1879  0.070899            39.1200\n",
              "1086  1087                           Schabert, Mrs. Emma  female  35.0   1st        C        Germany   13236.0  57.1500    1.0    0.0      yes  1877  0.106319            57.1500\n",
              "1106  1107                       Silvey, Mrs. Alice Gray  female  39.0   1st        C  United States   13507.0  55.1800    1.0    0.0      yes  1873  0.102449            55.1800\n",
              "1107  1108                     Silvey, Mr. William Baird    male  51.0   1st        C  United States   13507.0  55.1800    1.0    0.0       no  1861  0.102449            55.1800\n",
              "1109  1110  Simonius-Blumer, Mr. Colonel (Oberst) Alfons    male  56.0   1st        S    Switzerland   13213.0  35.1000    0.0    0.0      yes  1856  0.063001            35.1000\n",
              "1110  1111                          Sincock, Miss. Maude  female  20.0   2nd        S        England   33112.0  36.1500    0.0    0.0      yes  1892  0.065064            36.1500\n",
              "1128  1129                  Sloper, Mr. William Thompson    male  28.0   1st        S  United States  113788.0  35.1000    0.0    0.0      yes  1884  0.063001            35.1000\n",
              "1305  1306                             Woolner, Mr. Hugh    male  46.0   1st        S        England   19947.0  35.1000    0.0    0.0      yes  1866  0.063001            35.1000"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def test_mms(df):  \n",
        "\tmin_fair = np.min(df['fare'])\n",
        "\tmax_fair = np.max(df['fare'])\n",
        "\tfare = df.fare_mms.dropna().apply(lambda mms: mms * (max_fair - min_fair) + min_fair)\n",
        "\tdf['recalculated_fare'] = fare\n",
        "\treturn df.dropna()[~(df['recalculated_fare'].dropna() == df['fare'].dropna())]\n",
        "\treturn (fare == df['fare'].dropna()).all()\n",
        "\n",
        "result = test_mms(df.copy())\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22pIGz5OJ4T_"
      },
      "source": [
        "**Sklearn's Min-Max Scalar**\n",
        "\n",
        "Sklearn also provides a simple minmax_scale function. We can use it to confirm our results as well. Below also shows how sklearn uses the fit & transform methods on its MinMaxScaler. In this case, fit would calculate the min and max first; transform then applies the formula to all the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Cpq9irT9KABJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      fare  fare_scaled  fare_scaled2\n",
            "0   7.1100     0.008014      0.008014\n",
            "1  20.0500     0.033435      0.033435\n",
            "2  20.0500     0.033435      0.033435\n",
            "3  20.0500     0.033435      0.033435\n",
            "4   7.1300     0.008054      0.008054\n",
            "5   7.1300     0.008054      0.008054\n",
            "6  24.0000     0.041195      0.041195\n",
            "7  24.0000     0.041195      0.041195\n",
            "8  18.1509     0.029704      0.029704\n",
            "9   7.1806     0.008153      0.008153\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def fare_min_max_scaled(df):\n",
        "  df['fare_scaled'] = minmax_scale(df['fare'])\n",
        "\n",
        "  # fit & transform way\n",
        "  scaler = MinMaxScaler()\n",
        "  s_values = scaler.fit_transform(df['fare'].values.reshape(-1,1))\n",
        "  df['fare_scaled2'] = s_values\n",
        "  print(df['fare fare_scaled fare_scaled2'.split()].head(10))\n",
        "\n",
        "fare_min_max_scaled(df.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PROjJb8lKDY1"
      },
      "source": [
        "**Mean Normalization Mean Centering**\n",
        "\n",
        "Another version of Min-Max Scaling is named mean normalization. In this case, the mean is subtracted from each value (rather than the minimum value).\n",
        "\n",
        "Note that Mean centering is the subtraction part -- and it can be done without any further scaling. The dividing by the data range provides the scaling part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJzUIZ6VKOUD"
      },
      "source": [
        "**Z-Score Scaling; Standardization**\n",
        "\n",
        "Sometimes it's important that an attribute has certain statistical requirements. We can 'normalize' (here normalize is used in the statistical sense) the values such that the data is centered at 0 with a standard deviation of 1. This technique is called z-score scaling or just standardization or z-score normalization.\n",
        "\n",
        "Z-score scaling is done using the following formula:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1p2OVmwJvXRr-YTkxiOEtmDu3rHLRTngr)\n",
        "\n",
        "Here is the original feature vector, is the mean of that feature vector, and σ is its standard deviation. By subtracting the mean from the distribution, you are essentially shifting it towards left or right by amount equal to mean. By dividing by the standard deviation σ, you are changing the shape of distribution.\n",
        "\n",
        "The new standard deviation of this standardized distribution is 1 and μ = 0.\n",
        "With sklearn, you can do this transformation using the scale function or the StandardScaler class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fYeeWZLeKW9k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      fare    fare_z   fare_z2\n",
            "0   7.1100 -0.503660 -0.503660\n",
            "1  20.0500 -0.255802 -0.255802\n",
            "2  20.0500 -0.255802 -0.255802\n",
            "3  20.0500 -0.255802 -0.255802\n",
            "4   7.1300 -0.503277 -0.503277\n",
            "5   7.1300 -0.503277 -0.503277\n",
            "6  24.0000 -0.180142 -0.180142\n",
            "7  24.0000 -0.180142 -0.180142\n",
            "8  18.1509 -0.292178 -0.292178\n",
            "9   7.1806 -0.502308 -0.502308\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def fare_z_scaled(df):\n",
        "\n",
        "  # simple way\n",
        "  df['fare_z'] = scale(df['fare'])\n",
        "\n",
        "  # fit & transform way\n",
        "  scaler = StandardScaler()\n",
        "  s_values = scaler.fit_transform(df['fare'].values.reshape(-1,1))\n",
        "  df['fare_z2'] = s_values\n",
        "  print(df['fare fare_z fare_z2'.split()].head(10))\n",
        "\n",
        "fare_z_scaled(df.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRuWiKeCKb-D"
      },
      "source": [
        "#**Outlier Detection**\n",
        "\n",
        "Having outliers in the dataset, can affect scaling. Although there are machine learning algorithms to help with outlier detection, there are a couple of simple approaches.\n",
        "<br><br>\n",
        "\n",
        "**Removing the outliers**\n",
        "\n",
        "A very quick way to isolate the outliers is to remove those values that are over 2.5 standard deviations away from the rest of the values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pJyy9e-wKZk1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38 outliers: min 211.06 max 512.06\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def find_fare_outliers(df):\n",
        "  df['fare'].fillna(df['fare'].mean(), inplace=True)\n",
        "  data = df['fare'].values.reshape(-1,1)\n",
        "\n",
        "  m = np.mean(data)\n",
        "  s = np.std(data)\n",
        "  \n",
        "  # identify outliers\n",
        "  cut_off = s * 3.5 # pick any number of standard deviations (usually >= 2.0)\n",
        "  lower, upper = m - cut_off, m + cut_off\n",
        "  # identify outliers\n",
        "  outliers = [x for x in data if x < lower or x > upper]\n",
        "  print(\"{:d} outliers: min {:.2f} max {:.2f}\".format(len(outliers), np.min(outliers),\n",
        "np.max(outliers)))\n",
        "  \n",
        "  # remove outliers\n",
        "  # outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
        "\n",
        "find_fare_outliers(df.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhMOb8MVKt8X"
      },
      "source": [
        "You can actually remove the outliers by uncommenting the last line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDLpURYYKwc2"
      },
      "source": [
        "**Robust Scaling**\n",
        "\n",
        "The mean is highly sensitive to outliers. Sklearn's RobustScaler using IQR (interquartile range) to keep all values between the 25th and 75 quartile. It subtracts the column's median and divides by the interquartile range.\n",
        "\n",
        "This scales the data using\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1U06oPdGbrrt9QVjmX27vdNLaa6GNtO6c)\n",
        "\n",
        "RobustScaler can be used when you want to reduce the effects of having many outliers. However, removing unimportant outliers (see above) should also be done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUpbgixxK9hC"
      },
      "source": [
        "**Confused ?**\n",
        "\n",
        "It's not necessarily easy to know which technique to use. The best strategy is to evaluate models with the data prepared using different techniques. Sometimes, it's a combination of a few of the methods.\n",
        "\n",
        "There are a few guidelines to help make a first approximation:\n",
        "* if the distribution of the quantity is normal, then it should be standardized,\n",
        "* if the distribution is not normal, the data should be normalized. This applies if the range of quantity values is large (10s, 100s, etc.) or small (0.01, 0.0001).\n",
        "\n",
        "**Min-Max Scaler**\n",
        "\n",
        "* Re-scales to predetermined range [0–1]\n",
        "* Typical neural network algorithm require data that on a 0-1 scale.\n",
        "* Doesn’t change distribution’s center (doesn’t correct skewness)\n",
        "* The distribution of the feature (or any transformations of the feature ) isn’t Gaussian\n",
        "* Feature falls within a bounded interval (sensitive to outliers)\n",
        "\n",
        "**Standard Scaler**\n",
        "* Shifts distribution’s mean to 0 and unit variance\n",
        "* No predetermined range\n",
        "* Best to use on data that is approximately normally distributed clustering, PCA (those that rely on using variance)\n",
        "\n",
        "**Robust Scaler**\n",
        "* 0 mean and unit variance\n",
        "* Use of quartile ranges makes this less sensitive to (a few) outliers • No predetermined range"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4yIEtRhLsea"
      },
      "source": [
        "**Custom Cleaning**\n",
        "\n",
        "Sometimes, it's necessary to provide cleaning beyond what a library has to offer. Sklearn's FunctionTransformer can be used in these situations. For example, the dataset has an 'sid' field which is actually a string representing the birth year of the person on board the Titanic. If you wanted to do 'math' on that field, a FunctionTransformer could be used to convert that string into a number:\n",
        "\n",
        "The following code (you should implement it) demonstrates how to convert a string field (sid) to an integer. Once that is done, the field can be used like any valid numeric attribute:\n",
        "\n",
        "\n",
        "> **Coder's Log:** You may see references to integer (int for short) or floating point (float for short). These are different ways to represent numbers. A floating point is a number with a decimal point (e.g 123.45) and an integer has no decimal place (whole numbers). Floating point numbers have more precision.\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def string_to_float(v):\n",
        "  # v is an array of values\n",
        "  return v.astype(np.float)\n",
        "\n",
        "def string_to_int(v):\n",
        "  # v is an array of values\n",
        "  return v.astype(np.int)\n",
        "\n",
        "def clean_sid(df):\n",
        "\n",
        "  # first clean any missing values\n",
        "  mode = df['sid'].mode()[0]\n",
        "  df['sid'].fillna(mode, inplace=True)\n",
        "\n",
        "  # because 'sid' is pandas StringArray, reshape(-1,1) won't work\n",
        "  # print(type(df['sid'].values))\n",
        "\n",
        "  # either of these will work\n",
        "  values = df['sid'].values\n",
        "  # OR\n",
        "  # attribute = ['sid']\n",
        "  # values = df[attribute]\n",
        "  \n",
        "  transformer = FunctionTransformer(string_to_int)\n",
        "  df['sid'] = transformer.fit_transform(values)\n",
        "  return df\n",
        "```\n",
        "\n",
        "The following code cell demonstrates the custom cleaning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TJkIpExcXt20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "invalid math\n",
            "   id                            name  gender   age class embarked        country  ticketno   fare  sibsp  parch survived   sid  fare_mms\n",
            "0   1             Abbing, Mr. Anthony    male  42.0   3rd        S  United States    5547.0   7.11    0.0    0.0       no  42.0  0.008014\n",
            "1   2       Abbott, Mr. Eugene Joseph    male  13.0   3rd        S  United States    2673.0  20.05    0.0    2.0       no  13.0  0.033435\n",
            "2   3     Abbott, Mr. Rossmore Edward    male  16.0   3rd        S  United States    2673.0  20.05    1.0    1.0       no  16.0  0.033435\n",
            "3   4  Abbott, Mrs. Rhoda Mary 'Rosa'  female  39.0   3rd        S        England    2673.0  20.05    1.0    1.0      yes  39.0  0.033435\n",
            "4   5     Abelseth, Miss. Karen Marie  female  16.0   3rd        S         Norway  348125.0   7.13    0.0    0.0      yes  16.0  0.008054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zq/gn09x0d53r74hd7z0lp249cr0000gp/T/ipykernel_33131/1155584546.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  return v.astype(np.float)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def string_to_float(v):\n",
        "  # v is an array of values\n",
        "  return v.astype(np.float)\n",
        "\n",
        "def clean_sid(df):\n",
        "\n",
        "  from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "   # need to implement this function\n",
        "   # using the FunctionTransformer\n",
        "\n",
        "  mode = df['sid'].mode()[0]\n",
        "  df['sid'].fillna(mode, inplace=True)\n",
        "\n",
        "  transformer = FunctionTransformer(string_to_float)\n",
        "  df['sid'] = transformer.fit_transform(df['sid'].values)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "def demo_custom_cleaning(df):\n",
        "  try:\n",
        "    # this will not work\n",
        "    df['sid'] = df['sid'] - 1912\n",
        "  except Exception as e:\n",
        "    print('invalid math')\n",
        "\n",
        "  # clean it so we can do math on it\n",
        "  df_c = clean_sid(df)\n",
        "\n",
        "  df_c['sid'] = 1912 - df_c['sid']\n",
        "  print(df_c.head())\n",
        "  \n",
        "demo_custom_cleaning(df.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zycEktuXMJ5m"
      },
      "source": [
        "**Pandas Coercion**\n",
        "\n",
        "Although sklearn's FunctionTransformer is incredibly flexible, for simple type conversion (string-to-int, int-to-string, etc), you can use panda's to_numeric method. If any issues happen in the coercion, np.nan will be used:\n",
        "\n",
        "```\n",
        "values = pd.to_numeric(df['xyz_column'], errors='coerce')\n",
        "```\n",
        "\n",
        "The to_numeric method will convert values to floats (real numbers). If you want the conversion to be a specific type (like integer) you can either use the downcast [flag](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html) or the astype method:\n",
        "\n",
        "```\n",
        "values = df['xyz'].astype(int) # if any issues, an exception is thrown\n",
        "values = df['xyz'].astype(int, errors='ignore') # ignore those exceptions\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7GoNnV_Ms7l"
      },
      "source": [
        "**Date and Time Care**\n",
        "\n",
        "Handling date and time attributes is a mix of working with text, categorical, and numerical. How you handle the attribute just depends on the level of granularity and its purpose. For example, if you are just marking the month of a purchase, treating dates at the 'month' level as a category is perfectly reasonable. However, if you are working with timestamps of events, then these become numeric fields that you need to work with.\n",
        "\n",
        "Deciding to scale a date/time field is also application specific. If the year of when a car was manufactured becomes important, than that field can be treated as an integer. Another issue is that more recent years will have a higher weight (the scaled number would be closer to 1) than those that happened early on. This may or may not be what you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1bkxn0aM42D"
      },
      "source": [
        "**What is Regularization -- it sounds like normalization?**\n",
        "\n",
        "Regularization has to do with preventing overfitting. They are the techniques used to reduce the error by fitting a function appropriately on the given training set and avoid overfitting.\n",
        "\n",
        "Regularization can be controlled via hyperparameters (those values that are given to configure the algorithm to build a model. Going into the specifics of regularization would be difficult here since it's more appropriate to discuss this when we are trying to avoid over- fitting by adjusting the loss (or objective function). You may hear about L1/L2 regularization which uses the same 'math' as L1, L2 normalization.\n",
        "\n",
        "As a reminder, Overfitting is when the model doesn't generalize the 'pattern' being learned, but 'memorizes' it instead. Regularization attempts to prevent models from overfitting by using a hyperparameter to affecting the parameters or weights the model is learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcUptRZtNBXo"
      },
      "source": [
        "#**Lesson Assignment**\n",
        "**Cleaning Cars**\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1A8hVea1Nx8Ezc4VvFmGx8sMT_xg8ng07)\n",
        "\n",
        "This lesson will be using a classic dataset on automobiles. The origin of this dataset can be found [here](http://lib.stat.cmu.edu/datasets/).\n",
        "\n",
        "However, before we can use it for any machine learning algorithms, it needs a lot of cleaning. We will guide you through all the steps that need to be done. Be sure to print out the dataset (df.head()) so you can first familiarize yourself with the data.\n",
        "\n",
        "For all questions you can solve by using the information in this lesson and (if necessary) the official pandas. (e.g. see [replace](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ZB_3ZzNPvu"
      },
      "source": [
        "**Build the cars**\n",
        "\n",
        "Create a function named build_cars that does the following:\n",
        "* loads 'cars.csv' into a pandas dataframe \n",
        "* returns the dataframe\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def build_cars():\n",
        "   # return the pandas dataframe with cars.csv loaded\n",
        "   return None\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GCNTey-HNdqr"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>69</td>\n",
              "      <td>2050</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "      <td>pulsar (24mpg)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "      <td>(1974)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>257</td>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>258</td>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>259</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>260</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>261</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id   mpg   cylinders  cubicinches   hp  weightlbs   time-to-60    year     brand            notes\n",
              "0      0   NaN           4          NaN   69       2050            6   1985     Japan.   pulsar (24mpg)\n",
              "1     32  16.0           6          250  100       3278           18               US.           (1974)\n",
              "2      1  14.0           8          350  165       4209           12   1972        US.              NaN\n",
              "3      2  31.9           4           89   71       1925           14   1980    Europe.              NaN\n",
              "4      3  17.0           8          302  140       3449           11   1971        US.              NaN\n",
              "..   ...   ...         ...          ...  ...        ...          ...     ...       ...              ...\n",
              "257  257  17.0           8          305  130       3840           15   1980        US.              NaN\n",
              "258  258  36.1           4           91   60       1800           16   1979     Japan.              NaN\n",
              "259  259  22.0           6          232  112       2835           15   1983        US.              NaN\n",
              "260  260  18.0           6          232  100       3288           16   1972        US.              NaN\n",
              "261  261  22.0           6          250  105       3353           15   1977        US.              NaN\n",
              "\n",
              "[262 rows x 10 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 200)\n",
        "\n",
        "def build_cars(*args):\n",
        "  return pd.read_csv('cars.csv')\n",
        "\n",
        "df = build_cars()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqD0TCu1Nie9"
      },
      "source": [
        "**Clean Columns**\n",
        "\n",
        "Now do the following to the dataframe\n",
        "\n",
        "* removes the notes and id columns\n",
        "* remove all spaces from column names\n",
        "* replaces all empty string values with np.nan\n",
        "   * see DataFrame.replace method for one possible option\n",
        "* You can use the df.rename or df.columns.str (which allows you access to all the string methods).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h2NSo-H-efeT"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>69</td>\n",
              "      <td>2050</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mpg  cylinders cubicinches   hp weightlbs  time-to-60    year     brand\n",
              "0     NaN          4         NaN   69      2050           6   1985     Japan.\n",
              "1    16.0          6         250  100      3278          18               US.\n",
              "2    14.0          8         350  165      4209          12   1972        US.\n",
              "3    31.9          4          89   71      1925          14   1980    Europe.\n",
              "4    17.0          8         302  140      3449          11   1971        US.\n",
              "..    ...        ...         ...  ...       ...         ...     ...       ...\n",
              "257  17.0          8         305  130      3840          15   1980        US.\n",
              "258  36.1          4          91   60      1800          16   1979     Japan.\n",
              "259  22.0          6         232  112      2835          15   1983        US.\n",
              "260  18.0          6         232  100      3288          16   1972        US.\n",
              "261  22.0          6         250  105      3353          15   1977        US.\n",
              "\n",
              "[262 rows x 8 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_columns(df):\n",
        "  df.columns = df.columns.str.strip()\n",
        "  df.drop(columns=['notes', 'id'], inplace=True)\n",
        "  df.replace(to_replace='', value=np.nan, inplace=True)\n",
        "\n",
        "  \n",
        "\n",
        "  return df\n",
        "\n",
        "df = clean_columns(build_cars())\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRwqQqK5OFgL"
      },
      "source": [
        "##**Clean nan values**\n",
        "\n",
        "For the following columns replace all empty/missing values with the requested value \n",
        "\n",
        "**clean the mpg field**\n",
        "\n",
        "Create a function named clean_mpg\n",
        "* replaces missing values with the median value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       True\n",
              "1      False\n",
              "2      False\n",
              "3      False\n",
              "4      False\n",
              "       ...  \n",
              "257    False\n",
              "258    False\n",
              "259    False\n",
              "260    False\n",
              "261    False\n",
              "Name: mpg, Length: 262, dtype: bool"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.mpg.isna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "blhuxIWTawaJ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>69</td>\n",
              "      <td>2050</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mpg  cylinders cubicinches   hp weightlbs  time-to-60    year     brand\n",
              "0    22.0          4         NaN   69      2050           6   1985     Japan.\n",
              "1    16.0          6         250  100      3278          18               US.\n",
              "2    14.0          8         350  165      4209          12   1972        US.\n",
              "3    31.9          4          89   71      1925          14   1980    Europe.\n",
              "4    17.0          8         302  140      3449          11   1971        US.\n",
              "..    ...        ...         ...  ...       ...         ...     ...       ...\n",
              "257  17.0          8         305  130      3840          15   1980        US.\n",
              "258  36.1          4          91   60      1800          16   1979     Japan.\n",
              "259  22.0          6         232  112      2835          15   1983        US.\n",
              "260  18.0          6         232  100      3288          16   1972        US.\n",
              "261  22.0          6         250  105      3353          15   1977        US.\n",
              "\n",
              "[262 rows x 8 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_mpg(df):\n",
        "  mask = df.mpg.isna()\n",
        "  value = df.mpg.median()\n",
        "  df['mpg'] = df.mpg.fillna(value)\n",
        "  # print(mask)\n",
        "\n",
        "  # # mask to select the rows where age is empty\n",
        "  # mask = df.age.isna()\n",
        "\n",
        "  # # calculate the mean (the replacement value)\n",
        "  # replace_value = df.age.mean()\n",
        "  \n",
        "  # # fill those values with the value calculated\n",
        "  # df['age_clean']= df[mask].age.fillna(replace_value)\n",
        "  \n",
        "  return df\n",
        "\n",
        "clean_mpg(clean_columns(build_cars()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0DWik3GOUYD"
      },
      "source": [
        "**clean the time-to-60 field** \n",
        "\n",
        "Create a function named clean_t60\n",
        "* replaces missing values with the median value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MEaj6o0LbBPe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>69</td>\n",
              "      <td>2050</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mpg  cylinders cubicinches   hp weightlbs  time-to-60    year     brand\n",
              "0    22.0          4         NaN   69      2050           6   1985     Japan.\n",
              "1    16.0          6         250  100      3278          18               US.\n",
              "2    14.0          8         350  165      4209          12   1972        US.\n",
              "3    31.9          4          89   71      1925          14   1980    Europe.\n",
              "4    17.0          8         302  140      3449          11   1971        US.\n",
              "..    ...        ...         ...  ...       ...         ...     ...       ...\n",
              "257  17.0          8         305  130      3840          15   1980        US.\n",
              "258  36.1          4          91   60      1800          16   1979     Japan.\n",
              "259  22.0          6         232  112      2835          15   1983        US.\n",
              "260  18.0          6         232  100      3288          16   1972        US.\n",
              "261  22.0          6         250  105      3353          15   1977        US.\n",
              "\n",
              "[262 rows x 8 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_t60(df):\n",
        "  value = df['time-to-60'].median()\n",
        "  df['time-to-60'] = df['time-to-60'].fillna(value)\n",
        "  return df\n",
        "\n",
        "clean_t60(clean_mpg(clean_columns(build_cars())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>69</td>\n",
              "      <td>2050</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mpg  cylinders cubicinches   hp weightlbs  time-to-60    year     brand\n",
              "0     NaN          4         NaN   69      2050           6   1985     Japan.\n",
              "1    16.0          6         250  100      3278          18               US.\n",
              "2    14.0          8         350  165      4209          12   1972        US.\n",
              "3    31.9          4          89   71      1925          14   1980    Europe.\n",
              "4    17.0          8         302  140      3449          11   1971        US.\n",
              "..    ...        ...         ...  ...       ...         ...     ...       ...\n",
              "257  17.0          8         305  130      3840          15   1980        US.\n",
              "258  36.1          4          91   60      1800          16   1979     Japan.\n",
              "259  22.0          6         232  112      2835          15   1983        US.\n",
              "260  18.0          6         232  100      3288          16   1972        US.\n",
              "261  22.0          6         250  105      3353          15   1977        US.\n",
              "\n",
              "[262 rows x 8 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def pipeline(data, args):\n",
        "\tfor arg in args:\n",
        "\t\tdata = arg(data)\n",
        "\treturn data\n",
        "\n",
        "pipeline(None, [build_cars, clean_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def add(*args):\n",
        "\tn = 0\n",
        "\tfor arg in args:\n",
        "\t\tn += arg\n",
        "\treturn n\n",
        "\n",
        "add(*[1, 2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>69</td>\n",
              "      <td>2050</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mpg  cylinders cubicinches   hp weightlbs  time-to-60    year     brand\n",
              "0    22.0          4         NaN   69      2050           6   1985     Japan.\n",
              "1    16.0          6         250  100      3278          18               US.\n",
              "2    14.0          8         350  165      4209          12   1972        US.\n",
              "3    31.9          4          89   71      1925          14   1980    Europe.\n",
              "4    17.0          8         302  140      3449          11   1971        US.\n",
              "..    ...        ...         ...  ...       ...         ...     ...       ...\n",
              "257  17.0          8         305  130      3840          15   1980        US.\n",
              "258  36.1          4          91   60      1800          16   1979     Japan.\n",
              "259  22.0          6         232  112      2835          15   1983        US.\n",
              "260  18.0          6         232  100      3288          16   1972        US.\n",
              "261  22.0          6         250  105      3353          15   1977        US.\n",
              "\n",
              "[262 rows x 8 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def recur_pipe(data=None, args=[], *ops):\n",
        "\tif callable(data):\n",
        "\t\targs = [data, args]\n",
        "\tif not ops == None:\n",
        "\t\tfor op in ops:\n",
        "\t\t\targs.append(op)\n",
        "\tif args == []:\n",
        "\t\treturn data\n",
        "\telse:\n",
        "\t\tif callable(args[0]):\n",
        "\t\t\tfunc = args[0]\n",
        "\t\t\treturn recur_pipe(func(data), args[1:])\n",
        "\t\telif isinstance(args[0], (list, tuple)):\n",
        "\t\t\tfunc = args[0][0]\n",
        "\t\t\tsub_args = args[0][1:]\n",
        "\t\t\treturn recur_pipe(func(data, *sub_args), args[1:])\n",
        "\n",
        "\n",
        "recur_pipe(None, [build_cars, clean_columns], clean_mpg, clean_t60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>69</td>\n",
              "      <td>2050</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mpg  cylinders cubicinches   hp weightlbs  time-to-60    year     brand\n",
              "0    22.0          4         NaN   69      2050           6   1985     Japan.\n",
              "1    16.0          6         250  100      3278          18               US.\n",
              "2    14.0          8         350  165      4209          12   1972        US.\n",
              "3    31.9          4          89   71      1925          14   1980    Europe.\n",
              "4    17.0          8         302  140      3449          11   1971        US.\n",
              "..    ...        ...         ...  ...       ...         ...     ...       ...\n",
              "257  17.0          8         305  130      3840          15   1980        US.\n",
              "258  36.1          4          91   60      1800          16   1979     Japan.\n",
              "259  22.0          6         232  112      2835          15   1983        US.\n",
              "260  18.0          6         232  100      3288          16   1972        US.\n",
              "261  22.0          6         250  105      3353          15   1977        US.\n",
              "\n",
              "[262 rows x 8 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recur_pipe(build_cars, clean_columns, clean_mpg, clean_t60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4TbodxmOhRh"
      },
      "source": [
        "**clean the year field**\n",
        "\n",
        "Create a function named clean_year\n",
        "\n",
        "* replaces missing values with the mode \n",
        "* converts the field to an integer value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ycl_sOdpbMJg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1974 \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>69</td>\n",
              "      <td>2050</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278</td>\n",
              "      <td>18</td>\n",
              "      <td>1974</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mpg  cylinders cubicinches   hp weightlbs  time-to-60    year     brand\n",
              "0    22.0          4         NaN   69      2050           6   1985     Japan.\n",
              "1    16.0          6         250  100      3278          18   1974        US.\n",
              "2    14.0          8         350  165      4209          12   1972        US.\n",
              "3    31.9          4          89   71      1925          14   1980    Europe.\n",
              "4    17.0          8         302  140      3449          11   1971        US.\n",
              "..    ...        ...         ...  ...       ...         ...     ...       ...\n",
              "257  17.0          8         305  130      3840          15   1980        US.\n",
              "258  36.1          4          91   60      1800          16   1979     Japan.\n",
              "259  22.0          6         232  112      2835          15   1983        US.\n",
              "260  18.0          6         232  100      3288          16   1972        US.\n",
              "261  22.0          6         250  105      3353          15   1977        US.\n",
              "\n",
              "[262 rows x 8 columns]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_year(df):\n",
        "  value = df['year'].mode()[0]\n",
        "  print(value)\n",
        "  df['year'].replace(to_replace=[' ', '', 'NaN'], value=np.nan, inplace=True)\n",
        "  df['year'] = df['year'].fillna(value)\n",
        "  df['year'].astype(np.int64)\n",
        "  return df\n",
        "\n",
        "recur_pipe(build_cars, clean_columns, clean_mpg, clean_t60, clean_year)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyu3EwsQOrHB"
      },
      "source": [
        "**clean the cubicinches field**\n",
        "\n",
        "Create a function named clean_ci\n",
        "* replaces missing values with the mode\n",
        "* converts the field to an integer value by using the FunctionTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pcw0fSRYbSHE"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97</td>\n",
              "      <td>69</td>\n",
              "      <td>2050</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mpg  cylinders  cubicinches   hp weightlbs  time-to-60    year     brand\n",
              "0    22.0          4           97   69      2050           6   1985     Japan.\n",
              "1    16.0          6          250  100      3278          18               US.\n",
              "2    14.0          8          350  165      4209          12   1972        US.\n",
              "3    31.9          4           89   71      1925          14   1980    Europe.\n",
              "4    17.0          8          302  140      3449          11   1971        US.\n",
              "..    ...        ...          ...  ...       ...         ...     ...       ...\n",
              "257  17.0          8          305  130      3840          15   1980        US.\n",
              "258  36.1          4           91   60      1800          16   1979     Japan.\n",
              "259  22.0          6          232  112      2835          15   1983        US.\n",
              "260  18.0          6          232  100      3288          16   1972        US.\n",
              "261  22.0          6          250  105      3353          15   1977        US.\n",
              "\n",
              "[262 rows x 8 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# def string_to_float(v):\n",
        "#   # v is an array of values\n",
        "#   return v.astype(np.float)\n",
        "\n",
        "# def clean_sid(df):\n",
        "\n",
        "#   from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "#    # need to implement this function\n",
        "#    # using the FunctionTransformer\n",
        "\n",
        "#   mode = df['sid'].mode()[0]\n",
        "#   df['sid'].fillna(mode, inplace=True)\n",
        "\n",
        "#   transformer = FunctionTransformer(string_to_float)\n",
        "#   df['sid'] = transformer.fit_transform(df['sid'].values)\n",
        "\n",
        "#   return df\n",
        "\n",
        "def clean_ci(df):\n",
        "  from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "  df['cubicinches'].replace(to_replace=[' ', ''], value=np.nan, inplace=True)\n",
        "  df['cubicinches'] = df['cubicinches'].fillna(df['cubicinches'].mode()[0])\n",
        "  df['cubicinches'] = FunctionTransformer(lambda x: x.astype(np.int64)).fit_transform(df['cubicinches'].values)\n",
        "\n",
        "  return df\n",
        "\n",
        "recur_pipe(build_cars, clean_columns, clean_mpg, clean_t60, clean_year, clean_ci)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5bPuAU0O9at"
      },
      "source": [
        "**clean the weightlbs field**\n",
        "\n",
        "Create a function named clean_wlb\n",
        "* replaces missing values with the mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_0Pv3kyKbkJM"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97</td>\n",
              "      <td>69</td>\n",
              "      <td>2050.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278.0</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209.0</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288.0</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mpg  cylinders  cubicinches   hp  weightlbs  time-to-60    year     brand\n",
              "0    22.0          4           97   69     2050.0           6   1985     Japan.\n",
              "1    16.0          6          250  100     3278.0          18               US.\n",
              "2    14.0          8          350  165     4209.0          12   1972        US.\n",
              "3    31.9          4           89   71     1925.0          14   1980    Europe.\n",
              "4    17.0          8          302  140     3449.0          11   1971        US.\n",
              "..    ...        ...          ...  ...        ...         ...     ...       ...\n",
              "257  17.0          8          305  130     3840.0          15   1980        US.\n",
              "258  36.1          4           91   60     1800.0          16   1979     Japan.\n",
              "259  22.0          6          232  112     2835.0          15   1983        US.\n",
              "260  18.0          6          232  100     3288.0          16   1972        US.\n",
              "261  22.0          6          250  105     3353.0          15   1977        US.\n",
              "\n",
              "[262 rows x 8 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def clean_wlb(df):\n",
        "  df['weightlbs'].replace(to_replace=[' ', ''], value=np.nan, inplace=True)\n",
        "  df['weightlbs'] = FunctionTransformer(lambda x: x.astype(np.float128)).fit_transform(df['weightlbs'].values)\n",
        "  df['weightlbs'].fillna(df['weightlbs'].mean(skipna=True), inplace=True)\n",
        "  return df\n",
        "\n",
        "# recur_pipe(build_cars, clean_columns, clean_mpg, clean_t60, clean_year, clean_ci, clean_wlb)\n",
        "df = recur_pipe(build_cars, clean_columns, clean_mpg, clean_t60, clean_year, clean_ci, clean_wlb)\n",
        "df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9GiYLk-PMm5"
      },
      "source": [
        "**clean the brand field**\n",
        "\n",
        "Create a function named clean_brand\n",
        "* remap this categorical field: \n",
        "* US becomes 0\n",
        "* Europe becomes 1 \n",
        "* Japan becomes 2\n",
        "* place the new value in the field manf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uhp32-n0byPK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "      <th>manf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97</td>\n",
              "      <td>69</td>\n",
              "      <td>2050.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>100</td>\n",
              "      <td>3278.0</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>165</td>\n",
              "      <td>4209.0</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.9</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>140</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>130</td>\n",
              "      <td>3840.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>36.1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>112</td>\n",
              "      <td>2835.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>100</td>\n",
              "      <td>3288.0</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>22.0</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>105</td>\n",
              "      <td>3353.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      mpg  cylinders  cubicinches   hp  weightlbs  time-to-60  year    brand  manf\n",
              "0    22.0          4           97   69     2050.0           6  1985   Japan.     2\n",
              "1    16.0          6          250  100     3278.0          18            US.     0\n",
              "2    14.0          8          350  165     4209.0          12  1972      US.     0\n",
              "3    31.9          4           89   71     1925.0          14  1980  Europe.     1\n",
              "4    17.0          8          302  140     3449.0          11  1971      US.     0\n",
              "..    ...        ...          ...  ...        ...         ...   ...      ...   ...\n",
              "257  17.0          8          305  130     3840.0          15  1980      US.     0\n",
              "258  36.1          4           91   60     1800.0          16  1979   Japan.     2\n",
              "259  22.0          6          232  112     2835.0          15  1983      US.     0\n",
              "260  18.0          6          232  100     3288.0          16  1972      US.     0\n",
              "261  22.0          6          250  105     3353.0          15  1977      US.     0\n",
              "\n",
              "[262 rows x 9 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_spaces(df):\n",
        "  return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "categories = {'US.': 0, 'Europe.': 1, 'Japan.': 2}\n",
        "\n",
        "def clean_brand(df):\n",
        "  df['manf'] = df['brand'].map(categories)\n",
        "  return df\n",
        "\n",
        "recur_pipe(build_cars, clean_columns, clean_spaces, clean_mpg, clean_t60, clean_year, clean_ci, clean_wlb, clean_brand)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqD1YwUyPtyN"
      },
      "source": [
        "###**Scaling Features**\n",
        "\n",
        "Create a function named scale_features that transforms a list of column names to [0,1] using sklearn's min-max scaling.\n",
        "* return a new dataframe with the scaled columns \n",
        "\n",
        "For example, this code\n",
        "\n",
        "```\n",
        "df_sub = scale_features(cars_df, ['mpg', 'hp])\n",
        "print(df_sub.head())\n",
        "```\n",
        "\n",
        "would generate this output (before and after)\n",
        "\n",
        "```\n",
        "    mpg   hp\n",
        "0  22.0   69\n",
        "1  16.0  100\n",
        "2  14.0  165\n",
        "3  31.9   71\n",
        "4  17.0  140\n",
        "        mpg        hp\n",
        "0  0.327869  0.125000\n",
        "1  0.163934  0.293478\n",
        "2  0.109290  0.646739\n",
        "3  0.598361  0.135870\n",
        "4  0.191257  0.510870\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "oOHCzyHNcYLh"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "      <th>manf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.327869</td>\n",
              "      <td>4</td>\n",
              "      <td>97</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>2050.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.163934</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>0.293478</td>\n",
              "      <td>3278.0</td>\n",
              "      <td>18</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.109290</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>0.646739</td>\n",
              "      <td>4209.0</td>\n",
              "      <td>12</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.598361</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>0.135870</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.191257</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>0.510870</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>0.191257</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>0.456522</td>\n",
              "      <td>3840.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0.713115</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>0.076087</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>16</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0.327869</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>0.358696</td>\n",
              "      <td>2835.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>0.218579</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>0.293478</td>\n",
              "      <td>3288.0</td>\n",
              "      <td>16</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0.327869</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>0.320652</td>\n",
              "      <td>3353.0</td>\n",
              "      <td>15</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          mpg  cylinders  cubicinches        hp  weightlbs  time-to-60  year    brand  manf\n",
              "0    0.327869          4           97  0.125000     2050.0           6  1985   Japan.     2\n",
              "1    0.163934          6          250  0.293478     3278.0          18            US.     0\n",
              "2    0.109290          8          350  0.646739     4209.0          12  1972      US.     0\n",
              "3    0.598361          4           89  0.135870     1925.0          14  1980  Europe.     1\n",
              "4    0.191257          8          302  0.510870     3449.0          11  1971      US.     0\n",
              "..        ...        ...          ...       ...        ...         ...   ...      ...   ...\n",
              "257  0.191257          8          305  0.456522     3840.0          15  1980      US.     0\n",
              "258  0.713115          4           91  0.076087     1800.0          16  1979   Japan.     2\n",
              "259  0.327869          6          232  0.358696     2835.0          15  1983      US.     0\n",
              "260  0.218579          6          232  0.293478     3288.0          16  1972      US.     0\n",
              "261  0.327869          6          250  0.320652     3353.0          15  1977      US.     0\n",
              "\n",
              "[262 rows x 9 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def scale_features(df, cols=['mpg', 'hp']):\n",
        "  scaler = MinMaxScaler()\n",
        "  for col in cols:\n",
        "    df[col] = scaler.fit_transform(df[col].values.reshape(-1, 1))\n",
        "  return df\n",
        "\n",
        "recur_pipe(build_cars, clean_columns, clean_spaces, clean_mpg, clean_t60, clean_year, clean_ci, clean_wlb, clean_brand, (scale_features, ['mpg', 'hp']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmClQzvLQHVU"
      },
      "source": [
        "###**Flip Features**\n",
        "\n",
        "For the 'time-to-60' a lower value is 'better'. We can remap this column so those cars with fast 'time-to-60' values (low numbers) are close to 1 and those with slow 'time-to-60' values (high numbers) are close to 0. We can simply invert these values.\n",
        "\n",
        "Create a function called flip_features that takes a dataframe list of column names that inverts the values. For example, for the following code:\n",
        "\n",
        "```\n",
        "dfs = scale_features(dfc.copy(), ['time-to-60'])\n",
        "print(dfs.head(5))\n",
        "print(flip_features(dfs.copy(), ['time-to-60']).head(5))\n",
        "```\n",
        "\n",
        "The output would look like this:\n",
        "\n",
        "```\n",
        "   time-to-60  (OLD)\n",
        "0    0.000000\n",
        "1    0.631579\n",
        "2    0.315789\n",
        "3    0.421053\n",
        "4    0.263158\n",
        "   time-to-60  (Flipped)\n",
        "0    1.000000\n",
        "1    0.368421\n",
        "2    0.684211\n",
        "3    0.578947\n",
        "4    0.736842\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "E4fPfRudc56W"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>cubicinches</th>\n",
              "      <th>hp</th>\n",
              "      <th>weightlbs</th>\n",
              "      <th>time-to-60</th>\n",
              "      <th>year</th>\n",
              "      <th>brand</th>\n",
              "      <th>manf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.327869</td>\n",
              "      <td>4</td>\n",
              "      <td>97</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>2050.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1985</td>\n",
              "      <td>Japan.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.163934</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>0.293478</td>\n",
              "      <td>3278.0</td>\n",
              "      <td>0.368421</td>\n",
              "      <td></td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.109290</td>\n",
              "      <td>8</td>\n",
              "      <td>350</td>\n",
              "      <td>0.646739</td>\n",
              "      <td>4209.0</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.598361</td>\n",
              "      <td>4</td>\n",
              "      <td>89</td>\n",
              "      <td>0.135870</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>1980</td>\n",
              "      <td>Europe.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.191257</td>\n",
              "      <td>8</td>\n",
              "      <td>302</td>\n",
              "      <td>0.510870</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>1971</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>0.191257</td>\n",
              "      <td>8</td>\n",
              "      <td>305</td>\n",
              "      <td>0.456522</td>\n",
              "      <td>3840.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>1980</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0.713115</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>0.076087</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>1979</td>\n",
              "      <td>Japan.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0.327869</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>0.358696</td>\n",
              "      <td>2835.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>1983</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>0.218579</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>0.293478</td>\n",
              "      <td>3288.0</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>1972</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0.327869</td>\n",
              "      <td>6</td>\n",
              "      <td>250</td>\n",
              "      <td>0.320652</td>\n",
              "      <td>3353.0</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>1977</td>\n",
              "      <td>US.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          mpg  cylinders  cubicinches        hp  weightlbs  time-to-60  year    brand  manf\n",
              "0    0.327869          4           97  0.125000     2050.0    1.000000  1985   Japan.     2\n",
              "1    0.163934          6          250  0.293478     3278.0    0.368421            US.     0\n",
              "2    0.109290          8          350  0.646739     4209.0    0.684211  1972      US.     0\n",
              "3    0.598361          4           89  0.135870     1925.0    0.578947  1980  Europe.     1\n",
              "4    0.191257          8          302  0.510870     3449.0    0.736842  1971      US.     0\n",
              "..        ...        ...          ...       ...        ...         ...   ...      ...   ...\n",
              "257  0.191257          8          305  0.456522     3840.0    0.526316  1980      US.     0\n",
              "258  0.713115          4           91  0.076087     1800.0    0.473684  1979   Japan.     2\n",
              "259  0.327869          6          232  0.358696     2835.0    0.526316  1983      US.     0\n",
              "260  0.218579          6          232  0.293478     3288.0    0.473684  1972      US.     0\n",
              "261  0.327869          6          250  0.320652     3353.0    0.526316  1977      US.     0\n",
              "\n",
              "[262 rows x 9 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def flip_features(df, cols=['time-to-60']):\n",
        "  df = scale_features(df, cols)\n",
        "  for col in cols:\n",
        "    df[col] = 1 - df[col]\n",
        "  return df\n",
        "\n",
        "the_final_data_is_here = recur_pipe(build_cars, clean_columns, clean_spaces, clean_mpg, clean_t60, clean_year, clean_ci, clean_wlb, clean_brand, (scale_features, ['mpg', 'hp']), (flip_features, ['time-to-60']))\n",
        "\n",
        "the_final_data_is_here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHHtBXaydJId"
      },
      "source": [
        "**Steps to submit your work:**\n",
        "\n",
        "\n",
        "1.   Download the notebook from Moodle. It is recommended that you use Google Colab to work on it.\n",
        "2.   Upload any supporting files using file upload option within Google Colab.\n",
        "3.   Complete the exercises and/or assignments\n",
        "4.   Download as .ipynb\n",
        "5.   Name the file as \"lastname_firstname_WeekNumber.ipynb\"\n",
        "6.   After following the above steps, submit the final file in Moodle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h1><center>The End!</center></h1>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Week8_Data_Normalization_Part1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
