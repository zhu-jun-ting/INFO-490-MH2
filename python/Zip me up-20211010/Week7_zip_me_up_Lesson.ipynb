{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Week7_zip_me_up_Lesson.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Zip Me Up: ngrams**\n",
        "\n",
        "This lessons fills in the details about Python's built-in zip function. It 's a very powerful utility to help manipulate and maneuver data lists/arrays.\n",
        "\n",
        "**N-Grams Revisited**\n",
        "\n",
        "As a quick refresher, ngrams are a way to group words together (usually from processing text). They are contiguous sequence of n tokens.\n",
        "For example, tri-grams (N = 3) for the first 2 sentences in **The Cat in The Hat** (cith.txt) would be:\n",
        "\n",
        "```\n",
        "The sun did\n",
        "sun did not\n",
        "did not shine\n",
        "not shine It\n",
        "shine It was\n",
        "It was too\n",
        "was too wet\n",
        "too wet to\n",
        "wet to play\n",
        "```\n"
      ],
      "metadata": {
        "id": "5H-rTZn-Y9OY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can print out the contents of the book using the following command:\n"
      ],
      "metadata": {
        "id": "NOoRLSjvaa7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "def read_data_file(filename):\n",
        "  with open(filename, 'r') as fd:\n",
        "    return fd.read()\n",
        "        \n",
        "print(read_data_file(\"cith.txt\")[0:100])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER ONE\n",
            "The sun did not shine.\n",
            "It was too wet to play.\n",
            "So we sat in the house\n",
            "All that cold, col\n"
          ]
        }
      ],
      "metadata": {
        "id": "_J5JYa4VQqc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the easiest ways to generate ngrams is to use Python's array slicing and comprehension syntax:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def get_ngrams(words, n):\n",
        "  total = len(words) - (n-1)\n",
        "  return [words[i:i+n] for i in range(total)]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nBiOpEpXbL7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# type&run the above example/exercise in this cell\n",
        "\n",
        "f = read_data_file(\"cith.txt\")\n",
        "\n",
        "def get_ngrams(words, n):\n",
        "  total = len(words) - (n-1)\n",
        "  return [words[i:i+n] for i in range(total)]\n",
        "\n",
        "get_ngrams(f, 4)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CHAP',\n",
              " 'HAPT',\n",
              " 'APTE',\n",
              " 'PTER',\n",
              " 'TER ',\n",
              " 'ER O',\n",
              " 'R ON',\n",
              " ' ONE',\n",
              " 'ONE\\n',\n",
              " 'NE\\nT',\n",
              " 'E\\nTh',\n",
              " '\\nThe',\n",
              " 'The ',\n",
              " 'he s',\n",
              " 'e su',\n",
              " ' sun',\n",
              " 'sun ',\n",
              " 'un d',\n",
              " 'n di',\n",
              " ' did',\n",
              " 'did ',\n",
              " 'id n',\n",
              " 'd no',\n",
              " ' not',\n",
              " 'not ',\n",
              " 'ot s',\n",
              " 't sh',\n",
              " ' shi',\n",
              " 'shin',\n",
              " 'hine',\n",
              " 'ine.',\n",
              " 'ne.\\n',\n",
              " 'e.\\nI',\n",
              " '.\\nIt',\n",
              " '\\nIt ',\n",
              " 'It w',\n",
              " 't wa',\n",
              " ' was',\n",
              " 'was ',\n",
              " 'as t',\n",
              " 's to',\n",
              " ' too',\n",
              " 'too ',\n",
              " 'oo w',\n",
              " 'o we',\n",
              " ' wet',\n",
              " 'wet ',\n",
              " 'et t',\n",
              " 't to',\n",
              " ' to ',\n",
              " 'to p',\n",
              " 'o pl',\n",
              " ' pla',\n",
              " 'play',\n",
              " 'lay.',\n",
              " 'ay.\\n',\n",
              " 'y.\\nS',\n",
              " '.\\nSo',\n",
              " '\\nSo ',\n",
              " 'So w',\n",
              " 'o we',\n",
              " ' we ',\n",
              " 'we s',\n",
              " 'e sa',\n",
              " ' sat',\n",
              " 'sat ',\n",
              " 'at i',\n",
              " 't in',\n",
              " ' in ',\n",
              " 'in t',\n",
              " 'n th',\n",
              " ' the',\n",
              " 'the ',\n",
              " 'he h',\n",
              " 'e ho',\n",
              " ' hou',\n",
              " 'hous',\n",
              " 'ouse',\n",
              " 'use\\n',\n",
              " 'se\\nA',\n",
              " 'e\\nAl',\n",
              " '\\nAll',\n",
              " 'All ',\n",
              " 'll t',\n",
              " 'l th',\n",
              " ' tha',\n",
              " 'that',\n",
              " 'hat ',\n",
              " 'at c',\n",
              " 't co',\n",
              " ' col',\n",
              " 'cold',\n",
              " 'old,',\n",
              " 'ld, ',\n",
              " 'd, c',\n",
              " ', co',\n",
              " ' col',\n",
              " 'cold',\n",
              " 'old,',\n",
              " 'ld, ',\n",
              " 'd, w',\n",
              " ', we',\n",
              " ' wet',\n",
              " 'wet ',\n",
              " 'et d',\n",
              " 't da',\n",
              " ' day',\n",
              " 'day.',\n",
              " 'ay.\\n',\n",
              " 'y.\\n\\n',\n",
              " '.\\n\\nI',\n",
              " '\\n\\nI ',\n",
              " '\\nI s',\n",
              " 'I sa',\n",
              " ' sat',\n",
              " 'sat ',\n",
              " 'at t',\n",
              " 't th',\n",
              " ' the',\n",
              " 'ther',\n",
              " 'here',\n",
              " 'ere ',\n",
              " 're w',\n",
              " 'e wi',\n",
              " ' wit',\n",
              " 'with',\n",
              " 'ith ',\n",
              " 'th S',\n",
              " 'h Sa',\n",
              " ' Sal',\n",
              " 'Sall',\n",
              " 'ally',\n",
              " 'lly.',\n",
              " 'ly.\\n',\n",
              " 'y.\\nW',\n",
              " '.\\nWe',\n",
              " '\\nWe ',\n",
              " 'We s',\n",
              " 'e sa',\n",
              " ' sat',\n",
              " 'sat ',\n",
              " 'at t',\n",
              " 't th',\n",
              " ' the',\n",
              " 'ther',\n",
              " 'here',\n",
              " 'ere,',\n",
              " 're, ',\n",
              " 'e, w',\n",
              " ', we',\n",
              " ' we ',\n",
              " 'we t',\n",
              " 'e tw',\n",
              " ' two',\n",
              " 'two.',\n",
              " 'wo.\\n',\n",
              " 'o.\\nA',\n",
              " '.\\nAn',\n",
              " '\\nAnd',\n",
              " 'And ',\n",
              " 'nd I',\n",
              " 'd I ',\n",
              " ' I s',\n",
              " 'I sa',\n",
              " ' sai',\n",
              " 'said',\n",
              " 'aid,',\n",
              " 'id, ',\n",
              " 'd, \"',\n",
              " ', \"H',\n",
              " ' \"Ho',\n",
              " '\"How',\n",
              " 'How ',\n",
              " 'ow I',\n",
              " 'w I ',\n",
              " ' I w',\n",
              " 'I wi',\n",
              " ' wis',\n",
              " 'wish',\n",
              " 'ish\\n',\n",
              " 'sh\\nW',\n",
              " 'h\\nWe',\n",
              " '\\nWe ',\n",
              " 'We h',\n",
              " 'e ha',\n",
              " ' had',\n",
              " 'had ',\n",
              " 'ad s',\n",
              " 'd so',\n",
              " ' som',\n",
              " 'some',\n",
              " 'omet',\n",
              " 'meth',\n",
              " 'ethi',\n",
              " 'thin',\n",
              " 'hing',\n",
              " 'ing ',\n",
              " 'ng t',\n",
              " 'g to',\n",
              " ' to ',\n",
              " 'to d',\n",
              " 'o do',\n",
              " ' do!',\n",
              " 'do!\"',\n",
              " 'o!\"\\n',\n",
              " '!\"\\n\\n',\n",
              " '\"\\n\\nT',\n",
              " '\\n\\nTo',\n",
              " '\\nToo',\n",
              " 'Too ',\n",
              " 'oo w',\n",
              " 'o we',\n",
              " ' wet',\n",
              " 'wet ',\n",
              " 'et t',\n",
              " 't to',\n",
              " ' to ',\n",
              " 'to g',\n",
              " 'o go',\n",
              " ' go ',\n",
              " 'go o',\n",
              " 'o ou',\n",
              " ' out',\n",
              " 'out\\n',\n",
              " 'ut\\nA',\n",
              " 't\\nAn',\n",
              " '\\nAnd',\n",
              " 'And ',\n",
              " 'nd t',\n",
              " 'd to',\n",
              " ' too',\n",
              " 'too ',\n",
              " 'oo c',\n",
              " 'o co',\n",
              " ' col',\n",
              " 'cold',\n",
              " 'old ',\n",
              " 'ld t',\n",
              " 'd to',\n",
              " ' to ',\n",
              " 'to p',\n",
              " 'o pl',\n",
              " ' pla',\n",
              " 'play',\n",
              " 'lay ',\n",
              " 'ay b',\n",
              " 'y ba',\n",
              " ' bal',\n",
              " 'ball',\n",
              " 'all.',\n",
              " 'll.\\n',\n",
              " 'l.\\nS',\n",
              " '.\\nSo',\n",
              " '\\nSo ',\n",
              " 'So w',\n",
              " 'o we',\n",
              " ' we ',\n",
              " 'we s',\n",
              " 'e sa',\n",
              " ' sat',\n",
              " 'sat ',\n",
              " 'at i',\n",
              " 't in',\n",
              " ' in ',\n",
              " 'in t',\n",
              " 'n th',\n",
              " ' the',\n",
              " 'the ',\n",
              " 'he h',\n",
              " 'e ho',\n",
              " ' hou',\n",
              " 'hous',\n",
              " 'ouse',\n",
              " 'use.',\n",
              " 'se.\\n',\n",
              " 'e.\\nW',\n",
              " '.\\nWe',\n",
              " '\\nWe ',\n",
              " 'We d',\n",
              " 'e di',\n",
              " ' did',\n",
              " 'did ',\n",
              " 'id n',\n",
              " 'd no',\n",
              " ' not',\n",
              " 'noth',\n",
              " 'othi',\n",
              " 'thin',\n",
              " 'hing',\n",
              " 'ing ',\n",
              " 'ng a',\n",
              " 'g at',\n",
              " ' at ',\n",
              " 'at a',\n",
              " 't al',\n",
              " ' all',\n",
              " 'all.',\n",
              " 'll.\\n',\n",
              " 'l.\\n\\n',\n",
              " '.\\n\\nS',\n",
              " '\\n\\nSo',\n",
              " '\\nSo ',\n",
              " 'So a',\n",
              " 'o al',\n",
              " ' all',\n",
              " 'all ',\n",
              " 'll w',\n",
              " 'l we',\n",
              " ' we ',\n",
              " 'we c',\n",
              " 'e co',\n",
              " ' cou',\n",
              " 'coul',\n",
              " 'ould',\n",
              " 'uld ',\n",
              " 'ld d',\n",
              " 'd do',\n",
              " ' do ',\n",
              " 'do w',\n",
              " 'o wa',\n",
              " ' was',\n",
              " 'was ',\n",
              " 'as t',\n",
              " 's to',\n",
              " ' to\\n',\n",
              " 'to\\n\\n',\n",
              " 'o\\n\\nS',\n",
              " '\\n\\nSi',\n",
              " '\\nSit',\n",
              " 'Sit!',\n",
              " 'it!\\n',\n",
              " 't!\\nS',\n",
              " '!\\nSi',\n",
              " '\\nSit',\n",
              " 'Sit!',\n",
              " 'it!\\n',\n",
              " 't!\\nS',\n",
              " '!\\nSi',\n",
              " '\\nSit',\n",
              " 'Sit!',\n",
              " 'it!\\n',\n",
              " 't!\\nS',\n",
              " '!\\nSi',\n",
              " '\\nSit',\n",
              " 'Sit!',\n",
              " 'it!\\n',\n",
              " 't!\\n\\n',\n",
              " '!\\n\\nA',\n",
              " '\\n\\nAn',\n",
              " '\\nAnd',\n",
              " 'And ',\n",
              " 'nd w',\n",
              " 'd we',\n",
              " ' we ',\n",
              " 'we d',\n",
              " 'e di',\n",
              " ' did',\n",
              " 'did ',\n",
              " 'id n',\n",
              " 'd no',\n",
              " ' not',\n",
              " 'not ',\n",
              " 'ot l',\n",
              " 't li',\n",
              " ' lik',\n",
              " 'like',\n",
              " 'ike ',\n",
              " 'ke i',\n",
              " 'e it',\n",
              " ' it.',\n",
              " 'it.\\n',\n",
              " 't.\\nN',\n",
              " '.\\nNo',\n",
              " '\\nNot',\n",
              " 'Not ',\n",
              " 'ot o',\n",
              " 't on',\n",
              " ' one',\n",
              " 'one ',\n",
              " 'ne l',\n",
              " 'e li',\n",
              " ' lit',\n",
              " 'litt',\n",
              " 'ittl',\n",
              " 'ttle',\n",
              " 'tle ',\n",
              " 'le b',\n",
              " 'e bi',\n",
              " ' bit',\n",
              " 'bit.',\n",
              " 'it.\\n',\n",
              " 't.\\n\\n',\n",
              " '.\\n\\nC',\n",
              " '\\n\\nCH',\n",
              " '\\nCHA',\n",
              " 'CHAP',\n",
              " 'HAPT',\n",
              " 'APTE',\n",
              " 'PTER',\n",
              " 'TER ',\n",
              " 'ER T',\n",
              " 'R TW',\n",
              " ' TWO',\n",
              " 'TWO\\n',\n",
              " 'WO\\nB',\n",
              " 'O\\nBU',\n",
              " '\\nBUM',\n",
              " 'BUMP',\n",
              " 'UMP!',\n",
              " 'MP!\\n',\n",
              " 'P!\\n\\n',\n",
              " '!\\n\\nA',\n",
              " '\\n\\nAn',\n",
              " '\\nAnd',\n",
              " 'And ',\n",
              " 'nd t',\n",
              " 'd th',\n",
              " ' the',\n",
              " 'then',\n",
              " 'hen\\n',\n",
              " 'en\\ns',\n",
              " 'n\\nso',\n",
              " '\\nsom',\n",
              " 'some',\n",
              " 'omet',\n",
              " 'meth',\n",
              " 'ethi',\n",
              " 'thin',\n",
              " 'hing',\n",
              " 'ing ',\n",
              " 'ng w',\n",
              " 'g we',\n",
              " ' wen',\n",
              " 'went',\n",
              " 'ent ',\n",
              " 'nt B',\n",
              " 't BU',\n",
              " ' BUM',\n",
              " 'BUMP',\n",
              " 'UMP!',\n",
              " 'MP!\\n',\n",
              " 'P!\\nH',\n",
              " '!\\nHo',\n",
              " '\\nHow',\n",
              " 'How ',\n",
              " 'ow t',\n",
              " 'w th',\n",
              " ' tha',\n",
              " 'that',\n",
              " 'hat ',\n",
              " 'at b',\n",
              " 't bu',\n",
              " ' bum',\n",
              " 'bump',\n",
              " 'ump ',\n",
              " 'mp m',\n",
              " 'p ma',\n",
              " ' mad',\n",
              " 'made',\n",
              " 'ade ',\n",
              " 'de u',\n",
              " 'e us',\n",
              " ' us ',\n",
              " 'us j',\n",
              " 's ju',\n",
              " ' jum',\n",
              " 'jump',\n",
              " 'ump!',\n",
              " 'mp!\\n',\n",
              " 'p!\\n\\n',\n",
              " '!\\n\\nW',\n",
              " '\\n\\nWe',\n",
              " '\\nWe ',\n",
              " 'We l',\n",
              " 'e lo',\n",
              " ' loo',\n",
              " 'look',\n",
              " 'ooke',\n",
              " 'oked',\n",
              " 'ked!',\n",
              " 'ed!\\n',\n",
              " 'd!\\nT',\n",
              " '!\\nTh',\n",
              " '\\nThe',\n",
              " 'Then',\n",
              " 'hen ',\n",
              " 'en w',\n",
              " 'n we',\n",
              " ' we ',\n",
              " 'we s',\n",
              " 'e sa',\n",
              " ' saw',\n",
              " 'saw ',\n",
              " 'aw h',\n",
              " 'w hi',\n",
              " ' him',\n",
              " 'him ',\n",
              " 'im s',\n",
              " 'm st',\n",
              " ' ste',\n",
              " 'step',\n",
              " 'tep ',\n",
              " 'ep i',\n",
              " 'p in',\n",
              " ' in ',\n",
              " 'in o',\n",
              " 'n on',\n",
              " ' on ',\n",
              " 'on t',\n",
              " 'n th',\n",
              " ' the',\n",
              " 'the ',\n",
              " 'he m',\n",
              " 'e ma',\n",
              " ' mat',\n",
              " 'mat!',\n",
              " 'at!\\n',\n",
              " 't!\\nW',\n",
              " '!\\nWe',\n",
              " '\\nWe ',\n",
              " 'We l',\n",
              " 'e lo',\n",
              " ' loo',\n",
              " 'look',\n",
              " 'ooke',\n",
              " 'oked',\n",
              " 'ked!',\n",
              " 'ed!\\n',\n",
              " 'd!\\nA',\n",
              " '!\\nAn',\n",
              " '\\nAnd',\n",
              " 'And ',\n",
              " 'nd w',\n",
              " 'd we',\n",
              " ' we ',\n",
              " 'we s',\n",
              " 'e sa',\n",
              " ' saw',\n",
              " 'saw ',\n",
              " 'aw h',\n",
              " 'w hi',\n",
              " ' him',\n",
              " 'him!',\n",
              " 'im!\\n',\n",
              " 'm!\\nT',\n",
              " '!\\nTh',\n",
              " '\\nThe',\n",
              " 'The ',\n",
              " 'he C',\n",
              " 'e Ca',\n",
              " ' Cat',\n",
              " 'Cat ',\n",
              " 'at i',\n",
              " 't in',\n",
              " ' in ',\n",
              " 'in t',\n",
              " 'n th',\n",
              " ' the',\n",
              " 'the ',\n",
              " 'he H',\n",
              " 'e Ha',\n",
              " ' Hat',\n",
              " 'Hat!',\n",
              " 'at!\\n',\n",
              " 't!\\nA',\n",
              " '!\\nAn',\n",
              " '\\nAnd',\n",
              " 'And ',\n",
              " 'nd h',\n",
              " 'd he',\n",
              " ' he ',\n",
              " 'he s',\n",
              " 'e sa',\n",
              " ' sai',\n",
              " 'said',\n",
              " 'aid ',\n",
              " 'id t',\n",
              " 'd to',\n",
              " ' to ',\n",
              " 'to u',\n",
              " 'o us',\n",
              " ' us,',\n",
              " 'us,\\n',\n",
              " 's,\\n\"',\n",
              " ',\\n\"W',\n",
              " '\\n\"Wh',\n",
              " '\"Why',\n",
              " 'Why ',\n",
              " 'hy d',\n",
              " 'y do',\n",
              " ' do ',\n",
              " 'do y',\n",
              " 'o yo',\n",
              " ' you',\n",
              " 'you ',\n",
              " 'ou s',\n",
              " 'u si',\n",
              " ' sit',\n",
              " 'sit ',\n",
              " 'it t',\n",
              " 't th',\n",
              " ' the',\n",
              " 'ther',\n",
              " 'here',\n",
              " 'ere ',\n",
              " 're l',\n",
              " 'e li',\n",
              " ' lik',\n",
              " 'like',\n",
              " 'ike ',\n",
              " 'ke t',\n",
              " 'e th',\n",
              " ' tha',\n",
              " 'that',\n",
              " 'hat?',\n",
              " 'at?\"',\n",
              " 't?\"\\n',\n",
              " '?\"\\n\"',\n",
              " '\"\\n\"I',\n",
              " '\\n\"I ',\n",
              " '\"I k',\n",
              " 'I kn',\n",
              " ' kno',\n",
              " 'know',\n",
              " 'now ',\n",
              " 'ow i',\n",
              " 'w it',\n",
              " ' it ',\n",
              " 'it i',\n",
              " 't is',\n",
              " ' is ',\n",
              " 'is w',\n",
              " 's we',\n",
              " ' wet',\n",
              " 'wet\\n',\n",
              " 'et\\nA',\n",
              " 't\\nAn',\n",
              " '\\nAnd',\n",
              " 'And ',\n",
              " 'nd t',\n",
              " 'd th',\n",
              " ' the',\n",
              " 'the ',\n",
              " 'he s',\n",
              " 'e su',\n",
              " ' sun',\n",
              " 'sun ',\n",
              " 'un i',\n",
              " 'n is',\n",
              " ' is ',\n",
              " 'is n',\n",
              " 's no',\n",
              " ' not',\n",
              " 'not ',\n",
              " 'ot s',\n",
              " 't su',\n",
              " ' sun',\n",
              " 'sunn',\n",
              " 'unny',\n",
              " 'nny.',\n",
              " 'ny.\\n',\n",
              " 'y.\\nB',\n",
              " '.\\nBu',\n",
              " '\\nBut',\n",
              " 'But ',\n",
              " 'ut w',\n",
              " 't we',\n",
              " ' we ',\n",
              " 'we c',\n",
              " 'e ca',\n",
              " ' can',\n",
              " 'can ',\n",
              " 'an h',\n",
              " 'n ha',\n",
              " ' hav',\n",
              " 'have',\n",
              " 'ave\\n',\n",
              " 've\\nL',\n",
              " 'e\\nLo',\n",
              " '\\nLot',\n",
              " 'Lots',\n",
              " 'ots ',\n",
              " 'ts o',\n",
              " 's of',\n",
              " ' of ',\n",
              " 'of g',\n",
              " 'f go',\n",
              " ' goo',\n",
              " 'good',\n",
              " 'ood ',\n",
              " 'od f',\n",
              " 'd fu',\n",
              " ' fun',\n",
              " 'fun ',\n",
              " 'un t',\n",
              " 'n th',\n",
              " ' tha',\n",
              " 'that',\n",
              " 'hat ',\n",
              " 'at i',\n",
              " 't is',\n",
              " ' is ',\n",
              " 'is f',\n",
              " 's fu',\n",
              " ' fun',\n",
              " 'funn',\n",
              " 'unny',\n",
              " 'nny!',\n",
              " 'ny!\"',\n",
              " 'y!\"\\n',\n",
              " '!\"\\n\\n',\n",
              " '\"\\n\\n\"',\n",
              " '\\n\\n\"I',\n",
              " '\\n\"I ',\n",
              " '\"I k',\n",
              " 'I kn',\n",
              " ' kno',\n",
              " 'know',\n",
              " 'now ',\n",
              " 'ow s',\n",
              " 'w so',\n",
              " ' som',\n",
              " 'some',\n",
              " 'ome ',\n",
              " 'me g',\n",
              " 'e go',\n",
              " ' goo',\n",
              " 'good',\n",
              " 'ood ',\n",
              " 'od g',\n",
              " 'd ga',\n",
              " ' gam',\n",
              " 'game',\n",
              " 'ames',\n",
              " 'mes ',\n",
              " 'es w',\n",
              " 's we',\n",
              " ' we ',\n",
              " 'we c',\n",
              " 'e co',\n",
              " ' cou',\n",
              " 'coul',\n",
              " 'ould',\n",
              " 'uld ',\n",
              " 'ld p',\n",
              " 'd pl',\n",
              " ' pla',\n",
              " 'play',\n",
              " 'lay,',\n",
              " 'ay,\"',\n",
              " 'y,\"\\n',\n",
              " ',\"\\nS',\n",
              " '\"\\nSa',\n",
              " '\\nSai',\n",
              " 'Said',\n",
              " 'aid ',\n",
              " 'id t',\n",
              " 'd th',\n",
              " ' the',\n",
              " 'the ',\n",
              " 'he c',\n",
              " 'e ca',\n",
              " ' cat',\n",
              " 'cat.',\n",
              " 'at.\\n',\n",
              " 't.\\n\"',\n",
              " '.\\n\"I',\n",
              " '\\n\"I ',\n",
              " '\"I k',\n",
              " 'I kn',\n",
              " ' kno',\n",
              " 'know',\n",
              " 'now ',\n",
              " 'ow s',\n",
              " 'w so',\n",
              " ' som',\n",
              " 'some',\n",
              " 'ome ',\n",
              " 'me n',\n",
              " 'e ne',\n",
              " ' new',\n",
              " 'new ',\n",
              " 'ew t',\n",
              " 'w tr',\n",
              " ' tri',\n",
              " 'tric',\n",
              " 'rick',\n",
              " 'icks',\n",
              " 'cks,',\n",
              " 'ks,\"',\n",
              " 's,\"\\n',\n",
              " ',\"\\nS',\n",
              " '\"\\nSa',\n",
              " '\\nSai',\n",
              " 'Said',\n",
              " 'aid ',\n",
              " 'id t',\n",
              " 'd th',\n",
              " ' the',\n",
              " 'the ',\n",
              " 'he C',\n",
              " 'e Ca',\n",
              " ' Cat',\n",
              " 'Cat ',\n",
              " 'at i',\n",
              " 't in',\n",
              " ' in ',\n",
              " 'in t',\n",
              " 'n th',\n",
              " ' the',\n",
              " 'the ',\n",
              " 'he H',\n",
              " 'e Ha',\n",
              " ' Hat',\n",
              " 'Hat.',\n",
              " 'at.\\n',\n",
              " 't.\\n\"',\n",
              " '.\\n\"A',\n",
              " '\\n\"A ',\n",
              " '\"A l',\n",
              " 'A lo',\n",
              " ' lot',\n",
              " 'lot ',\n",
              " 'ot o',\n",
              " 't of',\n",
              " ' of ',\n",
              " 'of g',\n",
              " 'f go',\n",
              " ' goo',\n",
              " 'good',\n",
              " 'ood ',\n",
              " 'od t',\n",
              " 'd tr',\n",
              " ' tri',\n",
              " 'tric',\n",
              " 'rick',\n",
              " 'icks',\n",
              " 'cks.',\n",
              " 'ks.\\n',\n",
              " 's.\\nI',\n",
              " '.\\nI ',\n",
              " '\\nI w',\n",
              " 'I wi',\n",
              " ' wil',\n",
              " 'will',\n",
              " 'ill ',\n",
              " 'll s',\n",
              " 'l sh',\n",
              " ' sho',\n",
              " 'show',\n",
              " 'how ',\n",
              " 'ow t',\n",
              " 'w th',\n",
              " ' the',\n",
              " 'them',\n",
              " 'hem ',\n",
              " 'em t',\n",
              " 'm to',\n",
              " ' to ',\n",
              " 'to y',\n",
              " 'o yo',\n",
              " ' you',\n",
              " 'you.',\n",
              " 'ou.\\n',\n",
              " 'u.\\nY',\n",
              " '.\\nYo',\n",
              " '\\nYou',\n",
              " 'Your',\n",
              " 'our ',\n",
              " 'ur m',\n",
              " 'r mo',\n",
              " ' mot',\n",
              " 'moth',\n",
              " 'othe',\n",
              " 'ther',\n",
              " 'her\\n',\n",
              " 'er\\nW',\n",
              " 'r\\nWi',\n",
              " '\\nWil',\n",
              " 'Will',\n",
              " 'ill ',\n",
              " 'll n',\n",
              " 'l no',\n",
              " ' not',\n",
              " 'not ',\n",
              " 'ot m',\n",
              " 't mi',\n",
              " ' min',\n",
              " 'mind',\n",
              " 'ind ',\n",
              " 'nd a',\n",
              " 'd at',\n",
              " ' at ',\n",
              " 'at a',\n",
              " 't al',\n",
              " ' all',\n",
              " 'all ',\n",
              " 'll i',\n",
              " 'l if',\n",
              " ' if ',\n",
              " 'if I',\n",
              " 'f I ',\n",
              " ' I d',\n",
              " 'I do',\n",
              " ' do.',\n",
              " 'do.\"',\n",
              " 'o.\"\\n',\n",
              " '.\"\\n\\n',\n",
              " '\"\\n\\nC',\n",
              " '\\n\\nCH',\n",
              " '\\nCHA',\n",
              " 'CHAP',\n",
              " 'HAPT',\n",
              " 'APTE',\n",
              " 'PTER',\n",
              " 'TER ',\n",
              " 'ER T',\n",
              " 'R TH',\n",
              " ' THR',\n",
              " 'THRE',\n",
              " 'HREE',\n",
              " 'REE\\n',\n",
              " 'EE\\nT',\n",
              " 'E\\nTh',\n",
              " '\\nThe',\n",
              " 'Then',\n",
              " 'hen ',\n",
              " 'en S',\n",
              " 'n Sa',\n",
              " ' Sal',\n",
              " 'Sall',\n",
              " 'ally',\n",
              " 'lly ',\n",
              " 'ly a',\n",
              " 'y an',\n",
              " ' and',\n",
              " 'and ',\n",
              " 'nd I',\n",
              " 'd I\\n',\n",
              " ' I\\nD',\n",
              " 'I\\nDi',\n",
              " '\\nDid',\n",
              " 'Did ',\n",
              " 'id n',\n",
              " 'd no',\n",
              " ' not',\n",
              " 'not ',\n",
              " 'ot k',\n",
              " 't kn',\n",
              " ' kno',\n",
              " 'know',\n",
              " 'now ',\n",
              " 'ow w',\n",
              " 'w wh',\n",
              " ' wha',\n",
              " 'what',\n",
              " 'hat ',\n",
              " 'at t',\n",
              " 't to',\n",
              " ' to ',\n",
              " 'to s',\n",
              " 'o sa',\n",
              " ' say',\n",
              " 'say.',\n",
              " 'ay.\\n',\n",
              " 'y.\\nO',\n",
              " '.\\nOu',\n",
              " '\\nOur',\n",
              " 'Our ',\n",
              " 'ur m',\n",
              " 'r mo',\n",
              " ' mot',\n",
              " 'moth',\n",
              " 'othe',\n",
              " 'ther',\n",
              " 'her ',\n",
              " 'er w',\n",
              " 'r wa',\n",
              " ' was',\n",
              " 'was ',\n",
              " 'as o',\n",
              " 's ou',\n",
              " ' out',\n",
              " 'out ',\n",
              " 'ut o',\n",
              " 't of',\n",
              " ' of ',\n",
              " 'of t',\n",
              " 'f th',\n",
              " ' the',\n",
              " 'the ',\n",
              " 'he h',\n",
              " 'e ho',\n",
              " ' hou',\n",
              " 'hous',\n",
              " 'ouse',\n",
              " 'use\\n',\n",
              " 'se\\nF',\n",
              " 'e\\nFo',\n",
              " '\\nFor',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {
        "id": "SKnb3cwTbN6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type in the above code and be sure to experiment. You should be able to parse this out:\n",
        " * Experiment with some simple sentences\n",
        " * 'Prove' to yourself that if there is M words, the number of ngrams would  be M - (n - 1)\n",
        " * words[i:i+n] is just a slice n long of the array words \n",
        " * [ slice for i in range(total) ]"
      ],
      "metadata": {
        "id": "k_I16OcHbTgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Zip Me UP**\n",
        "We have seen that working with parallel arrays can be cumbersome. The Python zip function can help manage the situation by taking different arrays and combining them into tuples: (Be sure to run and understand what is happening)."
      ],
      "metadata": {
        "id": "Z-jJEWnXcDvT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "players = [\"A. Gordon\", \"A. Holiday\", \"A. Nader\"]\n",
        "teams = [\"ORL\", \"IND\", \"OKC\"]\n",
        "y_old = [23, 22, 25]\n",
        "h_ins = [81, 73, 78]\n",
        "w_lbs = [220, 185, 225]\n",
        "\n",
        "values = zip(players, teams, y_old, h_ins, w_lbs)\n",
        "for t in values:\n",
        "  print(t)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('A. Gordon', 'ORL', 23, 81, 220)\n",
            "('A. Holiday', 'IND', 22, 73, 185)\n",
            "('A. Nader', 'OKC', 25, 78, 225)\n"
          ]
        }
      ],
      "metadata": {
        "id": "f6r5HecLcMGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The zip function returns an object (i.e. a custom type) that can be used as an iterator.\n",
        "If you want all the items in a list or you want access to a specific element, you simply convert the output into a list:"
      ],
      "metadata": {
        "id": "0kY1kmmVcUu-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "values = zip(players, teams, y_old, h_ins, w_lbs)\n",
        "dataset = list(values)\n",
        "print(dataset)\n",
        "print(dataset[1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('A. Gordon', 'ORL', 23, 81, 220), ('A. Holiday', 'IND', 22, 73, 185), ('A. Nader', 'OKC', 25, 78, 225)]\n",
            "('A. Holiday', 'IND', 22, 73, 185)\n"
          ]
        }
      ],
      "metadata": {
        "id": "9KoOf39lcWCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we have to recreate the value assigned to values. Once you iterate though the object, it is essentially empty.\n",
        "\n",
        "With zip and list comprehensions, we can even create a dictionary of data from parallel arrays:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "values = list(zip(players, teams, y_old, h_ins, w_lbs))\n",
        "keys = ['p{}'.format(i) for i in range(len(values))]\n",
        "dataset = {k:v for k,v in zip(keys, values)}\n",
        "print(dataset)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "N81i7JWycuOW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "#type in the above code\n",
        "\n",
        "values = list(zip(players, teams, y_old, h_ins, w_lbs))\n",
        "keys = ['p{}'.format(i) for i in range(len(values))]\n",
        "dataset = {k:v for k,v in zip(keys, values)}\n",
        "print(dataset)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'p0': ('A. Gordon', 'ORL', 23, 81, 220), 'p1': ('A. Holiday', 'IND', 22, 73, 185), 'p2': ('A. Nader', 'OKC', 25, 78, 225)}\n"
          ]
        }
      ],
      "metadata": {
        "id": "jfw9scCyc5kY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example: Building columns from rows using zip**\n",
        "\n",
        "Here's a more complex example of using zip to wrangle your data from one format to another. Look at the following familiar dataset. Our goal is to easily get a full column of values in a single list (or tuple). For example, the first column would be ['a',1,4,7] as a list or ('a',1,4,7) as a tuple\n",
        "\n",
        "```\n",
        "a, b, c\n",
        "1, 2, 3\n",
        "4, 5, 6\n",
        "7, 8, 9\n",
        "```\n"
      ],
      "metadata": {
        "id": "iOBtjwiUdAXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So for this matrix (or table) of data, we want to get the 3 columns of data. Each column will have 4 items. This is an example of a column vector.\n",
        "\n",
        "**Set Up**\n",
        "\n",
        "We can easily read this data into a list of lists. So the first row is the header, the second row is the list [1,2,3], etc. You will want to be sure this code is run before all of the following examples.\n",
        "Before you run this code, try to figure out what gets printed on the last line.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "table = [\n",
        "['a','b','c'],\n",
        "[ 1,  2,  3],\n",
        "[ 4,  5,  6],\n",
        "[ 7,  8,  9] ]\n",
        "\n",
        "header = table[0]\n",
        "rows   = table[1:]  # this right here, is why we love slicing\n",
        "print(header, rows)\n",
        "print(rows[1][1])   # what gets printed here (figure it out before running)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "yjqoznQYdYPH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "#type in the above code\n",
        "\n",
        "table = [\n",
        "['a','b','c'],\n",
        "[ 1,  2,  3],\n",
        "[ 4,  5,  6],\n",
        "[ 7,  8,  9] ]\n",
        "\n",
        "header = table[0]\n",
        "rows   = table[1:]  # this right here, is why we love slicing\n",
        "print(header, rows)\n",
        "print(rows[1][1])   # what gets printed here (figure it out before running)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c'] [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
            "5\n"
          ]
        }
      ],
      "metadata": {
        "id": "JFHg-aTTc_pM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So for this matrix (or table) of data, we want to get the 3 columns of data.\n",
        "\n",
        "**Attempt 1:**\n",
        "\n",
        "Our first attempt will be to use the list concatenation operator '+':"
      ],
      "metadata": {
        "id": "AUxHdNdGdwVY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "column0 = header + rows[0]\n",
        "print(column0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 1, 2, 3]\n"
          ]
        }
      ],
      "metadata": {
        "id": "ZrSSRS5Xd3QH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is not what we wanted. Does the output make sense to you? \n",
        "\n",
        "However, even if you wanted do the following:\n",
        "\n",
        "```\n",
        "t = header[0] + str(rows[0][0]) + str(rows[1][0]) + str(rows[2][0])\n",
        "print(t)\n",
        "```\n",
        "The data is hard coded. You want to be able to build this regardless of the numbers of rows in the dataset."
      ],
      "metadata": {
        "id": "XWwL0Xu3d6hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attempt 2:**\n",
        "\n",
        "You could try to use enumeration:"
      ],
      "metadata": {
        "id": "uqgnFRqdeFVA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "out = []\n",
        "for i in range(0, len(header)):\n",
        "  l = header[i]\n",
        "  v = rows[i]\n",
        "  out.append( (l,v) )\n",
        "print(out)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('a', [1, 2, 3]), ('b', [4, 5, 6]), ('c', [7, 8, 9])]\n"
          ]
        }
      ],
      "metadata": {
        "id": "_7PIN7hIeVjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is closer. It at least builds an array of tuples .. wrong values though. Before continuing, think about what you would try next. You will get so much more out of this lesson if you try to solve it first.\n",
        "\n",
        "**Attempt 3: We need one more loop:**\n",
        "\n",
        "```\n",
        "out = []\n",
        "for i in range(0, len(header)):\n",
        "  l = header[i]\n",
        "  row = rows[i]\n",
        "  for j in range(0, len(row)):\n",
        "    v = row[j]\n",
        "    out.append( (l,v) )\n",
        "print(out)\n",
        "```\n",
        "Does that work?\n",
        "\n",
        "That is a lot of code. But it's important that you understand what is happening.\n",
        "\n",
        "We are looping through the rows in the table (i is the row index). Then for each row, we are looping for each of the values found at row i (j is the column index). So any cell is at table[i][j].\n",
        "\n",
        "**Attempt 4:**\n",
        "\n",
        "Let's try to use zip for solving this. As we have seen, zip works great if you have all your arrays ahead of time. Every parameter is suppose to be a list that will be \"zipped up\" with the other parameters. If we pass in a list for its parameters, zip will do the wrong thing:\n",
        "\n",
        "```\n",
        "print(rows)\n",
        "print(list(zip(rows)))\n",
        "```"
      ],
      "metadata": {
        "id": "uJC4x8BleZwu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# type&run the above example/exercise in this cell\n",
        "\n",
        "out = []\n",
        "for i in range(0, len(header)):\n",
        "  l = header[i]\n",
        "  row = rows[i]\n",
        "  for j in range(0, len(row)):\n",
        "    v = row[j]\n",
        "    out.append( (l,v) )\n",
        "print(out)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('a', 1), ('a', 2), ('a', 3), ('b', 4), ('b', 5), ('b', 6), ('c', 7), ('c', 8), ('c', 9)]\n"
          ]
        }
      ],
      "metadata": {
        "id": "sXMgKPvRtGDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function zip is looking for multiple arguments to zip up. In the above example, the zip function is only being passed one parameter (the rows).\n",
        "\n",
        "**\"Fixing\" zip:**\n",
        "\n",
        "As we have seen Python has a special 'operator', the âœ±, that basically takes a list, and flattens it into its single elements:"
      ],
      "metadata": {
        "id": "OCDj40p-fGpi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "items = [1,2,3]\n",
        "print(items)\n",
        "print(*items)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3]\n",
            "1 2 3\n"
          ]
        }
      ],
      "metadata": {
        "id": "LyHJnGCyfOpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We can use that operator on the list we pass into zip. This operator will essentially pass each row to zip as a separate argument:\n",
        "\n",
        "```\n",
        "print(list(zip(*rows)))\n",
        "```"
      ],
      "metadata": {
        "id": "QM1L-iW3fSFH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "# type&run the above example/exercise in this cell\n",
        "\n",
        "print(rows)\n",
        "print(list(zip(*rows)))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
            "[(1, 4, 7), (2, 5, 8), (3, 6, 9)]\n"
          ]
        }
      ],
      "metadata": {
        "id": "tQ2ML0ibffUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh WOW. So close. Make sure you can take apart that syntax and understand how it works. \n",
        "\n",
        "So zip(*rows) is similar to saying:\n",
        "\n",
        "zip(rows[0], rows[1], rows[2])\n",
        "\n",
        "But we never had to hard code the parameters (those numbers, 0, 1, 2 are 'hard coded'). If the number of rows in the table changes, we won't have to change our code.\n",
        "\n",
        "**Zipping It Up (finally)**\n",
        "```\n",
        "table = [\n",
        "   ['a','b','c'],\n",
        "   [1,2,3],\n",
        "   [4,5,6],\n",
        "   [7,8,9]\n",
        "]\n",
        "print(list(zip(*table)))\n",
        "```"
      ],
      "metadata": {
        "id": "jYNtQ3bUfZ8K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# type&run the above example/exercise in this cell\n",
        "\n",
        "table = [\n",
        "   ['a','b','c'],\n",
        "   [1,2,3],\n",
        "   [4,5,6],\n",
        "   [7,8,9]\n",
        "]\n",
        "print(list(zip(*table)))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('a', 1, 4, 7), ('b', 2, 5, 8), ('c', 3, 6, 9)]\n"
          ]
        }
      ],
      "metadata": {
        "id": "cbRzOx24fW0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That syntax can be formidable, but once you know what zip does and how the operator works, reading complex syntax becomes a bit easier.\n",
        "\n",
        "#**Ngrams Revisited (Again)**\n",
        "\n",
        "We can use zip to build ngrams as well. Lets start with some simple data:\n",
        "\n",
        "words = \"The sun did not shine It was too wet to play\".split()\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1yUmDI0UrAlXYM2317_8hVtO_JdXiTbBD)\n"
      ],
      "metadata": {
        "id": "ZzXc_YCLfv84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "\n",
        "words = \"The sun did not shine It was too wet to play\".split()\n",
        "words"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'sun', 'did', 'not', 'shine', 'It', 'was', 'too', 'wet', 'to', 'play']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bi-grams**\n",
        "\n",
        "For creating bi-grams, we pass in the words AND the words after removing the first word:\n",
        "\n",
        "```\n",
        "# bi-grams\n",
        "words = \"The sun did not shine It was too wet to play\".split()\n",
        "bigrams = list(zip(words, words[1:]))\n",
        "print(bigrams)\n",
        "```"
      ],
      "metadata": {
        "id": "pRYlMQftpwBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# type&run the above example/exercise in this cell\n",
        "\n",
        "# bi-grams\n",
        "words = \"The sun did not shine It was too wet to play\".split()\n",
        "bigrams = list(zip(words, words[1:]))\n",
        "print(bigrams)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'sun'), ('sun', 'did'), ('did', 'not'), ('not', 'shine'), ('shine', 'It'), ('It', 'was'), ('was', 'too'), ('too', 'wet'), ('wet', 'to'), ('to', 'play')]\n"
          ]
        }
      ],
      "metadata": {
        "id": "aKSKQ1XEgobV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tri-grams**\n",
        "\n",
        "For tri-grams, it's now 3 lists we need to pass to zip:\n",
        "\n",
        "```\n",
        "# tri-grams\n",
        "trigrams = list(zip(words, words[1:], words[2:]))\n",
        "print(trigrams)\n",
        "```"
      ],
      "metadata": {
        "id": "8QGG8dzOg3KY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# type&run the above example/exercise in this cell\n",
        "\n",
        "# tri-grams\n",
        "trigrams = list(zip(words, words[1:], words[2:]))\n",
        "print(trigrams)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'sun', 'did'), ('sun', 'did', 'not'), ('did', 'not', 'shine'), ('not', 'shine', 'It'), ('shine', 'It', 'was'), ('It', 'was', 'too'), ('was', 'too', 'wet'), ('too', 'wet', 'to'), ('wet', 'to', 'play')]\n"
          ]
        }
      ],
      "metadata": {
        "id": "Mptxb6_xg-wS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **N-grams**\n",
        "\n",
        "Do you see a pattern ?\n",
        "\n",
        "* What's the pattern for 4 words ?\n",
        "* ``` zip(words, words[1:], words[2:], words[3:])```\n",
        "\n",
        "We can generalize the parameter pattern using words and n:\n",
        "\n",
        "* ```slices = [words[i:] for i in range(n)]```\n",
        "\n",
        "and then pass the slices to zip:\n",
        "* ```ngrams = zip( *slices )```\n",
        "\n",
        "\n",
        "Once again, be certain you understand why we need to unpack the slices before sending them to zip. Finally, putting it all together:\n",
        "\n",
        "```\n",
        "def find_ngrams_v1(words, n):\n",
        "  return zip(*[words[i:] for i in range(n)])\n",
        "print(list(find_ngrams_v1(words, 3)))\n",
        "```"
      ],
      "metadata": {
        "id": "Biq4_dHqhGZf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# type&run the above example/exercise in this cell\n",
        "\n",
        "def find_ngrams_v1(words, n):\n",
        "  return zip(*[words[i:] for i in range(n)])\n",
        "print(list(find_ngrams_v1(words, 3)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'sun', 'did'), ('sun', 'did', 'not'), ('did', 'not', 'shine'), ('not', 'shine', 'It'), ('shine', 'It', 'was'), ('It', 'was', 'too'), ('was', 'too', 'wet'), ('too', 'wet', 'to'), ('wet', 'to', 'play')]\n"
          ]
        }
      ],
      "metadata": {
        "id": "BmWklMIkiKhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Joining lists**\n",
        "\n",
        "If you ever want to present ngrams as a unified string, just use string's join method with each of the ngram's list:\n",
        "\n",
        "```\n",
        "def find_ngrams_v2(words, n):\n",
        "  ngrams = zip(*[words[i:] for i in range(n)])\n",
        "  return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "print(list(find_ngrams_v2(words, 3)))\n",
        "```\n",
        "\n",
        "That was easy !! Take a look at the find_ngrams_v2.\n",
        "\n",
        "At first glance, it may seem impossible to understand but you now have the tools to unpack complex Pythonic code that you will see out in the wild."
      ],
      "metadata": {
        "id": "pphL-rB5iPAH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "# type&run the above example/exercise in this cell\n",
        "\n",
        "def find_ngrams_v2(words, n):\n",
        "  ngrams = zip(*[words[i:] for i in range(n)])\n",
        "  return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "print(list(find_ngrams_v2(words, 3)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The sun did', 'sun did not', 'did not shine', 'not shine It', 'shine It was', 'It was too', 'was too wet', 'too wet to', 'wet to play']\n"
          ]
        }
      ],
      "metadata": {
        "id": "SMkbBVEMjbXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Review**\n",
        "\n",
        "Before you go, you should know:\n",
        "\n",
        "* What does zip do?\n",
        "\n",
        "* What do you pass into zip?\n",
        "\n",
        "* What is the return type of zip?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SnZeznqgjpc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`## type in your answers to the above review questions ##`\n",
        "\n",
        "1. zip can make a list of the corresponding tokens in a series of list\n",
        "2. we pass in a list of lists\n",
        "3. zip() return a interator object, but we can convert it to a list"
      ],
      "metadata": {
        "id": "rsZqN7SxoSJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lesson Assignment:**\n",
        "\n",
        "Be sure to type in all the examples first. For this lesson you will build on find_ngrams_v2.\n",
        "\n",
        "**Create it**\n",
        "\n",
        "Create a function named find_ngrams_bow:\n",
        "\n",
        "* it has 4 parameters (words, n, bow=False, stopwords=[])\n",
        "* words is a list of tokens/words\n",
        "* each word should be converted to lowercase\n",
        "* if bow is True, create ngrams such that order of the ngram words is no longer considered. Hence, each ngram is simply a bag-of-words (BOW). You can implement this by always using the alphabetical order for the words. For example the two ngrams, 'he said fine' and 'fine he said' would be the same ngram in the BOW model.\n",
        "* if stopwords contains words, those words should not be considered part of the text\n",
        "\n",
        "\n",
        "```\n",
        "import Collections\n",
        "def find_ngrams_bow():\n",
        "   return []\n",
        "\n",
        "def simple_test():\n",
        "  text = read_data_file('hp1.txt')\n",
        "  ngrams = find_ngrams_bow(text.split(), 3)\n",
        "  top5 = collections.Counter(ngrams).most_common(5)\n",
        "  print(top5)\n",
        "\n",
        "expected output of simple_test():\n",
        "[('of out the', 63), ('and harry ron', 51), ('end of the', 35), ('of rest the', 34), ('and hermione ron', 32)]\n",
        "```\n"
      ],
      "metadata": {
        "id": "t1BRzloRoPpj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "import collections\n",
        "def find_ngrams_bow(tokens, gram, bow=False, stopwords=[]):\n",
        "  \n",
        "  if not stopwords == []:\n",
        "    for word in stopwords:\n",
        "      while word in tokens:\n",
        "        tokens.remove(word)\n",
        "\n",
        "  n_grams = find_ngrams_v1(tokens, gram)\n",
        "\n",
        "  if bow:\n",
        "    n_grams = [tuple(sorted(g)) for g in n_grams]\n",
        "\n",
        "  return n_grams\n",
        "\n",
        "def simple_test(data_file='hp1.txt', ngrams=3, bow=False, stopwords=[], most_com=5):\n",
        "  text = read_data_file(data_file)\n",
        "  ngrams = find_ngrams_bow(text.split(), ngrams, bow=bow, stopwords=stopwords)\n",
        "  top5 = collections.Counter(ngrams).most_common(most_com)\n",
        "  print(top5)\n",
        "\n",
        "simple_test()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('out', 'of', 'the'), 63), (('harry', 'and', 'ron'), 36), (('ron', 'and', 'hermione'), 32), (('in', 'front', 'of'), 25), (('seemed', 'to', 'be'), 22)]\n"
          ]
        }
      ],
      "metadata": {
        "id": "c1WyyoCQqXDi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "set([1, 2, 3]).difference(set([3, 4]))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1, 2}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Use it**\n",
        "\n",
        "With everything working, you will now use find_ngrams_bow to help support your research: \n",
        "\n",
        "**Question 1: write a function named q1 that takes no parameters.**\n",
        "\n",
        "The function will use find_ngrams_bow to answer the following question:\n",
        "\n",
        "As the n in ngrams increases, would you expect the BOW ngram counts to be higher or lower than non-BOW version?\n",
        "\n",
        "* make sure you understand the question\n",
        "* answer it BEFORE writing any code\n",
        "* now write the code inside q1 that will help you confirm/deny your answer. You can use any method you want (print statements, analytical calculations, etc).\n",
        "* q1 provides evidence to support the truth"
      ],
      "metadata": {
        "id": "Bc89ScJ9mKgz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "source": [
        "#expectation: ngrams increase will let counts of grams decrease\n",
        "\n",
        "def q1():\n",
        "\tfor n in range(1, 5):\n",
        "\t\tprint('ngrams={}'.format(n))\n",
        "\t\tprint(simple_test(ngrams=n))\n",
        "\n",
        "\n",
        "q1()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrams=1\n",
            "[(('the',), 3626), (('and',), 1920), (('to',), 1857), (('he',), 1528), (('of',), 1258)]\n",
            "None\n",
            "ngrams=2\n",
            "[(('of', 'the'), 286), (('in', 'the'), 270), (('on', 'the'), 217), (('it', 'was'), 207), (('he', 'was'), 195)]\n",
            "None\n",
            "ngrams=3\n",
            "[(('out', 'of', 'the'), 63), (('harry', 'and', 'ron'), 36), (('ron', 'and', 'hermione'), 32), (('in', 'front', 'of'), 25), (('seemed', 'to', 'be'), 22)]\n",
            "None\n",
            "ngrams=4\n",
            "[(('the', 'rest', 'of', 'the'), 15), (('in', 'front', 'of', 'the'), 12), (('out', 'of', 'the', 'way'), 12), (('he', 'was', 'going', 'to'), 11), (('the', 'three', 'of', 'them'), 11)]\n",
            "None\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: write a function named q2 that takes no parameters.**\n",
        "\n",
        "The function will use find_ngrams_bow to answer the following question:\n",
        "\n",
        "If you add stopwords, should you see higher or lower counts in your ngrams?\n",
        "\n",
        "* make sure you understand the question\n",
        "* answer it BEFORE writing any code\n",
        "* now write the code inside q2 that will help you confirm/deny your answer. You can use any method you want (print statements, analytical calculations, etc).\n",
        "* q2 provides evidence to support the truth"
      ],
      "metadata": {
        "id": "y8GfNPkwm0hC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "source": [
        "# adding stoprwords will decrease the count of the grams \n",
        "\n",
        "\n",
        "def load_stopwords(extra=[]):\n",
        "    return extra + ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n",
        "\n",
        "\n",
        "def q2():\n",
        "\tstopword_lists = [[], load_stopwords()]\n",
        "\tfor stopwords in stopword_lists:\n",
        "\t\tprint('stopwords={}'.format(stopwords))\n",
        "\t\tprint(simple_test(stopwords=stopwords))\n",
        "\n",
        "q2()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopwords=[]\n",
            "[(('out', 'of', 'the'), 63), (('harry', 'and', 'ron'), 36), (('ron', 'and', 'hermione'), 32), (('in', 'front', 'of'), 25), (('seemed', 'to', 'be'), 22)]\n",
            "None\n",
            "stopwords=['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n",
            "[(('said', 'professor', 'mcgonagall'), 16), (('nimbus', 'two', 'thousand'), 14), (('said', 'uncle', 'vernon'), 13), (('harry', 'ron', 'hermione'), 10), (('said', 'hagrid', 'harry'), 7)]\n",
            "None\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps to submit your work:**\n",
        "\n",
        "\n",
        "1.   Download the notebook from Moodle. It is recommended that you use Google Colab to work on it.\n",
        "2.   Upload any supporting files using file upload option within Google Colab.\n",
        "3.   Complete the exercises and/or assignments\n",
        "4.   Download as .ipynb\n",
        "5.   Name the file as \"lastname_firstname_WeekNumber.ipynb\"\n",
        "6.   After following the above steps, submit the final file in Moodle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h1><center>The End!</center></h1>"
      ],
      "metadata": {
        "id": "bLL5cpOrtq0v"
      }
    }
  ]
}