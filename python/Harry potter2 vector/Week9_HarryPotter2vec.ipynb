{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXaGN9j_ZSJe"
      },
      "source": [
        "# **Harry Potter 2 Vec**\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=10NHEpBSv-bQTZ0hMJRpJ-RqD66rrtJDR)\n",
        "\n",
        "In previous lessons, you learned about both word embeddings and how to create them using gensim's Word2Vec. In this lesson, we are going to build our own word vector model using the text of Harry Potter.\n",
        "\n",
        "Ideally, the model can then be used to find Harry Potter word analogies. For example, if you had the word vectors for the Harry Potter books, you could ask:\n",
        "                            \n",
        "                             Ron - man + woman = ?\n",
        "\n",
        "Hopefully, you would get Hermione.\n",
        "\n",
        "This lesson will ask you to build the best possible model. We will guide you through the steps and you can submit your best model for the assignment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJCp6lWYZrLn"
      },
      "source": [
        "##**Hyperparameters and Model Evaluation**\n",
        "\n",
        "The goal of this lesson is for you to experiment with the different hyperparameters to gensim's Word2Vec model. As a quick review, **hyperparameters** are those values or parameters that the model is not learning or trying to optimize, but rather are used to configure the algorithm. Examples include the 'K' in **K**â€¢means, the degree of polynomial to use in regression, number of levels in a decision tree, the learning rate, and number of layers and nodes in a neural network. For Word2Vec there are a [multiple](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) parameters with which to experiment.\n",
        "\n",
        "You will also build your own scoring system to evaluate the different models you create. We have so much to discuss, so let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFwZb8rLZzBQ"
      },
      "source": [
        "#**Building the Harry Potter Corpus**\n",
        "\n",
        "All 7 Harry Potter books are available in Moodle. You need to download them and upload in Colab using Colab's upload file option.\n",
        "\n",
        "Each book is a single 'sentence', cleaned and tokenized. The function read_one shows how to read a single Harry Potter book.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def read_one():\n",
        "  path = 'hp1.txt'\n",
        "  book = open(path, 'r').read()\n",
        "  return book\n",
        "```\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1C-l6Bg25X1-y7wPYlweVNuWRFgtVcTei)\n",
        "\n",
        "\n",
        "You will need to finish the build_hp_dataset implementation.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def build_hp_dataset(count=3, stopwords=[]):\n",
        "  # count is the number of documents in the corpus (harry potter books)\n",
        "  # each document is an array of words\n",
        "  # remove any stopwords\n",
        "  # returns an array of documents (same size as count)\n",
        "  return []\n",
        "```\n",
        "\n",
        "* You are free to experiment using any number of books from the collections; however, **only books 1-3** will be used for evaluation.\n",
        "* You should remove stopwords if any are passed in.\n",
        "* You can get a list of words from a book by doing a simple split on the content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import ssl\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import re\n",
        "import LessonUtil as Util\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import httpimport\n",
        "url = \"https://raw.githubusercontent.com/zhu-jun-ting/INFO-490-MH2/main/\"\n",
        "with httpimport.remote_repo([\"util\"], url):\n",
        "    import util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pcr-5U8fWlQg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_hp(number):\n",
        "    path = 'data/hp{}.txt'.format(number)\n",
        "    with open(path, 'r') as book:\n",
        "        text = book.read()\n",
        "    return text\n",
        "\n",
        "def build_hp_dataset(count=3, stopwords=[]):\n",
        "    # count is the number of documents in the corpus (harry potter books)\n",
        "    # each document is an array of words\n",
        "    # remove any stopwords\n",
        "    # returns an array of documents (same size as count)\n",
        "\n",
        "    hp = \"\"\n",
        "    for i in range(1, count+1):\n",
        "        hp += read_hp(i)\n",
        "\n",
        "    hp = hp.split()\n",
        "\n",
        "    return hp\n",
        "\n",
        "corpus = build_hp_dataset(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaTBNbxnawk7"
      },
      "source": [
        "#**Building the Model**\n",
        "\n",
        "You will build a word embedding model using Word2Vec. The next section will describe how to create a configuration for build_model to use.\n",
        "\n",
        "A few notes:\n",
        "* most of the configuartion values are coming from the config parameter\n",
        "* you are free to add additional parameters to see if you can build an awesome model; however, for the lesson, only the above parameters in a configuration will be used.\n",
        "* iter is capped at 100\n",
        "* size is capped at 300\n",
        "* the [Word2Vec documentation](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) should be used for additional details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D3rygQjNa_lM"
      },
      "outputs": [],
      "source": [
        "def build_model(config):\n",
        "\n",
        "    # no need to change anything\n",
        "    model = gensim.models.Word2Vec(\n",
        "        config.doc,                   # each sentence is a HP book\n",
        "        size=min(config.size,300),    # how big the output vectors (spacy == 300)\n",
        "        window=config.window,         # size of window around the target word\n",
        "        min_count=config.min_count,   # ignore words that occur less than 2 times\n",
        "        sg=config.sg,                 # 0 == CBOW (default) 1 == skip gram\n",
        "        \n",
        "        negative=config.negative,\n",
        "        # keep these the same\n",
        "        workers=1,  # threads to use\n",
        "        iter=min(config.iter, 100)  # max iterations is 100,\n",
        "        )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUEhR5-Mbt_k"
      },
      "source": [
        "#**Configuring the Model**\n",
        "\n",
        "Now that you know how the model will be built AND you have your corpus, the next step is to build a configuration to configure the Word2Vec model. This lesson comes with a special class that you will use to create a configuration object.\n",
        "\n",
        "```\n",
        "import LessonUtil as Util\n",
        "config = Util.build_config(corpus, size=75, window=15, iter=75)\n",
        "```\n",
        "\n",
        "Take a look below at how the configuration will be used to build a model:\n",
        "\n",
        "```\n",
        "def build_model(config):\n",
        "    return gensim.models.Word2Vec(sentences=config.doc, size=config.size, ... )\n",
        "```\n",
        "\n",
        "The configuration object has the following fields:\n",
        "\n",
        "```['doc', 'size', 'window', 'min_count', 'sg', 'negative', 'iter', 'name']```\n",
        "\n",
        "* The same hyperparameters that you can configure a Word2Vec model are in the configuration\n",
        "* The name field allows you to name the configuration if you want to keep track of it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pfx61XA7cEqa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Default config doc_len:262364, size:10, window:5, min_count:5, sg:0, negative:3, iter:25\n",
            "Custom config1 doc_len:262364, size:75, window:15, min_count:5, sg:0, negative:3, iter:75\n",
            "Custom config2 doc_len:262364, size:5, window:2, min_count:1, sg:1, negative:5, iter:30\n"
          ]
        }
      ],
      "source": [
        "default_config = Util.build_config(corpus)\n",
        "print(\"Default config\", default_config)\n",
        "\n",
        "config1 = Util.build_config(corpus, size=75, window=15, iter=75)\n",
        "config2 = Util.build_config(corpus, 5, 2, 1, 1, 5, 30)\n",
        "\n",
        "print(\"Custom config1\", config1)\n",
        "print(\"Custom config2\", config2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLqOHf3XcI2c"
      },
      "source": [
        "##**Preventing Randomness**\n",
        "\n",
        "Like most machine learning algorithms, randomization is introduced during initialization. This comes at the cost when trying to compare different versions of models. You can control some of this by setting workers=1.\n",
        "\n",
        "However, the results you get in this notebook will NOT be the same when you submit on gradescope. They should be close though."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDTo0M7KcTSB"
      },
      "source": [
        "#**Running with the model**\n",
        "We now have enough in place to start the process of building a Word2Vec model with Harry Potter Books. So Exciting. Below is a sample pipeline.\n",
        "\n",
        "Make sure you understand the pipeline inside simple_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOa7HkNecc10"
      },
      "outputs": [],
      "source": [
        "def simple_test():\n",
        "    # build the harry potter corpus\n",
        "    corpus = build_hp_dataset()\n",
        "\n",
        "    # build the configuration to try/experiment\n",
        "    config = Util.build_config(corpus, 5, 2, 1, 1, 5, 30)\n",
        "    \n",
        "    # build the model with this configuration\n",
        "    model  = build_model(config)\n",
        "    \n",
        "    # let's hope harry is in there\n",
        "    harry = model.wv['harry']\n",
        "    \n",
        "    # see who is similar to ron\n",
        "    print(model.wv.most_similar(positive=['ron']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoZotLV-cshA"
      },
      "source": [
        "What do you see? If you built a good model, would hope to see hermione near the top?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ige7Sh7vc3sC"
      },
      "source": [
        "#**Scoring the Model**\n",
        "\n",
        "Now with that in place, the fun begins. It is your job to find the best set of parameters (hyperparameters) to configure the Word2Vec model.\n",
        "\n",
        "The LessonUtil module has a set of tests you can use to evaluate your models. Each test looks like the following:\n",
        "\n",
        "```\n",
        "(['ron'],       [],       ['hermione', 'harry']),\n",
        "(['voldemort'], ['evil'], ['dumbledore']),\n",
        "```\n",
        "\n",
        "Each test has 3 components:\n",
        "\n",
        "* the first component is the positive vectors\n",
        "* the second component is the negative vectors\n",
        "* the third component is a set of possible answers\n",
        "\n",
        "Looking at the first example: (['ron'], [],['hermione', 'harry'])\n",
        "\n",
        "Here the **Ron** vector should be close to either (or both) the **Hermione**\n",
        "or **Harry** vector.\n",
        "\n",
        "Looking at the second example: (['voldemort'], ['evil'], ['dumbledore'])\n",
        "\n",
        "The vector that is the result of the **Voldemort** vector - the **evil** vector; the hope is that result vector is close/similar to the **Dumbledore**\n",
        "vector: veldemort - evil = dumbledore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epef9gG3a2xR"
      },
      "source": [
        "## **Lesson Assignment**\n",
        "After configuring the Word2Vec model with the best set of hyperparameters, test your best model with all (19) of the test cases give in the Util file.\n",
        "* ```result = model.wv.most_similar(positive=pos, negative=neg, topn=topn)```\n",
        "    *   Get the top 25 words (```topn = 25```)\n",
        "* Print out the results for all the test cases (when you submit the notebook, the results should be visible). \n",
        "<br><br>\n",
        "\n",
        "\n",
        "**Steps to submit your work:**\n",
        "\n",
        "\n",
        "1.   Download the lesson notebook from Moodle.\n",
        "2.   Upload any supporting files using file upload option within Google Colab.\n",
        "3.   Complete the exercises and/or assignments\n",
        "4.   Download as .ipynb\n",
        "5.   Name the file as \"lastname_firstname_WeekNumber.ipynb\"\n",
        "6.   After following the above steps, submit the final file in Moodle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h1><center>The End!</center></h1>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Week9_HarryPotter2vec.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
