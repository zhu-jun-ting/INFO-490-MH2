{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH7WDNgRmDBc"
      },
      "source": [
        "#**Word2Vec**\n",
        "The previous lesson on word embeddings introduced the idea of creating vectors from words. With these vectors we are able to 'math' on words and show relationships. More importantly, these word embeddings can be used as input into other ML algorithms.\n",
        "\n",
        "This lesson is all about how to create those vectors from text as well as how to use an already trained word embedding model.  \n",
        "\n",
        "#**What is word2vec?**\n",
        "\n",
        "Word2Vec is a machine learning algorithm developed in 2013. Specifically, it uses a neural network (2 layers) and is trained with unlabeled data. Since the data is raw text, there is no 'label' to work with, it's an unsupervised ML technique. You can read an overview and the [paper](https://arxiv.org/pdf/1301.3781.pdf).\n",
        "\n",
        "The open source project (https://github.com/tmikolov/word2vec) is written in C; however, the Python gensim (pronounced jen-sim) library provides a Python implementation.\n",
        "\n",
        "For this lesson, we are going to use a dataset from Kaggle regarding the make and model for cars. It is already included in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oF9H_TtFml3R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['make', 'model', 'year', 'engine', 'fuel', 'type', 'engine', 'hp', 'engine', 'cylinders', 'transmission', 'type', 'driven_wheels', 'number', 'of', 'doors', 'market', 'category', 'vehicle', 'size', 'vehicle', 'style', 'highway', 'mpg', 'city', 'mpg', 'popularity', 'msrp']\n",
            "['bmw', 'series', 'premium', 'unleaded', 'required', 'manual', 'rear', 'wheel', 'drive', 'luxury', 'compact', 'convertible']\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import gensim\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "def build_dataset_raw():\n",
        "  # here's an example of how to use a zipped (compressed) file\n",
        "  filename = 'cars.csv.gz'\n",
        "  # https://www.kaggle.com/CooperUnion/cardataset?select=data.csv\n",
        "  file = gzip.open(filename, 'rb')\n",
        "  # clean and tokenize the text\n",
        "  return [gensim.utils.simple_preprocess(line) for line in file]\n",
        "  \n",
        "def test_raw():\n",
        "  document = build_dataset_raw()\n",
        "  print(document[0])  # make note of the column names\n",
        "  print(document[10]) # row '9'\n",
        "  # print(document)\n",
        "test_raw()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YxlM3uxoEak"
      },
      "source": [
        "The above example shows how you open a compressed file in Python. Many data sets are very large and may only be available in a compressed format. The example also shows how you can use gensim to process data as well. You can [read](https://radimrehurek.com/gensim/utils.html#gensim.utils.simple_preprocess) about the gensim API (how to use the methods and functions) for pre-processing as well.\n",
        "\n",
        "Instead of using the raw data, let's make use of Pandas to help us clean the data. Take note of the compression parameter in read_csv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tftqXcSioH5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Factory Tuner', 'Luxury', 'High-Performance', 'Compact', 'BMW 1 Series M']\n",
            "['Luxury', 'Performance', 'Compact', 'BMW 1 Series', 'Convertible']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "def build_dataset():\n",
        "\n",
        "  # another way to read compressed data\n",
        "  filename = 'cars.csv.gz'\n",
        "  df_original = pd.read_csv(filename, compression='gzip')\n",
        "\n",
        "  # feature selection\n",
        "  # select the fields we want to train word2vec on\n",
        "  features = ['Make', 'Model', 'Market Category','Vehicle Size','Vehicle Style',\n",
        "              'Engine Fuel Type','Transmission Type','Driven_Wheels']\n",
        "  df = df_original[features]\n",
        "  ser = df['Make'] + ' ' + df['Model']\n",
        "  # print(ser)\n",
        "  df['Make_Model'] = ser\n",
        "  df = df.drop(labels=['Make', 'Model'], axis=1).reindex(columns=['Make_Model', 'Market Category','Vehicle Size','Vehicle Style','Engine Fuel Type','Transmission Type', 'Driven_Wheels']).reindex(columns=['Market Category','Vehicle Size', 'Make_Model', 'Vehicle Style','Engine Fuel Type','Transmission Type','Driven_Wheels'])\n",
        "\n",
        "  # print(df)\n",
        "  doc = []\n",
        "  for index, row in df.iterrows():\n",
        "    line = [r for v in row.values for r in str(v).split(',')]\n",
        "    doc.append(line)\n",
        "  return doc, df\n",
        "\n",
        "def test_pd_data():\n",
        "  document, df = build_dataset()\n",
        "  print(document[0][0:5])\n",
        "  print(document[1][0:5])\n",
        "\n",
        "test_pd_data()\n",
        "\n",
        "# ==> ['Factory Tuner', 'Luxury', 'High-Performance', 'Compact', 'Coupe']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8-DBK4R46hg"
      },
      "source": [
        "#**Exercise**\n",
        "Update build_dataset such that you will create the field Make_Model in the dataset. Be sure to add this field to the front of each line of the output. The new field Make_Model combines the fields Make and Model with a single space between them.\n",
        "Once this is finished, test_pd_data should print out the following:\n",
        "\n",
        "```\n",
        "['BMW 1 Series M', 'Factory Tuner', 'Luxury', 'High-Performance', 'Compact']\n",
        "```\n",
        "\n",
        "You should also confirm that there are 928 unique Make_Models in the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW_Vy4W1kcOg"
      },
      "source": [
        "#**Model Building**\n",
        "For creating word2vec models, gensim's Word2Vec class is available. It essentially implements the classic algorithm mentioned in the beginning. In the next code cell, re-type in the following:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def build_model_v0(doc):\n",
        "  model = gensim.models.Word2Vec(doc)\n",
        "  return model\n",
        "\n",
        "def test_v0():\n",
        "    document, df = build_dataset()\n",
        "    model = build_model_v0(document)\n",
        "    print(len(model.wv.vocab))\n",
        "\n",
        "test_v0()\n",
        "```\n",
        "\n",
        "Note that the .wv property of the model is the word vector object that provides access into the word vectors themselves.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'AUTOMATIC': 0, 'regular unleaded': 1, 'front wheel drive': 2, 'Compact': 3, 'Midsize': 4, 'nan': 5, 'rear wheel drive': 6, 'Luxury': 7, 'Sedan': 8, 'MANUAL': 9, 'Large': 10, '4dr SUV': 11, 'all wheel drive': 12, 'Performance': 13, 'Crossover': 14, 'premium unleaded (required)': 15, 'premium unleaded (recommended)': 16, 'four wheel drive': 17, 'High-Performance': 18, 'Coupe': 19, 'Hatchback': 20, 'Flex Fuel': 21, 'flex-fuel (unleaded/E85)': 22, 'Convertible': 23, '4dr Hatchback': 24, 'Crew Cab Pickup': 25, 'AUTOMATED_MANUAL': 26, 'Extended Cab Pickup': 27, 'Factory Tuner': 28, 'Wagon': 29, '2dr Hatchback': 30, 'Exotic': 31, 'Passenger Minivan': 32, 'Regular Cab Pickup': 33, 'Hybrid': 34, 'Diesel': 35, 'Chevrolet Silverado 1500': 36, 'diesel': 37, 'Toyota Tundra': 38, '2dr SUV': 39, 'Passenger Van': 40, 'Ford F-150': 41, 'Cargo Van': 42, 'GMC Sierra 1500': 43, 'Volkswagen Beetle Convertible': 44, 'Toyota Tacoma': 45, 'Nissan Frontier': 46, 'Volkswagen GTI': 47, 'Honda Accord': 48, 'Volkswagen Beetle': 49, 'Cargo Minivan': 50, 'Honda Civic': 51, 'DIRECT_DRIVE': 52, 'electric': 53, 'Dodge Dakota': 54, 'Dodge Ram Pickup 1500': 55, 'Volkswagen Jetta': 56, 'Chevrolet Corvette': 57, 'Porsche 911': 58, 'Chevrolet C/K 1500 Series': 59, 'Volvo XC60': 60, 'flex-fuel (premium unleaded required/E85)': 61, 'Chevrolet Colorado': 62, 'Mazda 3': 63, 'Nissan 370Z': 64, 'Toyota Sienna': 65, 'Volkswagen Golf GTI': 66, 'Chevrolet Silverado 1500 Classic': 67, 'Mercedes-Benz E-Class': 68, 'GMC Sierra 1500 Classic': 69, 'Ford Transit Wagon': 70, 'GMC Canyon': 71, 'Honda Pilot': 72, 'Ford F-250': 73, 'Audi A3': 74, 'Ford Transit Connect': 75, 'Volkswagen Passat': 76, 'Volkswagen Jetta GLI': 77, 'Volkswagen Jetta SportWagen': 78, 'Cadillac CTS': 79, 'Dodge RAM 150': 80, 'Mazda B-Series Pickup': 81, 'Chevrolet Sonic': 82, 'Cadillac ATS': 83, 'Suzuki XL7': 84, 'Kia Sorento': 85, 'Ford Ranger': 86, 'Mercedes-Benz C-Class': 87, 'Ford Expedition': 88, 'Infiniti Q50': 89, 'Hyundai Sonata': 90, 'Volkswagen New Beetle': 91, 'Cadillac ATS Coupe': 92, 'Land Rover Range Rover': 93, 'Chevrolet S-10': 94, 'Nissan Titan': 95, 'Subaru Impreza': 96, 'Suzuki Forenza': 97, 'BMW 3 Series': 98, 'Toyota Corolla': 99, 'Acura MDX': 100, 'Nissan 350Z': 101, 'Dodge Challenger': 102, 'Chevrolet Camaro': 103, 'Suzuki SX4': 104, 'Honda CR-V': 105, 'Saab 9-3': 106, 'GMC Acadia': 107, 'Suzuki Kizashi': 108, 'Volkswagen CC': 109, 'Aston Martin V8 Vantage': 110, 'Toyota Camry Solara': 111, 'Suzuki Esteem': 112, 'Mazda Tribute': 113, 'Suzuki Aerio': 114, 'Chevrolet S-10 Blazer': 115, 'Dodge Journey': 116, 'GMC Jimmy': 117, 'Hyundai Veloster': 118, 'Chevrolet TrailBlazer': 119, 'Nissan Juke': 120, 'Cadillac Escalade': 121, 'Cadillac Escalade ESV': 122, 'Subaru B9 Tribeca': 123, 'Chrysler 300': 124, 'Convertible SUV': 125, 'Mazda CX-5': 126, 'Mercedes-Benz 300-Class': 127, 'GMC Terrain': 128, 'BMW 4 Series': 129, 'Suzuki XL-7': 130, 'Buick Encore': 131, 'Dodge Durango': 132, 'Land Rover Range Rover Evoque': 133, 'Mitsubishi Outlander Sport': 134, 'Kia Forte': 135, 'FIAT 500': 136, 'Mazda MX-5 Miata': 137, 'Nissan Murano': 138, 'Volvo S60': 139, 'Nissan Pathfinder': 140, 'Dodge Charger': 141, 'Ford Explorer Sport Trac': 142, 'Cadillac XTS': 143, 'Volkswagen Golf': 144, 'Toyota Venza': 145, 'Toyota Sequoia': 146, 'Toyota Pickup': 147, 'Chevrolet Traverse': 148, 'Volkswagen Tiguan': 149, 'Toyota 4Runner': 150, 'Volvo 850': 151, 'flex-fuel (premium unleaded recommended/E85)': 152, 'Lamborghini Gallardo': 153, 'Dodge RAM 250': 154, 'Audi R8': 155, 'Subaru WRX': 156, 'Audi A4': 157, 'Chevrolet Cruze': 158, 'Lincoln MKZ': 159, 'BMW 6 Series': 160, 'Ford Mustang': 161, 'Land Rover Range Rover Sport': 162, 'Oldsmobile Alero': 163, 'Acura RDX': 164, 'Dodge Nitro': 165, 'Nissan Altima': 166, 'Subaru Forester': 167, 'Volkswagen Routan': 168, 'Acura Integra': 169, 'Toyota RAV4': 170, 'Hyundai Elantra': 171, 'Honda Crosstour': 172, 'Hyundai Tucson': 173, 'Mercedes-Benz S-Class': 174, 'Nissan Truck': 175, 'Infiniti G Sedan': 176, 'Suzuki Equator': 177, 'Ford Explorer': 178, 'Chrysler 200': 179, 'Audi A6': 180, 'Chevrolet Equinox': 181, 'Acura TL': 182, 'Honda Ridgeline': 183, 'Suzuki Sidekick': 184, 'Saab 900': 185, 'Infiniti Q70': 186, 'Chevrolet Uplander': 187, 'Kia Spectra': 188, 'Volkswagen GLI': 189, 'Ford Edge': 190, 'Chevrolet Venture': 191, 'Volkswagen Rabbit': 192, 'Cadillac CTS Wagon': 193, 'Dodge Shadow': 194, 'Toyota Highlander': 195, 'Porsche Panamera': 196, 'Dodge Ramcharger': 197, 'Pontiac G6': 198, 'Chevrolet Cobalt': 199, 'Chevrolet Trax': 200, 'Toyota Yaris': 201, 'Nissan Xterra': 202, 'Ford Fiesta': 203, 'Cadillac SRX': 204, 'Volvo V60': 205, 'Dodge Dart': 206, 'Buick Lucerne': 207, 'Kia Rio': 208, 'Chevrolet Tracker': 209, 'Honda Element': 210, 'Acura TLX': 211, 'Audi Q5': 212, 'Ford Focus': 213, 'Mitsubishi Montero Sport': 214, 'Hyundai Tiburon': 215, 'Mazda CX-7': 216, 'Buick LaCrosse': 217, 'Subaru Outback': 218, 'Lincoln MKC': 219, 'Lincoln Navigator': 220, 'Ford F-150 Heritage': 221, 'Nissan Rogue': 222, 'Honda Passport': 223, 'Honda Insight': 224, 'Nissan Armada': 225, 'Chrysler Sebring': 226, 'Chevrolet Cavalier': 227, 'Plymouth Colt': 228, 'Bentley Continental GT': 229, 'Volkswagen Golf SportWagen': 230, 'Chevrolet Malibu': 231, 'Mazda CX-9': 232, 'Subaru Legacy': 233, 'UNKNOWN': 234, 'Nissan Sentra': 235, 'Dodge Ram 50 Pickup': 236, 'GMC S-15': 237, 'Toyota Camry': 238, 'Subaru Impreza WRX': 239, 'Cadillac CTS Coupe': 240, 'Hyundai Genesis Coupe': 241, 'Infiniti Q60 Coupe': 242, 'Hyundai Santa Fe': 243, 'Toyota Prius': 244, 'GMC Sonoma': 245, 'GMC S-15 Jimmy': 246, 'Mitsubishi Lancer': 247, 'Chevrolet Aveo': 248, 'Saab 9-3 Griffin': 249, 'GMC Yukon XL': 250, 'Ford Flex': 251, 'GMC Yukon': 252, 'Chevrolet Tahoe': 253, 'Ford Taurus': 254, 'Tesla Model S': 255, 'Chevrolet Suburban': 256, 'Cadillac CT6': 257, 'Chevrolet Impala': 258, 'Honda Fit': 259, 'Chevrolet Spark': 260, 'Honda CR-Z': 261, 'Ford Windstar': 262, 'Ford Explorer Sport': 263, 'Mitsubishi Outlander': 264, 'Hyundai Accent': 265, 'Volkswagen Touareg': 266, 'Kia Sportage': 267, 'Suzuki Grand Vitara': 268, 'Ford E-Series Wagon': 269, 'Volvo XC70': 270, 'Ford E-Series Van': 271, 'GMC Envoy': 272, 'Lincoln MKX': 273, 'Chrysler Town and Country': 274, 'Chevrolet Express': 275, 'Pontiac Grand Am': 276, 'Buick Regal': 277, 'Ford Fusion': 278, 'Mazda RX-8': 279, 'Pontiac Montana': 280, 'Chrysler Pacifica': 281, 'BMW 2 Series': 282, 'Volvo XC90': 283, 'Dodge Stratus': 284, 'GMC Savana': 285, 'Infiniti G Coupe': 286, 'Kia Optima': 287, 'GMC Envoy XL': 288, 'Suzuki Vitara': 289, 'BMW 5 Series': 290, 'Pontiac Sunbird': 291, 'Infiniti G35': 292, 'Acura Legend': 293, 'Nissan Versa': 294, 'Toyota Previa': 295, 'Aston Martin DBS': 296, 'Volvo 740': 297, 'BMW 1 Series': 298, 'Honda HR-V': 299, 'Dodge Grand Caravan': 300, 'Acura ILX': 301, 'Dodge Magnum': 302, 'Toyota Celica': 303, 'Oldsmobile Cutlass Calais': 304, 'Ford Five Hundred': 305, 'Acura TSX': 306, 'Dodge Caliber': 307, 'BMW 7 Series': 308, 'Hyundai Santa Fe Sport': 309, 'Nissan Versa Note': 310, 'Ford Freestyle': 311, 'Toyota T100': 312, 'Audi 100': 313, 'Mazda Truck': 314, 'Kia Sedona': 315, 'Ford Escape': 316, 'Chevrolet Avalanche': 317, 'Toyota Matrix': 318, 'Buick Enclave': 319, 'Mazda 6': 320, 'Honda Odyssey': 321, 'Oldsmobile Silhouette': 322, 'Suzuki Reno': 323, 'FIAT 500X': 324, 'Mercedes-Benz CLK-Class': 325, 'Kia Rondo': 326, 'Dodge Ram Cargo': 327, 'Audi Q7': 328, 'Mercedes-Benz M-Class': 329, 'Subaru Baja': 330, 'Pontiac Firebird': 331, 'Acura RSX': 332, 'Toyota Avalon': 333, 'Mitsubishi Raider': 334, 'Mitsubishi Expo': 335, 'Subaru XV Crosstrek': 336, 'Volkswagen Cabrio': 337, 'Ford Freestar': 338, 'Chevrolet Blazer': 339, 'Chevrolet HHR': 340, 'Volvo 940': 341, 'Volvo S70': 342, 'Plymouth Sundance': 343, 'Porsche Cayenne': 344, 'Dodge Daytona': 345, 'Audi Q3': 346, 'Mitsubishi Mirage': 347, 'Cadillac DTS': 348, 'Buick Verano': 349, 'GMC Savana Cargo': 350, 'Mitsubishi Eclipse': 351, 'Lexus LS 460': 352, 'Dodge Viper': 353, 'BMW 4 Series Gran Coupe': 354, 'Scion tC': 355, 'Mazda B-Series': 356, 'Ford LTD Crown Victoria': 357, 'Infiniti G37': 358, 'FIAT 500L': 359, 'Toyota Prius c': 360, 'Ford E-150': 361, 'Maserati Quattroporte': 362, 'Mercedes-Benz CLS-Class': 363, 'Ferrari 360': 364, 'Ferrari F430': 365, 'Lincoln Continental': 366, 'Dodge Neon': 367, 'Acura RL': 368, 'Oldsmobile Cutlass Ciera': 369, 'Scion FR-S': 370, 'Chrysler Crossfire': 371, 'Mazda CX-3': 372, 'BMW X5': 373, 'Infiniti EX35': 374, 'Acura RLX': 375, 'Mazda 2': 376, 'Chevrolet TrailBlazer EXT': 377, 'Toyota ECHO': 378, 'Lamborghini Aventador': 379, 'Audi S4': 380, 'GMC Sierra 1500 Hybrid': 381, 'GMC Yukon Hybrid': 382, 'Infiniti EX': 383, 'Cadillac Escalade Hybrid': 384, 'BMW X3': 385, 'Ford Escape Hybrid': 386, 'Hyundai Elantra Touring': 387, 'Kia Soul': 388, 'Nissan Maxima': 389, 'Nissan Quest': 390, 'BMW 6 Series Gran Coupe': 391, 'Plymouth Laser': 392, 'Chrysler Le Baron': 393, 'Subaru BRZ': 394, 'Hyundai Veracruz': 395, 'Mazda Navajo': 396, 'Toyota Prius v': 397, 'Mercedes-Benz CL-Class': 398, 'Lexus NX 200t': 399, 'Chevrolet Captiva Sport': 400, 'Mercedes-Benz SL-Class': 401, 'Ford Taurus X': 402, 'Mercedes-Benz GL-Class': 403, 'Dodge Ram Van': 404, 'Nissan 300ZX': 405, 'Chevrolet Silverado 1500 Hybrid': 406, 'Ford Aerostar': 407, 'Lexus RX 350': 408, 'Infiniti FX': 409, 'Mazda 5': 410, 'Hyundai Excel': 411, 'Buick Terraza': 412, 'Mercedes-Benz GLE-Class': 413, 'Mazda B-Series Truck': 414, 'GMC Vandura': 415, 'Ford Tempo': 416, 'Chevrolet Monte Carlo': 417, 'Mazda Protege': 418, 'Saab 9-5': 419, 'Pontiac Solstice': 420, 'Maserati GranTurismo Convertible': 421, 'Mazda 626': 422, 'Volkswagen Phaeton': 423, 'Lexus GS 350': 424, 'Chevrolet Malibu Maxx': 425, 'Lincoln LS': 426, 'Volkswagen Vanagon': 427, 'Ford E-250': 428, 'Saab 9000': 429, 'Subaru Justy': 430, 'Infiniti M': 431, 'Dodge Avenger': 432, 'Mitsubishi Endeavor': 433, 'Lincoln Aviator': 434, 'Oldsmobile Eighty-Eight Royale': 435, 'Cadillac STS': 436, 'Cadillac DeVille': 437, 'Lincoln Mark LT': 438, 'Nissan Leaf': 439, 'Land Rover LR4': 440, 'Dodge Colt': 441, 'Lotus Evora': 442, 'Subaru Crosstrek': 443, 'Scion xD': 444, 'Volkswagen Golf R': 445, 'Infiniti QX60': 446, 'Nissan Cube': 447, 'HUMMER H3': 448, 'Honda Accord Crosstour': 449, 'Audi A7': 450, 'Pontiac Torrent': 451, 'BMW 5 Series Gran Turismo': 452, 'Dodge Stealth': 453, 'Scion xB': 454, 'Ford Fusion Hybrid': 455, 'Bentley Arnage': 456, 'Pontiac Bonneville': 457, 'Hyundai Scoupe': 458, 'BMW Z3': 459, 'Toyota Camry Hybrid': 460, 'Chevrolet Cruze Limited': 461, 'Plymouth Neon': 462, 'Land Rover Discovery Sport': 463, 'Mitsubishi Diamante': 464, 'Chevrolet Chevy Van': 465, 'Lamborghini Murcielago': 466, 'Suzuki Verona': 467, 'Pontiac Vibe': 468, 'Lincoln MKS': 469, 'Mazda Millenia': 470, 'Audi 90': 471, 'Mercedes-Benz SLK-Class': 472, 'Audi S5': 473, 'BMW ALPINA B7': 474, 'Chrysler Concorde': 475, 'Land Rover Freelander': 476, 'Mercedes-Benz GLA-Class': 477, 'Buick Roadmaster': 478, 'Toyota FJ Cruiser': 479, 'Acura CL': 480, 'Mercedes-Benz CLA-Class': 481, 'Mitsubishi 3000GT': 482, 'Ford Bronco': 483, 'BMW Z4': 484, 'Honda Accord Hybrid': 485, 'Chevrolet Impala Limited': 486, 'Dodge Caravan': 487, 'Mercedes-Benz GLK-Class': 488, 'Ford Escort': 489, 'Oldsmobile Intrigue': 490, 'Land Rover LR2': 491, 'Subaru Loyale': 492, 'Toyota Avalon Hybrid': 493, 'Pontiac Le Mans': 494, 'Kia Borrego': 495, 'Nissan 200SX': 496, 'Honda Civic del Sol': 497, 'Audi A5': 498, 'Cadillac Escalade EXT': 499, 'BMW X6': 500, 'Ford Contour': 501, 'Ford Bronco II': 502, 'Chevrolet C/K 2500 Series': 503, 'Porsche Cayman': 504, 'Kia Cadenza': 505, 'Saab 9-7X': 506, 'Aston Martin DB9': 507, 'Porsche Macan': 508, 'Hyundai Elantra Coupe': 509, 'Mercedes-Benz 500-Class': 510, 'Ford Probe': 511, 'Chrysler PT Cruiser': 512, 'Ferrari 458 Italia': 513, 'Infiniti QX50': 514, 'Plymouth Voyager': 515, 'Volvo S40': 516, 'Volvo S80': 517, 'Volvo 240': 518, 'Kia Sephia': 519, 'Nissan 240SX': 520, 'Buick Skylark': 521, 'Hyundai Sonata Hybrid': 522, 'Chevrolet Sportvan': 523, 'Subaru SVX': 524, 'Ford Thunderbird': 525, 'Lincoln Town Car': 526, 'Mazda Tribute Hybrid': 527, 'Pontiac 6000': 528, 'Mazda MPV': 529, 'Porsche Boxster': 530, 'Infiniti G Convertible': 531, 'Audi allroad': 532, 'Audi allroad quattro': 533, 'Hyundai Genesis': 534, 'Maserati Ghibli': 535, 'Aston Martin Vanquish': 536, 'Pontiac Grand Prix': 537, 'Plymouth Grand Voyager': 538, 'Maserati GranTurismo': 539, 'Nissan GT-R': 540, 'Dodge Intrepid': 541, 'Lexus IS 250': 542, 'Volkswagen Jetta Hybrid': 543, 'Buick Envision': 544, 'Lotus Elise': 545, 'Infiniti G20': 546, 'Ford Aspire': 547, 'Cadillac XLR': 548, 'Chrysler Aspen': 549, 'Maybach 62': 550, 'BMW 8 Series': 551, 'BMW 3 Series Gran Turismo': 552, 'Suzuki X-90': 553, 'Chrysler Voyager': 554, 'Maybach 57': 555, 'Oldsmobile Bravada': 556, 'BMW X4': 557, 'Acura ZDX': 558, 'Oldsmobile Eighty-Eight': 559, 'Suzuki Swift': 560, 'Volkswagen Eos': 561, 'Cadillac Eldorado': 562, 'Mitsubishi Lancer Evolution': 563, 'Mitsubishi Eclipse Spyder': 564, 'Honda S2000': 565, 'Nissan Stanza': 566, 'Volkswagen Fox': 567, 'Oldsmobile Ninety-Eight': 568, 'Infiniti J30': 569, 'Oldsmobile Cutlass Supreme': 570, 'Lexus RX 450h': 571, 'Mazda MX-6': 572, 'Chevrolet Metro': 573, 'Toyota Tercel': 574, 'Pontiac Trans Sport': 575, 'Infiniti QX80': 576, 'Chevrolet Caprice': 577, 'HUMMER H3T': 578, 'Honda Prelude': 579, 'Infiniti QX56': 580, 'Infiniti QX70': 581, 'Infiniti QX4': 582, 'Ferrari 456M': 583, 'Infiniti Q60 Convertible': 584, 'Mercedes-Benz R-Class': 585, 'Chevrolet Prizm': 586, 'Lincoln MKT': 587, 'Rolls-Royce Phantom': 588, 'Buick Park Avenue': 589, 'GMC Rally Wagon': 590, 'Kia Optima Hybrid': 591, 'Nissan NX': 592, 'Nissan NV200': 593, 'Acura Vigor': 594, 'Ferrari 575M': 595, 'Mazda MX-3': 596, 'Ford Mustang SVT Cobra': 597, 'Toyota MR2': 598, 'Toyota MR2 Spyder': 599, 'Dodge Monaco': 600, 'Buick Rainier': 601, 'BMW X1': 602, 'Chrysler 300M': 603, 'Chevrolet Spark EV': 604, 'Aston Martin V12 Vantage': 605, 'Audi TT': 606, 'Acura TSX Sport Wagon': 607, 'Volkswagen Touareg 2': 608, 'Oldsmobile Toronado': 609, 'Chevrolet Tahoe Hybrid': 610, 'Cadillac XT5': 611, 'Toyota Supra': 612, 'GMC Suburban': 613, 'Hyundai XG350': 614, 'Audi SQ5': 615, 'Maserati Spyder': 616, 'Mercedes-Benz 190-Class': 617, 'Lexus RC 350': 618, 'Audi 200': 619, 'GMC Sierra 1500HD': 620, 'Scion xA': 621, 'Ford Shelby GT350': 622, 'GMC Safari': 623, 'GMC Safari Cargo': 624, 'Audi S3': 625, 'Lexus RX 400h': 626, 'Lexus RX 330': 627, 'Lexus RX 300': 628, 'Audi RS 5': 629, 'Buick Rendezvous': 630, 'Ford C-Max Hybrid': 631, 'Volvo V60 Cross Country': 632, 'Pontiac G5': 633, 'Mitsubishi Galant': 634, 'Hyundai Equus': 635, 'Lexus HS 250h': 636, 'Toyota Highlander Hybrid': 637, 'Lexus GX 460': 638, 'Maserati Coupe': 639, 'Oldsmobile Cutlass': 640, 'Land Rover Discovery Series II': 641, 'Pontiac Aztek': 642, 'Rolls-Royce Ghost': 643, 'Volvo V50': 644, 'Hyundai Azera': 645, 'flex-fuel (unleaded/natural gas)': 646, 'Lincoln Mark VII': 647, 'Infiniti G37 Sedan': 648, 'Land Rover Discovery': 649, 'Dodge Dynasty': 650, 'Infiniti FX35': 651, 'Hyundai Elantra GT': 652, 'Ford Festiva': 653, 'Lotus Exige': 654, 'Chevrolet Astro Cargo': 655, 'Chevrolet Astro': 656, 'Infiniti I30': 657, 'Audi A8': 658, 'Bentley Continental': 659, 'Chevrolet Beretta': 660, 'Volvo C30': 661, 'Lincoln Mark VIII': 662, 'BMW M6': 663, 'Audi 80': 664, 'BMW M4': 665, 'Infiniti M45': 666, 'Volkswagen Cabriolet': 667, 'Infiniti M35': 668, 'Chevrolet Black Diamond Avalanche': 669, 'Bentley Continental GTC': 670, 'Volkswagen EuroVan': 671, 'Chevrolet Lumina Minivan': 672, 'Oldsmobile LSS': 673, 'Chevrolet City Express': 674, 'Buick LeSabre': 675, 'Mitsubishi Lancer Sportback': 676, 'Honda Civic CRX': 677, 'Volvo 960': 678, 'Porsche 968': 679, 'Lexus IS 350': 680, 'Buick Cascada': 681, 'Pontiac Sunfire': 682, 'Hyundai Entourage': 683, 'Kia Soul EV': 684, 'Oldsmobile Aurora': 685, 'Mercedes-Benz SLS AMG GT': 686, 'Subaru Tribeca': 687, 'BMW M': 688, 'Ford Shelby GT500': 689, 'Cadillac Seville': 690, 'Mitsubishi Mighty Max Pickup': 691, 'Ferrari 599': 692, 'Infiniti M30': 693, 'Saab 9-4X': 694, 'Chevrolet Lumina': 695, 'Acura NSX': 696, 'Lexus NX 300h': 697, 'Kia K900': 698, 'Alfa Romeo 4C': 699, 'Lexus IS 300': 700, 'Volkswagen Golf Alltrack': 701, 'Oldsmobile Achieva': 702, 'Dodge Ram Wagon': 703, 'Mazda 323': 704, 'Toyota RAV4 Hybrid': 705, 'Pontiac G8': 706, 'Infiniti G37 Coupe': 707, 'Mercedes-Benz G-Class': 708, 'Bentley Flying Spur': 709, 'Audi S6': 710, 'Volvo S90': 711, 'Plymouth Breeze': 712}\n"
          ]
        }
      ],
      "source": [
        "def build_model_v0(doc):\n",
        "  model = gensim.models.Word2Vec(doc)\n",
        "  return model\n",
        "\n",
        "def test_v0():\n",
        "    document, df = build_dataset()\n",
        "    model = build_model_v0(document)\n",
        "    print(model.wv.key_to_index)\n",
        "\n",
        "test_v0()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiO-g2hOlL-h"
      },
      "source": [
        "#**Model Evaluation: Extrinsic vs Intrinsic evaluation**\n",
        "\n",
        "Of course, we have no idea on how 'good' the default Word2Vec function is at building word embeddings. We need a way to evaluate it. For evaluating how useful/accurate the word embeddings are, there are two different ways to assess them: intrinsically and extrinsically.\n",
        "\n",
        "In **intrinsic** evaluation, you are assessing the performance on a very specific task or sub- task for the vectors themselves. For example, one task might be how many word analogies are correctly identified.\n",
        "<br>\n",
        "\n",
        "In **extrinsic** evaluation, you are using your word vectors as input into another NLP process (e.g. named entity recognition, classification, another neural network).\n",
        "\n",
        "For this example, we will evaluate our simple model using a few intrinsic evaluations:\n",
        "1. Do the word vectors capture all the make/models of the car set?\n",
        "2. How accurate are the car similarities? For example, we would expect 'Toyota Camry' and 'Nissan Van' to be closer than 'Toyota Camry' and 'Mercedes-Benz SLK-Class'.\n",
        "\n",
        "Read, understand and run the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZaFLY23_lwQU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "263 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.9765\n",
            "\n",
            "Error:\"Key 'Nissan Van' not present\"\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, df=None):\n",
        "\n",
        "  output = ''\n",
        "  if df is not None:\n",
        "    unique_set = df['Make_Model'].unique()\n",
        "    missing=0\n",
        "    for mm in unique_set:\n",
        "      if mm not in model.wv.index_to_key:\n",
        "        missing += 1\n",
        "    output += \"{:d} models are missing of {:d}\\n\".format(missing, len(unique_set))\n",
        "\n",
        "  try:\n",
        "    t = 'Toyota Camry'\n",
        "    other = ['Honda Accord', 'Nissan Van', 'Mercedes-Benz SLK-Class']\n",
        "    for o in other:\n",
        "      output += t + '->' + o + ' ' + \"{:0.4f}\\n\".format(model.wv.similarity(t,o))\n",
        "\n",
        "    tuples = model.wv.most_similar(positive='Honda Odyssey', topn=3)\n",
        "    for mm, v in tuples:\n",
        "      output += mm + ', '\n",
        "    output = output.strip(', ')\n",
        "\n",
        "  except KeyError as e:\n",
        "    output += \"\\nError:\" + str(e)\n",
        "\n",
        "  return output\n",
        "\n",
        "def test_v0():\n",
        "  document, df = build_dataset()\n",
        "  model = build_model_v0(document)\n",
        "  print(evaluate_model(model, df))\n",
        "  \n",
        "test_v0()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BQBhHBRl0l1"
      },
      "source": [
        "What did you notice for test_v0? Of course, this isn't a thorough testing suite; but it helps to show some simple relationships. Ideally, you would come up with score/metric for your evaluation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7R6VUS8l5io"
      },
      "source": [
        "**Tuning Our Algorithm**\n",
        "\n",
        "There's another parameter (many actually) that we can use to configure Word2Vec. These parameters (called hyper parameters) along with our evaluation function can be used to build an accurate model based on our dataset. The values of these hyper-parameters come from experience and trail-and-error.\n",
        "\n",
        "The first parameter is min_count whose default value is 5. There are many car models that only appear a few times and these cars are being dropped. Let's update our model to use this parameter:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def build_model_v1(doc):\n",
        "  model = gensim.models.Word2Vec(\n",
        "          doc,\n",
        "          min_count=1, # only ignore words that occur less than 1 times\n",
        "          )\n",
        "  return model\n",
        "```\n",
        "add the following code to the above cell (`build_model_v1`) and run `test_v1`\n",
        "```\n",
        "def test_v1():\n",
        "  document, df = build_dataset()\n",
        "  model = build_model_v1(document)\n",
        "  print(evaluate_model(model,df))\n",
        "test_v1()\n",
        "```\n",
        "\n",
        "That's much better (your output will be different, but all the car models should be there):\n",
        "\n",
        "```\n",
        "0 models are missing of 928\n",
        "Toyota Camry->Honda Accord 0.9584\n",
        "Toyota Camry->Nissan Van 0.9442\n",
        "Toyota Camry->Mercedes-Benz SLK-Class 0.6755\n",
        "Toyota Previa, Pontiac Montana, Chevrolet Uplander\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.9081\n",
            "Toyota Camry->Nissan Van 0.9334\n",
            "Toyota Camry->Mercedes-Benz SLK-Class 0.5702\n",
            "Toyota Previa, GMC Jimmy, Dodge Ramcharger\n"
          ]
        }
      ],
      "source": [
        "def build_model_v1(doc):\n",
        "  model = gensim.models.Word2Vec(\n",
        "          doc,\n",
        "          min_count=1, # only ignore words that occur less than 1 times\n",
        "          )\n",
        "  return model\n",
        "\n",
        "def test_v1():\n",
        "  document, df = build_dataset()\n",
        "  model = build_model_v1(document)\n",
        "  print(evaluate_model(model,df))\n",
        "test_v1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1khsvKWDnDqD"
      },
      "source": [
        "#**Randomness of ML**\n",
        "\n",
        "You may see different numbers in your output than what is shown. Many machine learning algorithms use randomization to make sure things are evenly spaced out in high dimensional space to start. So if you re-run your above model, you should see different results each time -- but on average, your results should be close on each run.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoJzXbm7nH5o"
      },
      "source": [
        "**CPUS and Threads**\n",
        "\n",
        "However, this randomness causes issues with reproducibility. We can control the randomness by doing a few things. The main issue for Word2Vec is that the work it does is split across many threads. You can think of a thread as an independent worker. Usually you want to at least match the number of CPUs to the number of threads. That way if you have multiple CPUS, you can take advantage of parallel processing. For this lesson, we will not worry about how to find the number of CPUS our VM has. But you can get this information from within a Python program.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import multiprocessing\n",
        "print(multiprocessing.cpu_count())\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "print(multiprocessing.cpu_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUbKV7SBnkKc"
      },
      "source": [
        "***Coder's Log***: a process is an active program. It has it's own memory and resources. A thread is 'lightweight' in that it can share the same memory of it's parent process. Processes are isolated; threads are not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzy5gP84n7Gu"
      },
      "source": [
        "When work is split up between threads, each thread may be assigned different units of work, finish at different times and their results may be combined differently. At the cost of being less efficient, we can tell Word2Vec to only use a single thread. That will stop the randomness. Note that there is also a seed hyperparameter that can be used to control randomness.\n",
        "\n",
        "\n",
        "Go back to the previous code cell and update your code (and run it):\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def build_model_v1(doc):\n",
        "  model = gensim.models.Word2Vec(\n",
        "             doc,\n",
        "             min_count=1, # ignore words that occur less than 1 times\n",
        "             workers=1\n",
        "          )\n",
        "  return model\n",
        "  \n",
        "def test_v1():\n",
        "  document, df = build_dataset()\n",
        "  model = build_model_v1(document)\n",
        "  print(evaluate_model(model,df))\n",
        "test_v1()\n",
        "```\n",
        "You should now see consistent numbers between multiple runs. Here's the output we get (your output will be slightly different):\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "0 models are missing of 928\n",
        "Toyota Camry->Honda Accord 0.9773\n",
        "Toyota Camry->Nissan Van 0.9501\n",
        "Toyota Camry->Mercedes-Benz SLK-Class 0.4989\n",
        "GMC Jimmy, Ford Five Hundred, GMC Envoy\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.9263\n",
            "Toyota Camry->Nissan Van 0.8998\n",
            "Toyota Camry->Mercedes-Benz SLK-Class 0.7427\n",
            "Chevrolet Blazer, Toyota Previa, Chevrolet Silverado 1500 Hybrid\n"
          ]
        }
      ],
      "source": [
        "def build_model_v1(doc):\n",
        "  model = gensim.models.Word2Vec(\n",
        "             doc,\n",
        "             min_count=1, # ignore words that occur less than 1 times\n",
        "             workers=1\n",
        "          )\n",
        "  return model\n",
        "  \n",
        "def test_v1():\n",
        "  document, df = build_dataset()\n",
        "  model = build_model_v1(document)\n",
        "  print(evaluate_model(model,df))\n",
        "test_v1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RIRc7kmoluj"
      },
      "source": [
        "#**Windows of Context**\n",
        "The output of word2vec is a set of word vectors. And each word vector is essentially the same as shown in the previous lesson on word embeddings. The goal of the algorithm is to have words with similar context occupy close spatial positions. As discussed in the word embeddings lesson, the cosine similarity can be used as a metric of closeness.\n",
        "\n",
        "For word2vec there is a concept of defining both a 'target word' and 'context words'. Below shows an example of the target word 'by' with its context window (word is known the company it):\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1QR5HR3sFX5Dt1ZDb_sNxoX1xEsf4uMl7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg_ruFOeqIfG"
      },
      "source": [
        "For the window of size n the contexts are defined by capturing n words to the left of the target and n words to its right. This window of context (shown here to be size 3) slides along the text. So the next word that is processed is the:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Ao5X5Z07uZdnZNQRRaRhH9kDdYJ7pPc-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X15M3K9DqN-3"
      },
      "source": [
        "Given that information, it's clear that where the target word appears in the document and the size of the context window can affect the quality of the output. If the window is too small, 'meaning' becomes very narrow. If the window is too big, words no longer separate from each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to7Y2lPRqgrr"
      },
      "source": [
        "###**Exercise**\n",
        "\n",
        "Go all the way back to the code cell that creates the function build_dataset. Move the column 'Make_Model' from the front of the list to the third position. Now Re-run the cell with build_dataset in it. You should see the following (from the output of test_pd_data):\n",
        "\n",
        "```\n",
        "['Factory Tuner', 'Luxury', 'High-Performance', 'BMW 1 Series M', 'Compact']\n",
        "```\n",
        "\n",
        "Now re-run the cell with test_v1():\n",
        "\n",
        "```\n",
        "test_v1()\n",
        "```\n",
        "\n",
        "Notice that the position of where the make/model appears in the document affects the result (the similarity of Camry and Accord went down). We can avoid this issue by creating a wide context window.\n",
        "\n",
        "The default window size is 5. Do the following modifications:\n",
        "* update build_model_v1 to be the following:\n",
        "\n",
        "```\n",
        "def build_model_v1(doc):\n",
        "  model = gensim.models.Word2Vec(\n",
        "             doc,\n",
        "             min_count=1, # ignore words that occur less than 1 times\n",
        "             workers=1,   # one thread to remove randomness\n",
        "             window=10,   # wide window size\n",
        "          )\n",
        "  return model\n",
        "```\n",
        "\n",
        "When you re-run the cell (test_v1()) the output becomes:\n",
        "\n",
        "```\n",
        "0 models are missing of 928\n",
        "Toyota Camry->Honda Accord 0.9734\n",
        "Toyota Camry->Nissan Van 0.9292\n",
        "Toyota Camry->Mercedes-Benz SLK-Class 0.1101\n",
        "Dodge Ramcharger, Pontiac Montana, GMC Jimmy\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl7S0dMCubcT"
      },
      "source": [
        "#**Epoch Training**\n",
        "\n",
        "As we saw in the ML Prep lesson, each machine learning algorithm involves iteration over the dataset to help adjust and improve. Initially, the word vectors are assigned random locations in very high dimensional space. As the algorithm iterates, these word vectors move closer to neighborhoods with 'similar words'.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1v1C8k8v-rZnaDtRVv2nqb0eEwmlZuKqa)\n",
        "\n",
        "Remember, that 'closeness' is defined by\n",
        "how similar these words are. And being similar, means the words share similar contexts. So you expect common misspellings and upper/lower case versions of the same word to be located near each other in high dimensional space. The image to the left shows how the days of the week (orange circle) might be near each other. Also similar relationships would have similar distances (e.g. king to queen and uncle to aunt)\n",
        "\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Gvt7N27XLaHRlpvYe2qGV732FGVgt24S)\n",
        "\n",
        "\n",
        "You can control how many times word2vec iterates on its training through the iter parameter (whose default is 5). Let's up this to 15. Of course, this is a choice that comes from experimentation and evaluation. If your corpus is huge, you may not have enough years to iterate.\n",
        "\n",
        "\n",
        "Let's create another function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DAcCOZqJvqEY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NDIM = 25\n",
            "0 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.8772\n",
            "Toyota Camry->Nissan Van 0.6246\n",
            "Toyota Camry->Mercedes-Benz SLK-Class -0.1957\n",
            "Toyota Sienna, Plymouth Grand Voyager, Chevrolet Astro\n",
            "****************************************************************************************************\n",
            "NDIM = 50\n",
            "0 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.8747\n",
            "Toyota Camry->Nissan Van 0.6553\n",
            "Toyota Camry->Mercedes-Benz SLK-Class -0.1814\n",
            "Toyota Sienna, Plymouth Grand Voyager, Chevrolet Astro\n",
            "****************************************************************************************************\n",
            "NDIM = 75\n",
            "0 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.8740\n",
            "Toyota Camry->Nissan Van 0.6748\n",
            "Toyota Camry->Mercedes-Benz SLK-Class -0.1354\n",
            "Toyota Sienna, Plymouth Grand Voyager, Chevrolet Astro\n",
            "****************************************************************************************************\n",
            "NDIM = 100\n",
            "0 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.8724\n",
            "Toyota Camry->Nissan Van 0.7047\n",
            "Toyota Camry->Mercedes-Benz SLK-Class -0.1216\n",
            "Toyota Sienna, Plymouth Grand Voyager, Chevrolet Astro\n",
            "****************************************************************************************************\n",
            "NDIM = 150\n",
            "0 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.8736\n",
            "Toyota Camry->Nissan Van 0.6930\n",
            "Toyota Camry->Mercedes-Benz SLK-Class -0.0943\n",
            "Toyota Sienna, Ford Aerostar, Plymouth Grand Voyager\n",
            "****************************************************************************************************\n",
            "NDIM = 200\n",
            "0 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.8714\n",
            "Toyota Camry->Nissan Van 0.7089\n",
            "Toyota Camry->Mercedes-Benz SLK-Class -0.0816\n",
            "Toyota Sienna, Ford Aerostar, Plymouth Grand Voyager\n",
            "****************************************************************************************************\n"
          ]
        }
      ],
      "source": [
        "def build_model_v2(doc):\n",
        "  model = gensim.models.Word2Vec(\n",
        "          doc,\n",
        "          min_count=1,   # ignore words that occur less than 2 times\n",
        "          workers=1,     # threads to use\n",
        "          window=10,     # size of window around the target word\n",
        "          epochs=15        # 15 epochs\n",
        "          )\n",
        "  return model\n",
        "\n",
        "ndims = [25, 50, 75, 100, 150, 200]\n",
        "\n",
        "def build_model_v2(doc):\n",
        "  model = gensim.models.Word2Vec(\n",
        "          doc,\n",
        "          min_count=1,   # ignore words that occur less than 2 times\n",
        "          workers=1,     # threads to use\n",
        "          window=10,     # size of window around the target word\n",
        "          epochs=15,        # 15 epochs\n",
        "          vector_size=ndim, # how big the output vectors (spacy == 300)\n",
        "          )\n",
        "  return model\n",
        "\n",
        "\n",
        "def test_v2():\n",
        "  document, df = build_dataset()\n",
        "  model = build_model_v2(document)\n",
        "  print(evaluate_model(model,df))\n",
        "# test_v2()\n",
        "\n",
        "for i in ndims:\n",
        "  print(\"NDIM = {}\".format(i))\n",
        "  ndim = i\n",
        "  test_v2()\n",
        "  print('*'*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3jRJr-Av0g_"
      },
      "source": [
        "The output should look close to the following:\n",
        "\n",
        "```\n",
        "0 models are missing of 928\n",
        "Toyota Camry->Honda Accord 0.8234\n",
        "Toyota Camry->Nissan Van 0.6933\n",
        "Toyota Camry->Mercedes-Benz SLK-Class -0.0498\n",
        "Ford Aerostar, GMC Safari, Dodge Caravan\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkdV9vGIv738"
      },
      "source": [
        "This looks a lot better. The three similar vans are correct and the Camry and Mercedes have a lot more distance between them (negative in fact). Note: your output will look slightly different. But you should see an improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc247lKKoLbr"
      },
      "source": [
        "#**High Dimensional Space**\n",
        "\n",
        "As we saw in the word embeddings lesson, word vectors have a length (we saw that spaCy uses 300) that indicates how many dimensions each word contains. The default for word2vec is 100.\n",
        "\n",
        "This is another hyper-parameter that you can adjust. There's no perfect number. The larger your corpus is the more dimensions you will need. The cars dataset is very small so it would be good to know how many dimensions capture the similarities between cars.\n",
        "\n",
        "You want the smallest number of dimensions necessary to do well on your evaluation metrics (and no more). Too many dimensions become space inefficient as your corpus size increase and could result in **overfitting** (when the model doesn't generalize well).\n",
        "\n",
        "Update build_model_v2 to allow the number of dimensions to be passed in.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def build_model_v2(doc):\n",
        "  model = gensim.models.Word2Vec(\n",
        "          doc,\n",
        "          min_count=1,   # ignore words that occur less than 2 times\n",
        "          workers=1,     # threads to use\n",
        "          window=10,     # size of window around the target word\n",
        "          iter=15        # 15 epochs\n",
        "          size=ndim, # how big the output vectors (spacy == 300)\n",
        "          )\n",
        "  return model\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlT2DyrYoZM-"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Experiment with using 25, 50, 75, 100, 150, 200. Update test_v2 to call build_model_v2 in a loop of the different sizes.\n",
        "\n",
        "What do you notice and where would you decide to put the cutoff?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Med2H7LGU90e"
      },
      "source": [
        "#**Two Ways To Train**\n",
        "\n",
        "Word2Vec uses a neural network as it's algorithm and architecture. We will go into more detail in the lesson on using neural networks. For now, we will simplify things a bit just so we can stay focused on the task at hand.\n",
        "\n",
        "Word2vec provides two very different ways to structure the neural network for learning the distributed representations of words that try to minimize the computational complexity (how long it takes to run). These two underlying architectures are the continuous bag-of-words model (CBOW) and a continuous Skip-gram (Skip Gram) model. Each uses a different metric to evaluate the training of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SciOO3y2VJom"
      },
      "source": [
        "#**Continuous bag-of-words (CBOW) training**\n",
        "\n",
        "In this method, a window of words surrounding the 'target' word (i.e. the context) is used in an attempt to predict the target word.\n",
        "\n",
        "It's a 'bag of words' in that the actual order of the surrounding words is not used in the analysis. It uses a continuous probability distribution to represent the context words (rather than discrete counting).\n",
        "\n",
        "The input into CBOW is a vector representation of a group of context words, the goal is to get the most appropriate target word which will be within the vicinity of the group of words.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Csgy5_ICG58GuiOGsojGZo3Fs0cUUBwW)\n",
        "\n",
        "\n",
        "#**Skip-gram training**\n",
        "\n",
        "For CBOW, if you have enough context, the goal is to predict the word. In the skip-gram 'model', if you are given a target word, the output is the set of context words (i.e. words who appeared in close proximity to the target).\n",
        "\n",
        "Essentially the task the neural network is solving is to find which context words can appear given a target word. After training the neural network, if we input any target word into the neural network, it will give a vector output which represents the words which have a high probability of appearing near the given word.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1dkeVAr5maRiSm2jmauQ_f2cpu9dg4hkK)\n",
        "\n",
        "\n",
        "#**Choosing between the two**\n",
        "\n",
        "The author of word2vec [summarizes the differences](https://groups.google.com/g/word2vec-toolkit/c/NLvYXU99cAM/m/E5ld8LcDxlAJ?pli=1) of CBOW and SkipGram:\n",
        "\n",
        "* Skip-gram: works well with small amount of the training data, represents well even rare words or phrases\n",
        "\n",
        "* CBOW: several times faster to train than the skip-gram, slightly better accuracy for the frequent words\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1TVBn_sskOkehevhJfcs9sQvd8uiFAz-w)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNsSyJyqWKp5"
      },
      "source": [
        "The default training method of word2vec is CBOW. But since our car dataset is so small, let's try the skipgram model by using the sg named parameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "iSNlB1yZXY5u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.9015\n",
            "Toyota Camry->Nissan Van 0.8168\n",
            "Toyota Camry->Mercedes-Benz SLK-Class 0.6322\n",
            "Toyota Sienna, Chevrolet Astro, Ford Aerostar\n"
          ]
        }
      ],
      "source": [
        "def build_model_v3(doc):\n",
        "  model = gensim.models.Word2Vec(\n",
        "          doc,\n",
        "          min_count=1,   # ignore words that occur less than 2 times\n",
        "          workers=1,     # threads to use\n",
        "          window=10,     # size of window around the target word\n",
        "          epochs=15,        # 15 epochs\n",
        "          vector_size=ndim,     # how big the output vectors (spacy == 300)\n",
        "          sg=1,          # 0 == CBOW (default) 1 == skip gram\n",
        "          negative=15\n",
        "          )\n",
        "  return model\n",
        "\n",
        "def test_v3():\n",
        "  document, df = build_dataset()\n",
        "  model = build_model_v3(document)\n",
        "  print(evaluate_model(model,df))\n",
        "\n",
        "test_v3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut9jYc1oXhU4"
      },
      "source": [
        "When you run it, you should see something similar to\n",
        "\n",
        "```\n",
        "0 models are missing of 928\n",
        "Toyota Camry->Honda Accord 0.8568\n",
        "Toyota Camry->Nissan Van 0.8036\n",
        "Toyota Camry->Mercedes-Benz SLK-Class 0.5291\n",
        "GMC Safari, Chevrolet Astro, Dodge Caravan\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS2TvUcjXtOK"
      },
      "source": [
        "In order to evaluate the accuracy between CBOW or skip-gram, we would need a more extensive test suite. But you can see that skip-gram did perform very well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0chhQ8-7X12f"
      },
      "source": [
        "#**Negative Sampling**\n",
        "\n",
        "Without getting into the details (they will come), training a neural network (NN) is very time consuming. A NN is made up of connected nodes and layers.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1lhZc_wHJiH3474H1MRDvnuQdlrywtav7)\n",
        "\n",
        "You can also think of each connection (a line or edge between nodes) as having a 'weight' that needs to be adjusted. As the size of the vocabulary increases (the number of unique words in the corpus) so does the complexity of the internal architecture (i.e. a lot more nodes, edges and weights to adjust).\n",
        "\n",
        "Negative sampling addresses the complexity issue by having each training sample modify only a small percentage of the nodes/weights (rather than all of them). With negative sampling, we randomly select just a small number of negative words to update the weights for. In this context, a negative word is one for which we want the network to output a 0).\n",
        "\n",
        "Another option for the training method is called soft-max. Soft-max is computational expensive and is usually referred to as hierarchical soft-max which is an optimized implementation. We can cover the details of these algorithms when we get to neural networks.\n",
        "\n",
        "For word2vec, the default negative sampling parameter is set to 5. Update the function build_model_v3 to include 15 to be the value:\n",
        "\n",
        "```\n",
        "negative=15,\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "When you re-run, test_v3, you should see results similar to the following:\n",
        "\n",
        "```\n",
        "0 models are missing of 928\n",
        "Toyota Camry->Honda Accord 0.8977\n",
        "Toyota Camry->Nissan Van 0.8216\n",
        "Toyota Camry->Mercedes-Benz SLK-Class 0.6351\n",
        "GMC Safari, Ford Windstar, Chevrolet Astro\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gv4RAFgYTh4"
      },
      "source": [
        "#**Saving and Loading Models**\n",
        "\n",
        "Once you train a model (which can take hours, days, weeks, months?), you will want to save it to a file so you can just reload the trained model. The model you save is significantly smaller than the corpus you used to train it.\n",
        "\n",
        "For gensim, you can save models via the save method. Update your test_v3 function to include saving the model:\n",
        "\n",
        "**Saving Models**\n",
        "\n",
        "```\n",
        "def test_v3():\n",
        "  document, df = build_dataset()\n",
        "  model = build_model_v3(document)\n",
        "  print(evaluate_model(model,df))\n",
        "  model.save('carmodel.skipgram')\n",
        "test_v3()\n",
        "```\n",
        "\n",
        "**Loading Models**\n",
        "\n",
        "You can reload saved models just as easily:\n",
        "```\n",
        "def test_load():\n",
        "  md2 = gensim.models.Word2Vec.load('carmodel.skipgram')\n",
        "  print(evaluate_model(md2))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 models are missing of 928\n",
            "Toyota Camry->Honda Accord 0.9015\n",
            "Toyota Camry->Nissan Van 0.8168\n",
            "Toyota Camry->Mercedes-Benz SLK-Class 0.6322\n",
            "Toyota Sienna, Chevrolet Astro, Ford Aerostar\n"
          ]
        }
      ],
      "source": [
        "def test_v3():\n",
        "  document, df = build_dataset()\n",
        "  model = build_model_v3(document)\n",
        "  print(evaluate_model(model,df))\n",
        "  model.save('carmodel.skipgram')\n",
        "test_v3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Toyota Camry->Honda Accord 0.9015\n",
            "Toyota Camry->Nissan Van 0.8168\n",
            "Toyota Camry->Mercedes-Benz SLK-Class 0.6322\n",
            "Toyota Sienna, Chevrolet Astro, Ford Aerostar\n"
          ]
        }
      ],
      "source": [
        "def test_load():\n",
        "  md2 = gensim.models.Word2Vec.load('carmodel.skipgram')\n",
        "  print(evaluate_model(md2))\n",
        "test_load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puZlOW-Pbdts"
      },
      "source": [
        "**Word Analogies Test Suite**\n",
        "\n",
        "A classic set of word analogies is also available to use (see https://github.com/nicholas-leonard/word2vec/blob/master/questions-words.txt)\n",
        "The word2vec model also provides a way to do the evaluation easily as well:\n",
        "\n",
        "```\n",
        "model.wv.evaluate_word_analogies\n",
        "```\n",
        "\n",
        "See the [documentation](https://radimrehurek.com/gensim/models/keyedvectors.html) for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMlRDUQkcIRl"
      },
      "source": [
        "#**fastText (2016)**\n",
        "\n",
        "Facebook's implementation for creating word embeddings and sentence classification is called fastText. It is written in C++ and supports multiprocessing during training. It's word vectors are actually sub-words. You can [read](https://arxiv.org/pdf/1607.04606.pdf) about it here. You can even install the fasttext Python library. The process of installing and evaluating the models will be very straightforward.\n",
        "\n",
        "#**Summary**\n",
        "There's a lot going on in this lesson. So much in fact that the tests for this lesson will only confirm that you wrote the necessary functions. We'll have a separate lesson that allows you to work on a corpus and build your own word embeddings.\n",
        "\n",
        "#**Lesson Assignment**\n",
        "If you followed along with the lesson, you should be good to go. All the model building (and loading) takes too long. But be sure that all the functions are properly written and run without errors. You still need to submit your notebook in Moodle for grading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_9ToiksMdCs"
      },
      "source": [
        "**Steps to submit your work:**\n",
        "\n",
        "\n",
        "1.   Download the notebook from Moodle. It is recommended that you use Google Colab to work on it.\n",
        "2.   Upload any supporting files using file upload option within Google Colab.\n",
        "3.   Complete the exercises and/or assignments\n",
        "4.   Download as .ipynb\n",
        "5.   Name the file as \"lastname_firstname_WeekNumber.ipynb\"\n",
        "6.   After following the above steps, submit the final file in Moodle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h1><center>The End!</center></h1>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Week7_word2vec_Lesson.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
