{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg1GOQPxSJr7"
      },
      "source": [
        "#**Gradient Descent**\n",
        "#**Parameter Estimation**\n",
        "\n",
        "**A quick recap**\n",
        "\n",
        "In the previous lesson on linear regression, we discussed the idea that the best fitting line $f(x) = w_0 + w_1x$  is the one that minimizes $SSE = \\sum(y_i - (w_0 + w_1x_i))^2 $ (the loss function).\n",
        "\n",
        "\n",
        "\n",
        "If you find that notation confusing, please go carefully through the linear regression lesson. This lesson continues where that one left off.\n",
        "\n",
        "We also created a graph that plotted different values for w0 (the y0) while holding the w1 (the slope) constant, and plotting the resulting MSE (mean squared error ) for a dataset (data20-2.csv).\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=19WnJchFoVWlX07paC-v2oSJC6b5nI-Ut)\n",
        "\n",
        "\n",
        "As a reminder, the above plot is the calculated MSE for different values of the y-intercept in a best-fit line for the dataset (while holding the slope constant).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ExYG2WiSjgM"
      },
      "source": [
        "#**A brute force attempt at finding the best w0**\n",
        "Of course it's easy to look at the graph you created and see that when w0 is about 7, the MSE is the lowest. However in a large dataset with multiple independent variables (or having a complex cost function), it's just not feasible to calculate every value for all possible combinations.\n",
        "\n",
        "#**An iterative attempt at finding the best w0**\n",
        "What if you were only given a single random w0 and you had to decide if that value was the best or if you should try a different value for w0?\n",
        "\n",
        "That is the job of gradient descent (GD for short). It is an iterative approach to parameter estimation. It starts with a random assignment for it's parameters. Then every iteration through the training set, it produces better estimates for the loss function it is trying to minimize.\n",
        "\n",
        "GD essentially starts on the graph somewhere, then attempts to go 'downhill' towards a better minimum.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1A2f5vJ1Q3KBiVXXKAaBSzJZcmr62MGBo)\n",
        "\n",
        "\n",
        "The loss function for this example is only based on one variable. However, gradient descent nicely generalizes to high dimensional space (i.e. having many independent variables), using different loss functions, and dealing with large datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JQ6sTBJS3be"
      },
      "source": [
        "#**Calculus, calculus!**\n",
        "#**wherefore art thou calculus?**\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1-opA0cIdsKVgG_QV9_2CZ2M-04IwX_j1)\n",
        "\n",
        "\n",
        "In order to understand the machinery behind GD, we need to peak back into our calculus books. If you never had calculus, fear not. Just be open to learning the reasons why we need it. Understanding the concepts are more important than being adroit at the mechanics.\n",
        "\n",
        "Hopefully, you are now comfortable with the concept of a line having a slope. It's simply the change in y divided by its change in x:\n",
        "\n",
        "$slope = \\frac{\\Delta y}{\\Delta x}$\n",
        "\n",
        "\n",
        "\n",
        "#**Magnitude**\n",
        "\n",
        "The slope's magnitude tells you how fast the line is changing (a slope of zero means it's not changing).\n",
        "\n",
        "#**Direction**\n",
        "\n",
        "The direction of the change is based on its sign:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Cp8sqiKXFXAPwzRcm9r0-I_V_uSyUn8U)\n",
        "\n",
        "\n",
        "\n",
        "Gradient descent loves the negative slope -- it communicates the idea that we are moving downward (we can minimize our loss even further).\n",
        "For a slope to be negative means either:\n",
        "\n",
        "* a positive step in the x direction results in a negative change in y \n",
        "* a negative step in the x direction results in a positive change in y\n",
        "\n",
        "By definition, a line's slope is constant. Calculate it once, and you are done. However, for non-linear functions it's not as simple. But calculus provides us with a few tricks (i.e. methods and techniques) to make it manageable.\n",
        "\n",
        "#**Back to the slopes**\n",
        "**The Tangent Trick**\n",
        "\n",
        "The following non-linear graph is the MSE vs w0 graph we created in the linear regression lesson. The MSE value is 258.32 when w0 is -8.16. And the number shown (-30.95) is the slope of that curve at the point (-8.16, 258.32).\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1IbnJEexetC30eGAoE-IQ_B8Hl6KKSAdu)\n",
        "\n",
        "\n",
        "How do get that value (-30.95)?\n",
        "\n",
        "Well if you zoom way into that graph, the 'curve' goes away (like seeing a flat horizon on a spherical earth). We can draw a new line (called the tangent line) that just touches the curve near the point we are interested in:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=18St174s__aQkWhdDvq1xtsDwNK0pV2dn)\n",
        "\n",
        "\n",
        "Note that the orange line (the tangent line) is essentially parallel to the curve at the point shown. And we know how to measure the slope of a line.\n",
        "We can now measure the change in  y (-50) for a positive change in x (1.6) (we can get those values by just selecting two different points).\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1kgL1VCkjbvljWXaD6BVEL4Hopl7dvkKy)\n",
        "\n",
        "\n",
        "\n",
        "**Slopes are a changin'**\n",
        "\n",
        "In our simple line equation, $f(x) = w_0 + w_1x$ , w1 is the slope. The slope tells us how much the line is changing at that point. In the case of a simple line, the output (y) always changes by the slope for a single step in x (note that value of w0 does not affect the result).\n",
        "\n",
        "The following graph shows the tangent line (representing the slope of the curve) at various selected points. Note what happens when and where the tangent line becomes horizontal.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1UyLQnpsGTaIFUfoiKJWq9xfvD1Ii5ySs)\n",
        "\n",
        "\n",
        "It's now clear that when the MSE is at its lowest (w0 = 7.13), the slope of the tangent line is zero! That's exactly what we need. We could pick points on the curve, measure the slope (using the tangent line) and decide how to pick the next point to try (until we have a zero slope).\n",
        "\n",
        "But we can do even better.\n",
        "\n",
        "**The Derivative Trick**\n",
        "\n",
        "If you know the function that is responsible for the curve, you can find it's derivative (if you know calculus). The derivative is just another function that gives you the slope at a point.\n",
        "\n",
        "Finding the derivative of a function is the specialty of differential calculus -- it teaches one how to find derivatives. You don't have to be an expert, but you should know the terminology.\n",
        "\n",
        "Rather than figuring out the necessary math to draw a line tangent to a curve, we can simply ask the derivative function for the value. When the derivative is zero, we are at the minimum for the curve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98YOCcLEUIU7"
      },
      "source": [
        "\n",
        "\n",
        "#**Summary's Slope**\n",
        "Here's what gradient descent is trying to do:\n",
        "\n",
        "You have a function (called the loss function) and you want to know where that function is at a minimum (i.e. you want to minimize it). For linear regression, we use the MSE function. Using calculus you find it's derivative function (or simply derivative).\n",
        "\n",
        "Gradient descent will pick a random point (a guess), ask for it's derivative (i.e. the slope) at that value. If the slope is negative it knows the guess needs to be bigger. If the slope (i.e. derivative) is positive, it knows it needs to subtract a bit from the guess. When the slope is near zero (or at zero), it knows it has found the value(s) where the loss function is minimized.\n",
        "\n",
        "That's it in a nutshell. There's a lot more details to fill in. But here's an outline of using gradient descent (version 1.0) to find the best value for w0:\n",
        "\n",
        "```\n",
        "w0 = pick a random value\n",
        "while not finished:\n",
        "    slope = get_slope_from_derivative(w0)\n",
        "    if slope < 0:\n",
        "        # increase our guess\n",
        "        w0 += a small amount\n",
        "    elif slope > 0:\n",
        "        # decrease our guess\n",
        "        w0 -= a small amount\n",
        "    else:\n",
        "        w0 is PERFECT\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAySVgxiUnhv"
      },
      "source": [
        "#**Gradient Descent for Two!**\n",
        "\n",
        "Now that we can see how GD works for a single variable, let's expand it for both w0 and w1. Let's review the MSE function we are trying to minimize:\n",
        "\n",
        "$MSE = \\frac{1}{n}\\sum(y_i-(w_0 + w_1x_i))^2$ </div>\n",
        "\n",
        "\n",
        "\n",
        "if MSE were a Python function, it would look like:\n",
        "```\n",
        "def calculate_mse(xv, yv, w0, w1):\n",
        "    err = yv - (xv*w1 + w0)\n",
        "    mse = np.sum(err * err)/len(xv)  # or mse = np.mean(err*err)\n",
        "    return mse\n",
        "```\n",
        "\n",
        "We can confirm this calculation (with our graphs above) and by using a guess for w0 of -8.16 with the known w1 value of 2.9063. Hopefully, we will get something close to 258."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xyeTe4gKU2f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "258.218923976\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def xy_from_file(p, x, y, show=False):\n",
        "  df = pd.read_csv(p)\n",
        "  if show:\n",
        "    df['XY'] = df[x] * df[y]\n",
        "    print(df.head())\n",
        "  x_values = df[x].values\n",
        "  y_values = df[y].values\n",
        "  return x_values, y_values\n",
        "\n",
        "def calculate_mse(xv, yv, w0, w1):\n",
        "    err = yv - (xv*w1 + w0)\n",
        "    mse = np.sum(err * err)/len(xv)  # or mse = np.mean(err*err)\n",
        "    return mse\n",
        "xv, yv = xy_from_file('data20-2.csv', 'SUGAR', 'TIME')\n",
        "mse = calculate_mse(xv, yv, -8.16, 2.9063)\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr3TAPPzU5bS"
      },
      "source": [
        "The function calculate_mse has two degrees of freedom (w0 and w1). Our initial plots from the previous lesson used just one of those weights.\n",
        "\n",
        "Here's what the graph looks like when you plot MSE vs w0 and w1. That is we are plotting for all combinations of w0 and w1 (same graph, two different perspectives):\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1JGiJ1GFS3fbgXBGfLu30CToZ1LfonxhK)\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1eONJCHx7qPejc_8n7jmwNz6lAUQohbLX)\n",
        "\n",
        "If you imagine looking straight at the w0 axis, you would 'see' your 2D graph previously created.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWsGfglYU-Tx"
      },
      "source": [
        "#**3D GD**\n",
        "Now rather than having a 'simple' graph to navigate, gradient descent will pick a random point on that mesh. But now it has to consider the slopes for w0 and w1. It can't make a decision in terms of which way is towards the minimum without taking into account both derivatives (slopes).\n",
        "<br><br>\n",
        "\n",
        "Since the loss function for a line has two weights (or a weight for each independent variable and an additional one) you need to find the derivative for both. In this case, it's called finding partial derivatives.\n",
        "<br><br>\n",
        "\n",
        "A partial derivative is a derivative found for each weight while assuming the other weights are just constants. In mathematical notation, for a function f (the MSE loss function), we say:\n",
        "\n",
        "* The partial derivative of f with respect to w0 is : $\\frac{\\partial f}{\\partial w0}$\n",
        "\n",
        "* The partial derivative of f with respect to w1 is : $\\frac{\\partial f}{\\partial w1}$\n",
        "\n",
        "Many times the letter d will be used instead of $\\partial$ (partial derivative $\\partial$).\n",
        "\n",
        "It is at this point, we ask our calculus friends to find those derivatives for us. When using gradient descent you don't have to know the mechanics of how to find derivatives, the libraries you will use have that figured out. When we get to neural networks the partial derivatives are a big part of back-propagation and can get a bit messy (again, we are getting ahead of ourselves).\n",
        "\n",
        "#**Partials Derivatives for GD (linear regression)**\n",
        "As mentioned in the linear regression lesson, sometimes you will see MSE expressed as a loss function using the letter 'J' (a homage to the Jacobian matrix):\n",
        "* $MSE = \\frac{1}{2n}\\sum(y_i-(w_0 + w_1x_i))^2$\n",
        "* $J(w_0,w_1) = \\frac{1}{2n}\\sum(y_i-(w_0 + w_1x_i))^2$ \n",
        "<br><br>\n",
        "\n",
        "Here are the two partial derivatives for the loss function MSE (already solved for us):\n",
        "* $\\frac{d}{dw_0} = \\frac{1}{n}\\sum(y_i-(w_0 + w_1x_i))$\n",
        "* $\\frac{d}{dw_1} = \\frac{1}{n}\\sum x_i(y_i-(w_0 + w_1x_i))$\n",
        "<br><br>\n",
        "\n",
        "\n",
        "Depending on who's in the mathroom, you may also see the following:\n",
        "* $\\frac{d}{dw_0} = \\frac{1}{2n}\\sum(y_i-(w_0 + w_1x_i))$\n",
        "* $\\frac{d}{dw_1} = \\frac{1}{2n}\\sum x_i(y_i-(w_0 + w_1x_i))$\n",
        "<br><br>\n",
        "\n",
        "**Extension for Linear Algebra**\n",
        "\n",
        "Another simplification that you may see (we won't be using this version) is to add an $x_0$ variable and set it to 1 for all instances (essentially adding another column/attribute). When GD is implemented using linear algebra, this is usually the way it's implemented.\n",
        "* $MSE = \\frac{1}{2n}\\sum(y_i-(w_0x_0 + w_1x_i))^2$\n",
        "* $\\frac{d}{dw_i} = \\frac{1}{2n}\\sum x_i(y_i-(w_0x_0 + w_1x_i))$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lKlfLquVyZS"
      },
      "source": [
        "#**Use the Gradient**\n",
        "\n",
        "The gradient in gradient descent is the set of functions (ultimately expressed inside of a matrix) that represent the slopes of the cost/loss function. The gradient is the set of partial derivatives (slopes).\n",
        "\n",
        "To repeat, the gradient is for the cost function.\n",
        "\n",
        "**Finding Your Way Home (with Blind Faith)**\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1u2uLrwTvQoBoKUHA4EqDOa8ovtYZeVQF)\n",
        "\n",
        "\n",
        "If you think of the loss function (i.e. the objective function) as a landscape, then to find your way home (where the loss is at its lowest point), you should proceed as follows:\n",
        "* start at some random place on the landscape\n",
        "* always move on the best path to a low ground (local minimum).\n",
        "* the best path is always the fastest path downward (consulting all directions).\n",
        "* the gradient is your guide.\n",
        "\n",
        "Here's our updated algorithm (Version 2.0) :\n",
        "\n",
        "```\n",
        "w0, w1 # pick random values to begin with\n",
        "\n",
        "while not finished:\n",
        "\n",
        "    mse = calculate_mse(xv, yv, [w0, w1])\n",
        "    if near threshold:\n",
        "       done\n",
        "\n",
        "    # calculate partial derivatives (errors)\n",
        "    for i in range(n):\n",
        "       w0_sum += (yv[i] - (w1*xv[i] + w0))\n",
        "       w1_sum += (yv[i] - (w1*xv[i] + w0)) * xv[i]\n",
        "    d_w0 = (-2/n) * w0_sum\n",
        "    d_w1 = (-2/n) * w1_sum\n",
        "\n",
        "    # update the weights (step size)\n",
        "    w0 = w0 - d_w0\n",
        "    w1 = w1 - d_w1\n",
        "```\n",
        "\n",
        "The important part is seeing how we update the weights (the last 2 lines).\n",
        "\n",
        " If the new slope is negative\n",
        "* we increase our guess a little bit (we subtract a negative)\n",
        "\n",
        "If the new slope is positive\n",
        "* we need to decrease our guess a little bit\n",
        "\n",
        "The following shows the path taken by gradient descent for our data (with both w0 and w1 purposely initialized with bad values.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1PHLm_Yrc6WzajWJS1fZ7cEfFWhdVpB3D)\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Eh2Rumga2kqG3xy6JR0681au8ttdp-Yq)\n",
        "\n",
        "\n",
        "You can see that the slope of w1 has a bigger impact in the direction to pursue at first, and then the slope of w0 has a bigger influence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muIrzsTIWVl4"
      },
      "source": [
        "\n",
        "\n",
        "#**The 'Learning' rate**\n",
        "The one area for concern is our update rule (how the weights get updated). Right now, if the slope, for example, was -18.00, our next step would be +18 steps in the x direction. That might jump right over the true minimum.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1m99030Z1M4jSZNt9sTf6ClU4wZVLvEkN)\n",
        "\n",
        "\n",
        "If you take too small of as step, converging on the local minimal can take a very long time. If you take too big of a step, you can jump past your goal:\n",
        "The solution is to dampen the effect by multiplying the slope (i.e. the next step) by a small amount -- called the learning rate. The result is called the step size:\n",
        "\n",
        "<div align=\"center\"> $ \\large step = learning\\ rate \\times slope$ </div>\n",
        "\n",
        "The learning rate ($\\alpha$) gives us some additional control over how large of steps we make.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1acDqx9sRm1KC0ByrW803VLRQjuntHDr3)\n",
        "\n",
        "\n",
        "With a very low learning rate, we can confidently move in the direction of the negative gradient at the cost of more calculations/steps.\n",
        "\n",
        "With a large learning rate, we can cover more ground each step, but we risk overshooting the lowest point since the slope of the hill is constantly changing.\n",
        "\n",
        "The most commonly used rates are: 0.001, 0.003, 0.01, 0.03, 0.1, 0.3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd6FS8IYW8wC"
      },
      "source": [
        "#**Normalizing input**\n",
        "A common technique to ensure GD converges quickly is to ensure the data is normalized to a 0-1 scale. If one attribute in orders of magnitude larger than the others, GD can result in numerical errors (overflow, instability). If you are unable to normalize the data and the attributes have different scales, you usually have to insist on a very small learning rate.\n",
        "\n",
        "#**Local vs Global Minimum**\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Fap7RaDLwKQrycPZGMGWRQm0M6g4f8WS)\n",
        "\n",
        "\n",
        "Depending on the landscape GD is navigating, it's quite possible that it will get stuck at a local minimum. That is how we end up at the bottom, but we are not at the lowest point of the cost function. It's one of the reasons why GD is initialized with random weights and run several times to compare different results.\n",
        "\n",
        "In some cases, we can get mathematical clearance (proof) that the gradient behaves in a way that we don't have to worry about it. But this is usually not the case.\n",
        "\n",
        "#**Variants of Gradient Descent**\n",
        "Once we have our gradient descent algorithm, we can use it in different ways. The algorithm outlined above (Version 2.0), updates the weights after visiting all the instances. This is batch gradient descent.\n",
        "\n",
        "**Batch gradient descent (BGD)**:\n",
        "* calculates the error for each example in the training dataset.\n",
        "* updates the model after all training examples have been evaluated.\n",
        "<br><br>\n",
        "\n",
        "For large datasets and/or working with many features, calculating the residuals and the derivatives for each of the features can become costly quickly. Rather than doing this for each data point (instance), we can pick a sample data point and run it through the algorithm. This is repeated for several samples. Stochastic gradient descent comes to our rescue! “Stochastic”, essentially means “random”.\n",
        "\n",
        "**Stochastic gradient descent (SGD)**:\n",
        "* calculate the error and updates the model for each example in the training dataset.\n",
        "* it is a batch size of 1 (the single sample).\n",
        "* this is done for many samples while keeping state of the model (rather than resetting the weights).\n",
        "<br><br>\n",
        "\n",
        "A third way is to use mini-batches. It is using the standard batch algorithm but with a small set (batch sizes of 32 are common) of instances. These mini-batches can be random samples or a specific set of rules to slice up the training data.\n",
        "<br><br>\n",
        "#**A Look Forward**\n",
        "Understanding GD is essential for knowing how parts of neural networks work. It can get messy fast, but the ideas are the same. Most implementations of GD are vectorized (i.e. use linear algebra) for efficient calculation. For example, the code below shows how the weights and MSE can be calculated very easily using numpy:\n",
        "\n",
        "```\n",
        "def gradient_v(xv, yv, w0, w1):\n",
        "\n",
        "    n = len(xv)\n",
        "    y_pred = xv.dot(w1).flatten() + w0\n",
        "    error = yv.flatten() - y_pred\n",
        "\n",
        "    # partial derivatives\n",
        "    est_w0 = np.mean(error)\n",
        "    est_w1 = error.dot(xv)\n",
        "\n",
        "    mse = np.sum(np.power(error, 2))/n\n",
        "    return est_w0, est_w1[0], mse\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLFTywY0XhIc"
      },
      "source": [
        "#**Lesson Assignment**\n",
        "#**Gradient Descent**\n",
        "\n",
        "We are going to implement batch gradient descent, starting with the pseudo code shown above (Version 2.0).\n",
        "\n",
        "You will create the same class from the previous lesson: LinearRegressionGD. The constructor will take two arrays (x, y)\n",
        "\n",
        "Implement the solve method within the LinearRegressionGD class\n",
        "```\n",
        "def solve(self, iterations=100000, learning_rate=???, threshold=???):\n",
        "```\n",
        "\n",
        "We will cover the details a bit further down.\n",
        "\n",
        "Here's how the class will be used (but not necessarily the correct hyper -parameters):\n",
        "```\n",
        "# load up the data\n",
        "xv, yv = xy_from_file('data20-2.csv', 'SUGAR', 'TIME')\n",
        "\n",
        "# create the class\n",
        "lr_gd = LinearRegressionGD(xv, yv)\n",
        "\n",
        "# solve using gradient descent\n",
        "w0, w1, iterations, mse = lr_gd.solve(threshold=1e-10, learning_rate=0.1)\n",
        "\n",
        "# see how well we did\n",
        "print(\"y = {:.4f}x + {:.4f}\".format(w1, w0))\n",
        "print('MSE {:.6f} after {:d} iterations'.format(mse, iterations))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vBY0rnxX3wC"
      },
      "source": [
        "#**Implementation Notes**\n",
        "General Restrictions:\n",
        "* You cannot use any part of an OLS solution (that would be taking short cuts) \n",
        "* You can only use numpy\n",
        "\n",
        "The method solve has a few requirements:\n",
        "\n",
        "* at most $iterations$ can be used, once that threshold is passed, you must return the current values\n",
        "* the parameter $threshold$ is used to determine when to return the current values\n",
        "* $threshold$ is the difference between the calculated MSE of the current step with the calculated MSE of the previous step. So if, for example, the last two calculations didn't improve MSE by enough, you are done\n",
        "\n",
        "* use the $learning\\_rate$ passed in as a parameter\n",
        "* return the 4-item tuple (w0 estimate, w1 estimate, number of iterations used, the current MSE value) in that order\n",
        "* use 0 for initializing both weight estimates (rather than using a random number)\n",
        "\n",
        "```\n",
        "\n",
        "xv, yv = xy_from_file('data20-2.csv', 'SUGAR', 'TIME')\n",
        "lr_gd = LinearRegressionGD(xv, yv)\n",
        "\n",
        "w0, w1, iterations, mse = lr_gd.solve(threshold=??, learning_rate=??)\n",
        "print(\"y = {:.4f}x + {:.4f}\".format(w1, w0))\n",
        "print('MSE {:.6f} after {:d} iterations'.format(mse, iterations))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "EjWUwDFoYPun"
      },
      "outputs": [],
      "source": [
        "class LinearRegressionGD(object):\n",
        "    def __init__(self, xv, yv) -> None:\n",
        "        super().__init__()\n",
        "        self.xv = xv\n",
        "        self.yv = yv\n",
        "        self.n = len(xv)\n",
        "    \n",
        "    def solve(self, iterations=100000, learning_rate=0.1, threshold=1e-10, w0=0, w1=0):\n",
        "        xv, yv, n, w0, w1 = self.xv, self.yv, self.n, 0, 0\n",
        "        # print(w0, w1)\n",
        "        mse = -np.Infinity\n",
        "        for iteration in range(int(iterations)):\n",
        "            mse_diff = abs(calculate_mse(xv, yv, w0, w1) - mse)\n",
        "            mse = calculate_mse(xv, yv, w0, w1)\n",
        "            # print(w0, w1)\n",
        "\n",
        "            w0_sum, w1_sum = 0, 0\n",
        "            for i in range(n):\n",
        "                w0_sum += yv[i] - (w1 * xv[i] + w0)\n",
        "                w1_sum += (yv[i] - (w1 * xv[i] + w0)) * xv[i]\n",
        "            d_w0 = (-2/n) * w0_sum\n",
        "            d_w1 = (-2/n) * w1_sum\n",
        "\n",
        "            ep_w0, ep_w1 = self.rescale([d_w0, d_w1], learning_rate)\n",
        "            # print(w0, w1, ep_w0, ep_w1, mse, mse_diff)\n",
        "            if np.isclose(mse_diff, threshold) or mse_diff < threshold:\n",
        "                return w0, w1, iteration, mse\n",
        "\n",
        "            w0 -= ep_w0\n",
        "            w1 -= ep_w1\n",
        "        return w0, w1, iterations, mse\n",
        "    \n",
        "    def rescale(self, vector=[0, 0], magnitude=1.0):\n",
        "        vec_mag = np.sqrt(np.sum(np.power(vector, 2)))\n",
        "        frac = magnitude / vec_mag\n",
        "        return np.multiply(vector, frac)\n",
        "                \n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "# TEST\n",
        "# lr_gd = LinearRegressionGD(xv, yv)\n",
        "# lr_gd.solve(iterations=100000, threshold=1e-10, learning_rate=0.1, w0=0, w1=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y = 2.9098x + 7.3005\n",
            "MSE 18.825036 after 1052 iterations\n"
          ]
        }
      ],
      "source": [
        "# load up the data\n",
        "xv, yv = xy_from_file('data20-2.csv', 'SUGAR', 'TIME')\n",
        "\n",
        "# create the class\n",
        "lr_gd = LinearRegressionGD(xv, yv)\n",
        "\n",
        "# solve using gradient descent\n",
        "w0, w1, iterations, mse = lr_gd.solve(iterations=10000, threshold=1e-4, learning_rate=1e-2)\n",
        "\n",
        "# see how well we did\n",
        "print(\"y = {:.4f}x + {:.4f}\".format(w1, w0))\n",
        "print('MSE {:.6f} after {:d} iterations'.format(mse, iterations))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y = -0.0530x + 7.5695\n",
            "MSE 1.866311 after 25495 iterations\n"
          ]
        }
      ],
      "source": [
        "# load up the data\n",
        "xv, yv = xy_from_file('data20-3.csv', \"SCORE\", \"NSOLVED\")\n",
        "\n",
        "# create the class\n",
        "lr_gd = LinearRegressionGD(xv, yv)\n",
        "\n",
        "# solve using gradient descent\n",
        "w0, w1, iterations, mse = lr_gd.solve(iterations=100000, threshold=1e-6, learning_rate=1e-2)\n",
        "\n",
        "# see how well we did\n",
        "print(\"y = {:.4f}x + {:.4f}\".format(w1, w0))\n",
        "print('MSE {:.6f} after {:d} iterations'.format(mse, iterations))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y = 1.0251x + 37.1985\n",
            "MSE 473.623768 after 5387 iterations\n"
          ]
        }
      ],
      "source": [
        "# load up the data\n",
        "xv, yv = xy_from_file('data21-1.csv', \"EXPER\", \"SCORE\")\n",
        "\n",
        "# create the class\n",
        "lr_gd = LinearRegressionGD(xv, yv)\n",
        "\n",
        "# solve using gradient descent\n",
        "w0, w1, iterations, mse = lr_gd.solve(iterations=100000, threshold=1e-10, learning_rate=1e-2)\n",
        "\n",
        "# see how well we did\n",
        "print(\"y = {:.4f}x + {:.4f}\".format(w1, w0))\n",
        "print('MSE {:.6f} after {:d} iterations'.format(mse, iterations))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's our updated algorithm (Version 2.0) :\n",
        "\n",
        "```\n",
        "w0, w1 # pick random values to begin with\n",
        "\n",
        "while not finished:\n",
        "\n",
        "    mse = calculate_mse(xv, yv, [w0, w1])\n",
        "    if near threshold:\n",
        "       done\n",
        "\n",
        "    # calculate partial derivatives (errors)\n",
        "    for i in range(n):\n",
        "       w0_sum += (yv[i] - (w1*xv[i] + w0))\n",
        "       w1_sum += (yv[i] - (w1*xv[i] + w0)) * xv[i]\n",
        "    d_w0 = (-2/n) * w0_sum\n",
        "    d_w1 = (-2/n) * w1_sum\n",
        "\n",
        "    # update the weights (step size)\n",
        "    w0 = w0 - d_w0\n",
        "    w1 = w1 - d_w1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 6, 10])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.multiply([3, 5], 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpdHQn_OYSZF"
      },
      "source": [
        "Be sure to experiment:\n",
        "\n",
        "* What happens if you set the threshold too low?\n",
        "\n",
        "the program finish early without have the more accurate regression function\n",
        "\n",
        "* What happens if you set the learning_rate too high?\n",
        "\n",
        "the (w0, w1) bounces between the actual point but not lie close to that point\n",
        "\n",
        "* What happens if you set the learning_rate too low?\n",
        "\n",
        "it take a lot of time for the cursor to travel from the beginning point and it may not capable to run near the goal point\n",
        "\n",
        "* Can you get the exact answer with the right parameters?\n",
        "\n",
        "no, at least not the exact value but we can get close. It dependes on the learning_rate param we pass (learning_rate lower, w0 w1 closer to the real value)\n",
        "\n",
        "* What is the least number of iterations you can solve for each dataset?\n",
        "\n",
        "-2:\n",
        "y = 2.9098x + 7.3005\n",
        "MSE 18.825036 after 1052 iterations (thres=1e-4)\n",
        "\n",
        "-3:\n",
        "y = -0.0530x + 7.5695\n",
        "MSE 1.866311 after 25495 iterations (thres=1e-6)\n",
        "\n",
        "21-1:\n",
        "y = 1.0251x + 37.1984\n",
        "MSE 473.623768 after 5377 iterations (thres=1e-9)\n",
        "\n",
        "it seems the later dataset are more organized\n",
        "\n",
        "* What is the least number of total iterations you can solve all the datasets?\n",
        "\n",
        "to be accurate to the .4 points after decimal, it's about tens thousands of iterations. \n",
        "\n",
        "Write down your observations!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2Z7mMGmeWDv"
      },
      "source": [
        "**Steps to submit your work:**\n",
        "\n",
        "\n",
        "1.   Download the lesson notebook from Moodle.\n",
        "2.   Upload any supporting files using file upload option within Google Colab.\n",
        "3.   Complete the exercises and/or assignments\n",
        "4.   Download as .ipynb\n",
        "5.   Name the file as \"lastname_firstname_WeekNumber.ipynb\"\n",
        "6.   After following the above steps, submit the final file in Moodle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h1><center>The End!</center></h1>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Gradient Descent_Week15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
